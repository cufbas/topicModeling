"
Sponsored Workshops at AAAI-18
February 2–3, 2018

2018 AAAI Author Kit
(Use of the files in the 2018 kit are required)

The AAAI-18 Program Committee invites proposals for the Workshop Program of the Association for the Advancement of Artificial Intelligence’s Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18).
",2018
"
Important Dates for Workshop Organizers


October 13: Submissions due (unless noted otherwise)
November 9: Notification of acceptance
November 21: Camera-ready copy due to AAAI
February 2-3: AAAI-18 Workshop Program

",2018
"

W1: Affective Content Analysis
W2: AI and Marketing Science
W3: Artificial Intelligence Applied to Assistive Technologies and Smart Environments
W4: Artificial Intelligence for Cyber Security
W5: AI for Imperfect-Information Games
CANCELLED W6: Artificial Intelligence for Smart Grids and Smart Buildings
W7: Declarative Learning Based Programming
W8: Engineering Dependable and Secure Machine Learning Systems
W9: Health Intelligence
W10: Knowledge Extraction from Games
W11: Plan, Activity, and Intent Recognition
W12: Planning and Inference
W13: Preference Handling
W14: Reasoning and Learning for Human-Machine Dialogues
W15: SmartIoT: AI Enhanced IoT Data Processing for Intelligent Applications
W16: Statistical Modeling of Natural Software Corpora

",2018
"

W01 — Affective Content Analysis
Affect analysis refers to the set of techniques that identify and measure the experience of an emotion. This workshop focuses on analyzing affect in content including text, audio, images, and videos. The word affective is used to refer to emotion, sentiment, personality, mood, and attitudes including subjective evaluations, opinions, and speculations. All methods and models that measure affective responses to content are in the scope of the workshop.
Work on affect analysis in language and text spans many research communities, including computational linguistics, consumer psychology, human-computer interaction (HCI), marketing science, and cognitive science. Computational linguists study how language evokes as well as expresses emotion. Consumer psychology examines human affect by drawing upon grounded psychological theories of human behavior. The HCI community studies human responses as a part of user experience evaluation. This workshop aims at bringing together researchers from multiple disciplines for stimulating discussions on the open research problems in affect analysis, with an emphasis on language and text.
Computational models for consumer psychology theories present a huge opportunity to guide the construction of intelligent systems that understand human reactions, and tools from linguistics and machine learning can provide attractive methods to fulfil those opportunities. Models of affect have recently been adapted for social media platforms, enabling new approaches to understanding users’ opinions, intentions, and expressions. However, the exponentially increasing size and the dynamic, multimedia nature of this data make it difficult to detect and measure affect. Furthermore, the subjective nature of human affect suggests the need to measure in ways that recognize multiple interpretations of human responses. A few key challenges are as follows:

Standardizing the measurement of affect in order to meaningfully compare different affective models against each other
Addressing the challenges in cross-media, cross-domain, and cross-platform affect analysis
Identifying consumer psychology theories and behaviors related to affect, which are amenable to computational modeling
Building language-based affect models as input for other data science applications

The AI community is well-poised to propose new solutions, approaches, and frameworks to tackle these and other challenges. This workshop invites papers that address these and other topics, propose novel solutions for well-established problems, offer modeling and measurement of affect, and identify the best affect–related dimensions to study consumer behavior. Potential examples include deep learning for affect analysis, leveraging traditional affective computing algorithms (that are built on multimodal data and sensors) for text and so on. Another area of focus for this workshop is the need of standardized baselines, datasets, and evaluation metrics. Hence, papers describing novel language resources, evaluation metrics, and standards for affect analysis and understanding are also invited.
Topics
We invite submissions on topics including — but not limited to — text and multimedia, multilingual analysis and understanding of affective content, applications of affect–based language processing, spoken versus written language comparison, and analysis of online text content — both user generated and planned marketing communication. Specific examples of fields of interests include (but are not limited to) the following:

Affect modeling in content
Computational models for consumer behavior theories
Psycholinguistics, including stylometrics and typography
Affect-aware text generation
Spoken and formal language comparison
Psychodemographic profiling
Measurement and evaluation of affective content
Modeling consumer’s affect reactions
Affect lexica for online marketing communication
Affective commonsense reasoning
Affective human-agent, human-computer, and human-robot interaction
Multimodal emotion recognition and sentiment analysis

We especially invite papers investigating multiple related themes, industry papers, and descriptions of running projects and ongoing work.
Call for Datasets
A big challenge in working in this interdisciplinary space is the availability of the right data. We invite dataset papers which describe new data resources. Dataset paper submissions must comprise the following:
The data itself — organized as a single dataset or a group of datasets, and metadata, which describes data collection and processing methods, documentation of the structure and descriptive statistics about the content and quality of the dataset.
Authors should describe potential uses and applications of the dataset, but any sophisticated analysis can be a regular paper submission.
Format
This full-day workshop will have several prominent invited speakers such as Dr. Dipankar Chakravarti and Dr. Lyle Ungar to lead the paper presentation sessions throughout the day.
In a poster session in the afternoon, a few papers deemed more suited for a poster than a presentation will be invited to display a poster or a demo. We will end the workshop with a fishbowl-style discussion among the organizers and participants to decide on future directions for the workshop and the research community.
Submissions
EasyChair Submission URL
Submissions should be made via the EasyChair submission site and must follow the formatting guidelines for AAAI-2018 using the AAAI-18 Author Kit. All submissions must be anonymous and conform to AAAI standards for double-blind review.
Cochairs
Niyati Chhaya, primary contact (Adobe Research, nchhaya@adobe.com), Kokil Jaidka (University of Pennsylvania, jaidka@sas.upenn.edu), Lyle Ungar (University of Pennsylvania, ungar@cis.upenn.edu), P. Anandan (p.anandan55@outlook.com)
Additional Information
Workshop URL

W02 — Artificial Intelligence and Marketing Science
The revolution in the digital economy has rapidly changed the way companies manage, execute and measure the effectiveness of marketing strategies and the delivery of marketing products and services. The widespread growth in digital marketing tools and platforms have led to diverse sources of marketing, advertising and consumer behavioral data, often available in real time. This opens the door to the application of a wide range of AI techniques in areas traditionally considered parts of the marketing science (MS). For example, this includes the use of machine learning, deep learning, sequential decision making, bandits and sequential testing, recommendation systems, game theory, knowledge representation, market design and optimization, and so on for the purpose of marketing resource optimization, managerial decision making, competitive behavior modeling, deconstruction of consumer behavior, and campaign automation and optimization.
Research in this field has been largely carried in separate communities until now. Within the AI and machine learning community, the focus has been on developing new and more efficient computational models and techniques, geared towards specific tasks. Within the MS community, the focus has been on exploiting machine learning methods and scalable data methods for addressing important business problems that marketers face. Consequently, researchers publish in separate journals and conferences. It is our conviction that these two separate communities have a lot to benefit from each other’s work, problems and insights.
Topics
This workshop seeks to bring together researchers and practitioners from AI and from MS communities to share in ideas, challenges, opportunities and successes. It will aim to identify important research directions and to identify opportunities for synthesis and unification. In particular, we are calling for research contributions in the following areas:

Optimizing marketing decisions under resource constraint
Automated decision making with feedback
Optimizing spend across channels
Automation and optimization of marketing campaign
Optimization in the delivery or marketing messages
Understanding consumer psychology personalization and optimization of marketing assets and contents
Bandits and sequential testing for marketing strategies.
Customer journey modeling
Consumer life time value optimization and sequential decision making
Personalization and recommendation
Intent recognition and user modeling on the web and in marketplaces and e-commerce
Causal inference and measuring the effectiveness of marketing message
Automatic clustering and audience segmentation
Predictive analytics and forecasting of key performance metrics in commerce
Applications of deep learning in predictive analytics
Representation learning for marketing data
Knowledge representation for marketing science insights
Learning in games and mechanism design for marketing
Social games and marketing methods.

Due to the diversity of disciplines represented in this area, related contributions in other fields are also welcome.
Format
We solicit research contributions that report new research results or ongoing research. The workshop’s proceedings can be considered nonarchival, meaning contributors are free to publish their results later in archival journals or conferences. Research contributions should follow the AAAI formatting guideline and template and should be limited to a maximum of 6 pages in AAAI format excluding the references.
Submissions
Submissions should be sent to aims2018submit@gmail.com; by October 13. Acceptance notification will be sent out on November 9, 2017.
Workshop Cochairs
Hung Bui (Adobe Research), Pradeep Chintagunta (University of Chicago), S. Muthukrishnan (Rutgers University), Tuomas Sandholm (Carnegie Mellon University), Atanu Sinha (Adobe Research and Emeritus, University of Colorado), Georgios Theocharous (Adobe Research)
Additional Information
Workshop URL

W03 — Artificial Intelligence Applied to Assistive Technologies and Smart Environments
Ambient intelligence can help, transform, and enhance the way people with disabilities perform their activities of daily living, activities that would otherwise be difficult or impossible for them to do. However, despite the increasing trend toward the development of new assistive technologies to help people with disabilities, no real adoption tendency has been observed yet, regarding the targeted user groups. Indeed, users’ impairments and particularities are so diverse, that implementing complex technological solutions — mandatory for user adaptation — represents a major challenge in terms of universal design. In such a context, the main objective of this workshop is to investigate new solutions to scientific problems occurring in the various topics related to artificial intelligence applied in the domain of impaired people assistance.
Topics
This workshop will explore various topics including, but not limited to the following:

Algorithms for plan, activity, intent, or behavior recognition or prediction
Personalization (user modeling, user profile, and others)
Algorithms for intelligent proactive assistance
Context awareness
High-level activity and event recognition
Multiperson localization
Autonomic computing
High-level control of autonomous systems
Fault tolerance of assistive technologies
Pervasive and/or mobile cognitive assistance

Format
This one-day workshop will consist of invited talks from experts, technical and position paper presentations organized into topical sessions (decided based on submissions), and a poster session depending on the participation. To encourage discussion, the workshop will be limited to 50 invited participants.
Submissions
EasyChair Submission URL
The organizing committee is currently seeking either technical papers up to six pages in the conference format, or, for poster presentations, a short paper or extended abstract up to 2 pages describing research relevant to the workshop.
Chairs and Cochairs
Bruno Bouchard, Ph.D
418 545-5011 (5604) | bruno.bouchard@uqac.ca
555, boul. de l’Université, Chicoutimi, QC, G7H 2B1 Canada
Sébastien Gaboury, Ph.D
418 545-5011 (2604) | Sebastien.Gaboury@uqac.ca
555, boul. de l’Université, Chicoutimi, QC, G7H 2B1 Canada
Kévin Bouchard, Ph.D
418 545-5011 (5063) | Kevin.Bouchard@uqac.ca
555, boul. de l’Université, Chicoutimi, QC, G7H 2B1 Canada
Abdenour Bouzouane, Ph.D
418 545-5011 (5214) | abdenour.bouzouane@uqac.ca
555, boul. de l’Université, Chicoutimi, QC, G7H 2B1 Canada
Additional Information
Workshop URL

W04 — Artificial Intelligence for Cyber Security
This workshop will focus on the application of artificial intelligence to problems in cyber security. This year the workshop’s emphasis will be on Internet of Things (IoT) and mobile devices relative to cyber security. The workshop will address technologies and their applications, such as machine learning, game theory, natural language processing, knowledge representation, automated and assistive reasoning, and human machine interactions. The workshop will emphasize cyber systems and research on techniques to enable resilience in mobile systems involving human-machine interactions.
IoT and mobile devices provide powerful sensing and computing capabilities to users and systems. These same capabilities, however, offer new opportunities for adversarial compromise, resulting in the loss of data and control, and could lead to infection spread to other connected devices. Artificial intelligence capabilities have the potential to help protect these mobile platforms in several ways. Because IoT mobile devices, such as smart phones, are often used by one individual at a time, behavioral analysis techniques that model normal user usage patterns can be leveraged to recognize anomalous, or out-of-the-ordinary, behaviors that might be indicative of misuse. In addition, graph analysis of a device’s connectivity network, such as a user’s social network or links in a web page, can be leveraged to identify malicious sites that could seek to infect the devices. Finally, AI capabilities that collect, correlate, and analyze multiple data sources at once can be leveraged to confirm the provenance and veracity of data from suspect IoT devices.
Addressing the cyber security challenges of IoT and mobile devices requires collaboration between several different research and development communities including the artificial intelligence, cyber-security, game theory, machine learning, and formal reasoning communities.
The aforementioned applications of AI have the potential to impact cyber security in a positive way, bringing automated learning and game theory into the service of improved system resilience. Developing and applying these and other AI capabilities to cyber security problems requires collaboration between several different communities including the artificial intelligence, game theory, machine learning, and cyber-security communities, as well as the operational and commercial applications communities. This workshop is structured to encourage a lively exchange of ideas between researchers in these communities from the academic, public, and commercial sectors.
Topics

Machine learning approaches to make cyber systems secure and resilient

Natural language processing techniques
Anomaly/threat detection techniques
Big data noise reduction techniques
Human behavioral modeling


Formal reasoning, with focus on human element, in cyber systems
Game theoretic reasoning in cyber security
Economics of cyber security
Multiagent interaction/agent-based modeling in cyber systems
Modeling and simulation of cyber systems and system components
Decision making under uncertainty in cyber systems
Automated security aids for system administrators
Quantitative human behavior models with application to cyber security
Operational and commercial applications of AI

Challenge Problem
For information on this year’s AICS challenge problem please see the Workshop URL. The Challenge Problem is sponsored by the CrowdStrike Foundation.
Format
The workshop will consist of invited speakers, presentations, and panel and group discussions
Submissions
EasyChair Submission URL
One of two submissions is solicited: Full-length papers (up to 8 pages in AAAI format) or Challenge Problem papers (up to 8 pages in AAAI format).
Submissions are not anonymized. Please submit PDF via the workshop URL website by October 23, 2017. Accepted papers will be published in the workshop proceedings.
Cochairs
William W. Streilein (MIT Lincoln Laboratory, MA, USA, wws@ll.mit.edu), David R. Martinez (MIT Lincoln Laboratory, MA, USA, dmartinez@ll.mit.edu), Howard Shrobe (MIT/CSAIL, MA, USA, hes@csail.mit.edu), Arunesh Sinha (University of Michigan, MI, USA, aruneshsinha@gmail.com), Neal Wagner (MIT Lincoln Laboratory, MA, USA, Neal.wagner@ll.mit.edu), Cem Sahin (MIT Lincoln Laboratory, MA, USA, Cem.Sahin@ll.mit.edu)
Program Committee
George Cybenko (Dartmouth College), Christos Dimitrakakis (Chalmers University of Technology, Sweden), Robert Goldman (Smart Information Flow Technologies (SIFT)), Christopher Kiekintveld (University of Texas at El Paso), Robert Laddaga (Vanderbilt University), Richard Lippmann (MIT Lincoln Laboratory), Mingyan Liu (University of Michigan), Daniel Lowd (University of Oregon), Christopher Miller (Smart Information Flow Technologies (SIFT)), Katerina Mitrokotsa (Chalmers University of Technology, Sweden), Ranjeev Mittu (Naval Research Laboratory), Sven Krasser (Crowdstrike), Benjamin Rubinstein (University of Melbourne, Australia), Robert Templeman (Navy Surface Warfare Center, Crane Division)
Administrative Contact: Cynthia Devlin-Brooks
MIT Lincoln Laboratory, 244 Wood Street, Lexington, MA 02420
Voice: 781-981-7501 | Fax: 781-981-4086
Cynthia.Devlin-Brooks@ll.mit.edu
Additional Information
Workshop URL

W05 — Artificial Intelligence for Imperfect-Information Games
Recent years brought substantial progress in research on imperfect-information games. Superhuman performance has been achieved in large-scale variants of poker. Game theoretic models with all sorts of uncertainty have been applied in security domains ranging from protecting critical infrastructure through green security (for example, protecting wildlife and fisheries) to cyber security. Computer agents able to play a previously unknown imperfect-information games only based on a formal description of its dynamics have been developed.
In this AAAI-18 workshop, we aim to create a forum where researchers studying theoretical and practical aspects of imperfect-information games can meet, present their recent results and discuss their new ideas. Moreover, we want to facilitate interaction between distinct communities studying various aspect and focusing on various domains in imperfect information games.
Topics
All topics related to theoretical or practical aspects of imperfect-information games are of interest at the workshop. This includes for example descriptions of complete agents or novel components of agents playing specific imperfect-information games, such as Poker or Bridge, imperfect-information games modelling real world problems, or general game playing agents for imperfect-information games. We welcome submissions analyzing formal representations of imperfect-information games and their consequences on speed or optimality of game playing. We are also interested in opponent modeling techniques and human behavioral aspects specific for imperfect-information games.
Format
The workshop will last a full day and will consist of both oral and poster presentations, as well as presentation of results and discussion about the annual Computer Poker Competition. Anyone is welcome to attend the workshop; in the event of space constraints, priority will be given to people who submit papers or posters, or who participate in the Computer Poker Competition.
Submissions
EasyChair Submission URL
Each submission will be in the form of an up to 8-page paper, using the main AAAI conference format. We leave to the authors if they want to anonymize their submissions or not. Papers should be submitted via EasyChair. Oral presentations and poster session participants will be selected from the submissions.
Workshop Chairs
Noam Brown (Carnegie Mellon University, noamb@cs.cmu.edu, Marc Lanctot (Google DeepMind, lanctot@google.com), Haifeng Xu (University of Southern California, haifengx@usc.edu)
Additional Information
Workshop URL

W07 — Declarative Learning Based Programming
The main goal of Declarative Learning Based Programming workshop is to investigate the issues that arise when designing and using programming languages that support learning from data and knowledge. Declarative learning based programming aims at new programming models and abstractions that facilitate the design and development of intelligent real world applications that use machine learning, deep learning and reasoning.
The challenges of such a paradigm include interaction with messy, naturally occurring data; specifying the requirements of the application at a high abstraction level; dealing with uncertainty in various layers of the application program; supporting flexible relational feature engineering and learning rich data representations; using representations that support flexible reasoning, structured and deep learning; supporting model chaining and composition; integrating a range of learning and inference algorithms; and, finally, addressing the above mentioned issues in one unified programming environment.
Conventional programming languages offer no help to application programmers that attempt to design and develop applications that make use of real world data, and reason about it in a way that involves learning interdependent concepts from data, incorporating and composing existing models, and reasoning about existing and trained models and their parameterization. The research community has tried to address these problems from multiple perspectives, most notably various approaches based on Probabilistic programming, Logical Programming and the integrated paradigms. The goal of this workshop is to present and discuss the current related research and the way various challenges have been addressed.
We aim at motivating the need for further research toward a unified framework in this area based on the key existing paradigms: probabilistic programming, logic programming, probabilistic logical programming, first-order query languages and database management systems and deductive databases, statistical relational learning and related languages, declarative deep learning frameworks and connect these to the ideas of declarative learning based programming. We aim to discuss and investigate the required type of languages and representations that facilitate modeling complex learning models, deep architectures, and provide the ability to combine, chain and perform flexible inference by exploiting domain knowledge.
Though the theme of this workshop remains generic, we aim at emphasizing on ideas and opinions regarding conceptual representations of deep learning architectures that connect various computational units to the semantics of declarative data and knowledge representations. We are interested in the abstractions that in contrast to the existing ones (for example, tensor flow), are away from the underlying computational units and are towards declarative domain representations while are expressive enough to exploit the deep configurations and computations.
Submissions
EasyChair Submission Site
We encourage contributions with either a technical paper (AAAI style, 6 pages without references), a position statement (AAAI style, 2 pages maximum) or an abstract of a published work. Please make submissions via EasyChair. Detailed submission instructions can be found on the workshop website.
Organizing Committee
Parisa Kordjamshidi (Tulane University / Florida Institute for Human & Machine Cognition, pkordjam@tulan.edu), Dan Roth (University of Pennsylvania, danroth@seas.upenn.edu), Kristian Kersting (TU Darmstadt, kersting@cs.tu-darmstadt.de), Dan Goldwasser (Purdue University, dgoldwas@purdue.edu), Nikolaos Vasiloglou II (Ismion Inc, nvasil@gmail.com)
Additional Information
Workshop URL

W08 — Engineering Dependable and Secure Machine Learning Systems
Modern society increasingly relies on machine learning (ML) solutions. Like other systems, ML systems must meet their requirements. Standard notions of software quality and reliability such as deterministic functional correctness, black box testing, code coverage or traditional software debugging become practically irrelevant for ML systems. This is due to the nondeterministic nature of ML systems, reuse of high quality implementations of ML algorithms, and lack of understanding of the semantics of learned models, for example, when deep learning methods are applied.
For example, self-driving car models may have been learned in a cold weather country. When such a car is deployed in a hot weather country, it will likely face dramatically different driving conditions that may render its models obsolete. This calls for novel methods and new methodologies and tools to address quality and reliability challenges of ML systems.
Furthermore, broad deployment of ML software in networked systems inevitably exposes the ML software to attacks. While classical security vulnerabilities are relevant, ML techniques have additional weaknesses, some already known (for example, sensitivity to training data manipulation), and some yet to be discovered. Hence, there is a need for research as well as practical solutions to ML security problems.
With these in mind, this workshop solicits original contributions addressing problems and solutions related to dependability, quality assurance and security of ML systems. The workshop combines several disciplines, including ML, software engineering (with emphasis on quality), security, and algorithmic game theory. It further combines academia and industry in a quest for well-founded practical solutions.
Topics
Topics of interest include, but are not limited, to the following:

Software engineering aspects of ML systems and quality implications
Testing and debugging of ML systems
Quality implication of ML algorithms on large-scale software systems
Case studies of successful and unsuccessful applications of ML techniques
Correctness of data abstraction, data trust

ML techniques to meet security and quality
Size of the training data, implied guaranties
Application of classical statistics to ML systems quality


Sensitivity to data distribution diversity and distribution drift
The effect of labeling costs on solution quality (semi-supervised learning)
Reliable transfer learning
Vulnerability, sensitivity and attacks against ML
Adversarial ML and adversary based learning models
Strategy-proof ML algorithms

Submissions
EasyChair Submission Site
We solicit original papers in two formats – full (8 pages) and short (4 pages, work in progress), in AAAI format. Submission is via EasyChair. All authors of accepted papers will be invited to participate. The workshop will include paper presentation sessions. Full papers are allocated 20m presentation and 10m discussion. Short papers 10m presentation + 5m discussion. The last session will be a panel discussion.
Chairs
Dr. Eitan Farchi
DE, Software Testing Analysis and Reviews,
IBM Research, Haifa, Israel
Tel: +972-4-8296154 | Fax: +972-4-8296114 | Mobile: +972-54-4373352
Email: farchi@il.ibm.com
Prof. Onn Shehory
Information Systems, Graduate School of Business Administration,
Bar Ilan University, Israel
Tel: +972-3-5318362 | Fax: +972-6325239 | Email: onn.shehory@biu.ac.il
Dr. Anna Zamansky
Information Systems Department, University of Haifa, Israel
Tel: +972-545402870 | Email: annazam@is.haifa.ac.il
Prof. Ilan Shimshoni
Information Systems Department, University of Haifa, Israel
Tel: +972-4-8288510 | Email: ishimshoni@is.haifa.ac.il
Additional Information
Workshop URL

W09 — Health Intelligence
Public health authorities and researchers collect data from many sources and analyze these data together to estimate the incidence and prevalence of different health conditions, as well as related risk factors. Modern surveillance systems employ tools and techniques from artificial intelligence and machine learning to monitor direct and indirect signals and indicators of disease activities for early, automatic detection of emerging outbreaks and other health-relevant patterns. To provide proper alerts and timely response public health officials and researchers systematically gather news, and other reports about suspected disease outbreaks, bioterrorism, and other events of potential international public health concern, from a wide range of formal and informal sources. Given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. This is especially the case for nontraditional online resources such as social networks, blogs, news feed, twitter posts, and online communities with the sheer size and ever-increasing growth and change rate of their data. Web applications along with text processing programs are increasingly being used to harness online data and information to discover meaningful patterns identifying emerging health threats. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real time data on epidemics.
Moreover, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork between patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All of these changes require novel solutions and the AI community is well positioned to provide both theoretical- and application-based methods and frameworks. Creating and refining AI-based approaches that (1) process personalized data, (2) help patients (and families) participate in the care process, (3) improve patient participation, (4) help physicians utilize this participation in order to provide high quality and efficient personalized care, and (5) connect patients with information beyond those available within their care setting will improve health outcomes. The extraction, representation, and sharing of health data, patient preference elicitation, personalization of generic therapy plans, adaptation to care environments and available health expertise, and making medical information accessible to patients are some of the relevant problems in need of AI-based solutions.
This two-day workshop will address various aspects of using AI for improving population and personalized healthcare and is structured in two tracks focusing on population (W3PHI) and personalized health (HIAI). This workshop aims to bring together a wide range of computer scientists, clinical and health informaticians, researchers, students, industry professionals, national and international health and public health agencies, and NGOs interested in the theory and practice of computational models of population health intelligence and personalized healthcare. The workshop promotes open debate and exchange of opinions among participants.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. The scope of the workshop includes, but is not limited to, the following areas:

Knowledge representation and extraction
Integrated health information systems
Patient education
Patient-focused workflows
Shared decision making
Geographical mapping and visual analytics for health data
Social media analytics
Epidemic intelligence
Predictive modeling and decision support
Semantic web and web services
Biomedical ontologies, terminologies, and standards
Bayesian networks and reasoning under uncertainty
Temporal and spatial representation and reasoning
Case-based reasoning in healthcare
Crowdsourcing and collective intelligence
Risk assessment, trust, ethics, privacy, and security
Sentiment analysis and opinion mining
Computational behavioral/cognitive modeling
Health intervention design, modeling and evaluation
Online health education and e-learning
Mobile web interfaces and applications
Applications in epidemiology and surveillance (for example, bioterrorism, participatory surveillance, syndromic surveillance, population screening)

Format
The workshop will be two full days consisting of a welcome session, keynote and invited talks, full/short paper presentations, demos, posters, and one or two panel discussions.
Submissions
EasyChair Submission Site
We invite researchers and industrial practitioners to submit their original contributions following the AAAI format through EasyChair. Three categories of contributions are sought: full-research papers up to 8 pages; short paper up to 4 pages; and posters and demos up to 2 pages.
Organizing Committee
Martin Michalowski, Cochair, (University of Minnesota – Twin Cities, martinm@umn.edu); Arash Shaban-Nejad, Cochair, (The University of Tennessee Health Science Center – Oak-Ridge National Lab Center for Biomedical Informatics, ashabann@uthsc.edu); Szymon Wilk (Poznan University of Technology, szymon.wilk@cs.put.poznan.pl); David L. Buckeridge (McGill University, david.buckeridge@mcgill.ca); John S. Brownstein (Boston Children’s Hospital, Harvard University, john_brownstein@harvard.edu); Byron C. Wallace (Northeastern University, byron@ccs.neu.edu); Michael J. Paul (The University of Colorado Boulder, mpaul@colorado.edu)
Additional Information
Workshop URL

W10 — Knowledge Extraction from Games
Knowledge Extraction from Games is a new workshop exploring questions of and approaches to the mechanical extraction of knowledge from games meant for humans &mdash including, but not limited to, game rules, character graphics, environment maps, music and sound effects, high-level goals or heuristic strategies, transferrable skills, aesthetic standards and conventions, or abstracted models of games.
Topics
Some examples of work that would be appropriate for KEG include contextual query-answering in games where nonplayer characters (or visual cues in environment design) offer hints to solve problems; extracting architectural information from game level layouts; transfer learning, analogical reasoning, or goal reasoning within or between games or game levels; game-playing agents which can explain their own actions or policy in terms of the game’s rules; learning the rules of a game from observation, or learning higher-level rules or goals automatically; or determining a designer or player’s mental model of game rules, and whether that differs from the rules induced by the game’s implementation.
We are especially keen to receive submissions from game designers or game critics on potentially mechanizable formalisms for knowledge representation and reasoning. We also welcome (especially in the short paper format) surveys or reframings of existing work in related fields reoriented towards (video) games.
Format
The workshop will be a series of thematically grouped presentations followed by brief discussions, with longer small-group discussions in the afternoon.
Attendance
Attendance is open to all; at least one author of each accepted submission must be present at the workshop.
Submissions
EasyChair Submission Site
The workshop accepts two types of papers, all in AAAI format (references are not counted against page limits). Full papers are up to 6 pages and are expected to be accompanied by some evaluation or formal proof; short papers are between 3 and 4 pages, showing promising new directions, nascent ideas, or new applications of existing work. All submissions will be reviewed double-blind, so please take care to anonymize your submission.
Papers should be submitted via EasyChair.
Chair
Joseph C Osborn, University of California, Santa Cruz
(jcosborn@ucsc.edu)
Phone: +1 (585) 705 6309
Organizing Committee
Adam Summerville (University of California, Santa Cruz, asummerv@ucsc.edu), Matthew Guzdial (Georgia Institute of Technology, mguzdial3@gatech.edu)
Additional Information
Workshop URL

W11 — Plan, Activity, and Intent Recognition
Plan recognition, activity recognition, and intent recognition all involve making inferences about other actors from observations of their behavior, that is, their interaction with the environment and with each other. The observed actors may be software agents, robots, or humans. This synergistic area of research combines and unifies techniques from user modeling, machine vision, intelligent user interfaces, human/computer interaction, autonomous and multiagent systems, natural language understanding, and machine learning. It plays a crucial role in a wide variety of applications including: assistive technology, software assistants, computer and network security, behavior recognition, coordination in robots and software agents, and more.
This workshop seeks to bring together researchers and practitioners from diverse backgrounds, to share in ideas and recent results. It will aim to identify important research directions, opportunities for synthesis and unification of representations and algorithms for plan recognition.
This year’s workshop will be centered on application domains. This will include a focused discussion where we will present and compare the various representations common in the literature and applications. We believe this will work to help identify areas of synergy between different communities and to provide opportunities and incentives for future work.
Format
This 1-day workshop will be split 50/50 between research presentations, organized into topical sessions (topics to be decided based on submissions) and additional contents including two invited talks and a discussion panel.
Submissions
EasyChair Submission Site
All submissions should be submitted to the EasyChair submission site. All papers must be original. If a work was submitted to the main conference as well, it should be written in the title. We accept full paper submissions. Papers must be formatted in AAAI two-column, camera-ready style; see the 2018 AAAI Author Kit for details. Papers must be in trouble-free, high-resolution PDF format, formatted for US Letter (8.5″ x 11″) paper, using Type 1 or TrueType fonts. Submissions are anonymous, and must conform to the AAAI-18 instructions for double-blind review. Submissions may have up to 6 pages with page 6 containing nothing but references. The last page of final papers may contain text other than references, but all references in the submitted paper should appear in the final version, unless superseded.
Organizing Committee
Ms. Reuth Mirsky
Ben-Gurion University
Department of Software and Information Systems Engineering
POB 15050, Be’er Sheva, 8412001, Israel
Email: dekelr@post.bgu.ac.il
Ms. Sarah Keren
Faculty of Industrial Engineering and Management
Technion – Israel Institute of Technology
Technion City, Haifa 32000, Israel
Email: sarahn@technion.ac.il
Dr. Christopher Geib
Drexel University, College of Computing and Informatics
3141 Chestnut St., Philadelphia, PA 19104 USA
Email: cgeib@drexel.edu
Additional Information
Workshop URL

W012 — Planning and Inference
The workshop is focused on the problems of Stochastic Planning and Probabilistic Inference and the intimate connections between them. Both Planning and inference are core tasks in AI and the connections between them have been long recognized. However, much of the work in these subareas is disjoint. The last decade has seen many exciting developments with explicit constructions and reductions between planning and inference that aim for efficient algorithms for large scale problems and applications. The work in this area is distributed across many conferences, sub-communities, and sub-topics and varies from discrete to continuous problems, single versus multiagent problems, general versus spatial problems, propositional versus relational problems, model based planning versus reinforcement learning, and exact/optimal versus approximate versus heuristic solutions. Applications similarly vary for example from scheduling to sustainability and to robot control.
The goal of this workshop is to bring together researchers from all these areas and facilitate synergy and exchange of ideas: to discuss core ideas, techniques and algorithms that take advantage of the connection between planning and inference, identify opportunities and challenges for future work, and explore applications and how they can inform the development of such work.
The workshop will include invited talks by experts on planning and inference, contributed talks and a poster session, leaving room for discussion and interaction among participants. Current invited speakers include Rina Dechter, Marc Toussaint, and Pascal Van Hentenryck.
The workshop topic is broad and the intention of this first workshop is to enable interaction among the various sub-areas while keeping the focus on the interaction between planning and inference. Some basic questions include the following:

What are effective reductions from planning to inference?
What are effective inference algorithms for such problems?
What are the challenges in planning applications, and how does their structure help or interfere with the application of planning as inference?
Can generic inference algorithms be used directly for planning? or are we better off tailoring algorithms directly to the planning problem?
Can planning algorithms or ideas developed for them be used for general inference?
How do structured solutions, for example, lifted inference, lifted planning, spatial MDPs, cooperative multiagent systems, and approximations in continuous problems, translate across the planning/inference spectrum, and help improve scalability.
Success stories and challenges in using planning for inference or inference for planning.
These questions cut across theoretical foundations and practical applications.

Submissions
EasyChair Submission Site
We invite 4 types of submissions (in AAAI style):

Papers describing work in progress (up to 8 pages including references).
Review of mature work (from multiple papers) by the authors (up to 8 pages including references).
Papers recently published at other venues (1-page abstract with a link to the full paper).
Position papers (2 pages including references).

All papers should clearly explain how the work relates planning and inference.
Submissions of papers being reviewed for AAAI 2018, or at other venues are welcome since this is a nonarchival venue (and if published they can be replaced with a 1 page abstract). If such papers are currently under blind review, please anonymize the submission.
Submissions should be made to the EasyChair submission site. Additional information is available at the workshop website.
Organizing Committee
Roni Khardon (Tufts University, USA), Akshat Kumar (Singapore Management University, Singapore), Alex Ihler (University of California, Irvine, USA)
Program Committee
Christopher Amato, Alan Fern, Vaishak Belle, Kristian Kersting, Qiang Liu, Radu Marinescu, Denis Maua, Sriraam Natarajan, Gerhard Neumann, Pascal Poupart, David Poole, Regis Sabbadin, Scott Sanner, Prasad Tadepalli, Jan-Willem van de Meent
Additional Information
Workshop URL

W13 — Preference Handling
Preferences are a central concept of decision making. As preferences are fundamental for the analysis of human choice behavior, they are becoming of increasing importance for computational fields such as artificial intelligence, databases, and human-computer interaction as well as for their respective applications.
The workshop will provide a forum for presenting advances in preference handling and for exchanging experiences between researchers facing similar questions, but coming from different fields.
Topics
The workshop on Advances in Preference Handling addresses all computational aspects of preference handling. This includes methods for the elicitation, learning, modeling, representation, aggregation, and management of preferences and for reasoning about preferences. The workshop studies the usage of preferences in computational tasks from decision making, database querying, web search, personalized human-computer interaction, personalized recommender systems, e-commerce, multiagent systems, game theory, social choice, combinatorial optimization, planning and robotics, automated problem solving, perception and natural language understanding and other computational tasks involving choices. The workshop seeks to improve the overall understanding of and best methodologies for preferences in order to realize their benefits in the multiplicity of tasks for which they are used. Another important goal is to provide cross-fertilization between the numerous subfields that work with preferences.

Preference handling in artificial intelligence
Preference handling in database systems
Preference handling in multiagent systems
Applications of preferences
Preference elicitation
Preference representation and modeling
Properties and semantics of preferences
Practical preferences

Format
The program will consist of presentations of peer-reviewed papers, panel discussions about future challenges, and an invited talk.
Attendance
At least one author from each accepted paper must register for the workshop. An attendance of approximately 40 people is expected. All authors as well as researchers interested in the field are encouraged to participate.
Submissions
EasyChair Submission Site
Papers must be formatted according to the AAAI Formatting Instructions and up to 6 pages in length + 1 page for references in PDF format. Authors can choose between an anonymized or nonanonymized submission. Authors should submit to the EasyChair submission site.
Chair
Kristen Brent Venable
Department of Computer Science, Tulane University
6823 St. Charles Avenue, New Orleans LA 70118, (USA)
E-mail: kvenabl@tulane.edu | Phone: +1 214 364 0739
Organizing Committee
Markus Endres, University of Augsburg (Germany), endres@informatik.uni-augsburg.de Nicholas Mattei, Cognitive Computing, IBM Research, n.mattei@ibm.com Andreas Pfandler, TU Wien (Austria) and University of Siegen (Germany), pfandler@dbai.tuwien.ac.at
Additional Information
Workshop URL

W14 — Reasoning and Learning for Human-Machine Dialogues
Natural conversation is a hallmark of intelligent systems. Unsurprisingly, dialog systems have been a key sub-area of AI for decades. Their most recent form, chatbots, which can engage people in natural conversation and are easy to build in software, have been in the news a lot lately. There are many platforms to create dialogs quickly for any domain based on simple rules. Further, there is a mad rush by companies to release chatbots to show their AI capabilities and gain market valuation. However, beyond basic demonstration, there is little experience in how they can be designed and used for real-world applications needing decision making under constraints (for example, sequential decision making). The workshop will thus be timely to help chatbots realize their full potential.
Furthermore, there is upcoming interest and need for innovation in human-technology-interaction as addressed in the context of companion technology. Here, the aim is to implement technical systems that smartly adapt their functionality to their users’ individual needs and requirements and are even able to solve problems in close co-operation with human users. To this end, they need to enter into a dialog and should be able to convincingly explain their suggestions and their decision making behavior.
From research side, statistical and machine learning methods are well entrenched for language understanding and entity detection. However, the wider problem of dialog management is unaddressed with mainstream tools supporting rudimentary rule-based processing. There is an urgent need to highlight the crucial role of reasoning methods, like constraints satisfaction, planning and scheduling, and learning working together with them, can play to build an end-to-end conversation system that evolves over time. From practical side, conversation systems need to be designed for working with people in a manner that they can explain their reasoning, convince humans about choices among alternatives, and can stand up to ethical standards demanded in real life settings.
With these motivations, some areas of interest for the workshop (but not limited to) are as follows:
Dialog Systems

Early experiences with implemented dialog systems
Evaluation of dialog systems, metrics
Open domain dialog and chat systems
Task-oriented dialogs
Style, voice and personality in spoken dialogue and written text
Novel methods for NL generation for dialogs

Reasoning

Domain model acquisition, especially from unstructured text
Plan recognition in natural conversation
Planning and reasoning in the context of dialog systems

Learning

Learning to reason
Learning for dialog management
End2end models for conversation
Explaining dialog policy

Practical considerations

Ethical issues with reasoning in dialog systems
Corpora, tools and methodology for dialogue systems

The intended audience includes students, academic researchers and practitioners with an industrial background from the AI subareas of dialog systems, natural language processing, learning, reasoning, planning, HCI, ethics and knowledge representation.
Submissions
EasyChair Submission Site
Papers must be formatted in AAAI two-column, camera-ready style. Regular research papers may be no longer than 7 pages, where page 7 must contain only references, and no other text whatsoever. Short papers, which describe a position on the topic of the workshop or a demonstration/tool, may be no longer than 4 pages, references included.
Organizing Committee
Biplav Srivastava (IBM Research, USA), Susanne Biundo (University of Ulm, Germany), Ullas Nambiar (Zensar Labs, India), Imed Zitouni (Microsoft AI+R, USA)
Additional Information
Workshop URL

W15 — SmartIoT: AI Enhanced IoT Data Processing for Intelligent Applications
Building intelligent applications for everyday use is the long-cherished aim of Artificial Intelligence (AI). With numerous devices deployed and used in day-to-day applications including mobile phones, tablets, wearable and other connected sensing and actuation devices, collectively referred to as the Internet of Things (IoT), there is an unprecedented opportunity to develop contextually intelligent applications with far-reaching societal implications. They can deliver fine-grained services in various areas such as healthcare, manufacturing, transportation and social good. These intelligent applications and services, however, could also pose privacy, security and trust issues and risks.
The purpose of the workshop is to discuss how AI techniques can help consume data from IoT to build intelligent applications. The workshop aims to bring together academic researchers and industry practitioners who are interested in advancing the state-of-the-art not merely in their specific subfields of AI, but also in multidisciplinary areas in order to solve problems with business as well as societal impacts.
Topics
By 2020, 50 billion Internet of Things (IoT) are expected to be deployed. That is, massive number of IoTs will be continuously or periodically make the data the generate available on the internet. This workshop will explore the possibilities of using Artificial Intelligence (AI) including machine learning, NLP, and semantic Web techniques to create new solutions that exploit the IoT generated data. The workshop will provide an opportunity to share new findings, exchange ideas, discuss research challenges, present demonstration of unique applications and report latest findings. The workshop will cover a range of topics including, but not limited to the following:

Semantic sensor (IoT) data
Information extraction from real-world data streams
Machine Learning, knowledge-enabled and spatio-temporal processing applied IoT data
AI techniques for intelligent IoT data fusion
Context-aware applications and services
Linked open IoT data, repositories of semantic IoT data
Semantic IoT data management
Chatbots using NLP and IoT data
Reasoning with IoT data, including semantic, cognitive and perceptual computing
Ethical and privacy issues with IoT data
Human computer interface (HCI) issues, data visualization
Applications in smart city, healthcare, transportation, energy, public safety, disaster coordination and other areas

Submissions
EasyChair Submission Site
Papers must be formatted in AAAI two-column, camera-ready style. Regular research papers may be no longer than 7 pages, where page 7 must contain only references, and no other text whatsoever. Short papers, which describe a position on the topic of the workshop or a demonstration/tool, may be no longer than 4 pages, references included. Submission should be made to the Easychair submission site.
Cochairs
Payam Barnaghi (University of Surrey, UK), Amelie Gyrard (Univ Lyon, MINES Saint-Etienne, CNRS, Laboratoire Hubert Curien, Saint-Etienne, France), Amit Sheth (Kno.e.sis, Wright State University, USA), Biplav Srivastava (IBM, USA)
Program Committee
Manfred Hauswirth (Technical University of Berlin/Fraunhofer FOKUS), Monika Solanki (University of Oxford, UK), Septimiu Nechifor (Siemens, Romania), Andreas Emrich (DFKI/University of Saarbrucken, Germany), Maria Bermudez (University of Granada, Spain), Frieder Ganz (Adobe, Germany), Cory Henson (Bosch Research & Technology, USA), Paolo Bellavista (University of Bologna, Italy), Ajit Joakar (City of London, UK), Edith Ngai (Uppsala University, Sweden), Fangming Liu (Huazhong University of Science and Technology, China), Yasmin Fathy (University of Surrey, UK), Danh Le Phuoc (TU Berlin, Germany), Josiane Xavier Parreira (SIEMENS AG, Austria), Maria Esther Vidal (Universidad Simon Bolivar, Venezuela), Simon Mayer (Siemens, USA), Pankesh Patel (Fraunhofer, USA), Ali Intizar (Insight-NUIG, Ireland), Gyu Myoung Lee (Liverpool John Moores University, UK), Emil Lupu (Imperial College London, UK), Bin Guo (Northwestern Polytechnical University, China), Koji Zettsu (NICT, Japan), Kerry Taylor (The Australian National University, Australia), Axel Ngonga (University of Leipzig, Germany), Xiang Su (University of Oulu, Finland), Philippe Gautier (Pierre and Marie Curie University, France)
Additional Information
Workshop URL
Email: smartiot2018@easychair.org

W16 — Statistical Modeling of Natural Software Corpora
The proliferation of open-source projects has led to large amounts of source code and related artifacts: arguably, the rich and open resources associated with software — including open source repositories, Q/A sites, change histories, and communications between developers — are the richest and most detailed information resource for any technical area. Recently it has been discovered that natural, human-produced software has many interesting statistical regularities. As a consequence, code corpora, just like natural language corpora, are amenable to statistical modeling, and a number of software tasks such as coding, testing, porting, bug-patching and others are potentially enhanced by the use of these statistical models.
Topics
This interdisciplinary workshop will explore issues related to the statistical modeling of software corpora, including topics such as modeling repetitiveness in source code; use of language models for the code suggestion in IDEs; using probabilistic grammars to mine programming idioms; statistical methods for type inference in a dynamically typed languages; statistical machine translation for porting applications between programming languages, or minifying Javascript; using statistical language models to find bugs; or statistical methods for automatic code patching, code summarization, code retrieval, code annotation, or test generation.
The workshop follows several earlier workshops on this topic at Microsoft Research, Dagstuhl event, and SIGSOFT FSE. From NSF, some funding is available for US travelers to the workshop, especially students and members of under-represented groups, and researchers that might not normally attend AAAI.
Submissions
EasyChair Submission Site
We invite 2-4 page position paper submissions. Submissions will be reviewed by the workshop committee. Please submit to the EasyChair submission site.
Additional Information
Workshop URL
",2018
"
This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2018 AAAI
",2018
"AAAI-19 Workshop Program
January 27-28, 2019
Honolulu, Hawaii, USA

2019 AAAI Author Kit

AAAI is pleased to present the AAAI-19 Workshop Program. Workshops will be held Sunday and Monday, January 27-28, 2019 at the Hilton Hawaiian Village Hotel in Honolulu, Hawaii, USA. Exact locations and dates for the workshops will be determined in December. The AAAI-19 workshop program includes 16 workshops covering a wide range of topics in artificial intelligence. Workshops are one day unless noted otherwise in the individual description. Participation in each workshop is generally limited to 25-65 participants, and participation is usually by invitation from the workshop organizers. However, most workshops also allow general registration by other interested individuals. Please note that there is a separate registration fee for attendance at a workshop. Workshop registration is available for workshop only registrants or for AAAI-19 technical registrants at a discounted rate. Registration information will be mailed directly to all invited participants in November.",2019
"Important Dates for Workshop Organizers


November 5, 2018: Submissions due (unless noted otherwise)
November 26, 2018: Notification of acceptance
January 27-28, 2019: AAAI-19 Workshop Program
",2019
" 

W1: Affective Content Analysis: Modeling Affect-in-Action
W2: Agile Robotics for Industrial Automation Competition (ARIAC)
W3: Artificial Intelligence for Cyber Security (AICS)
W4: Artificial Intelligence Safety
W5: Dialog System Technology Challenge (DSTC7)
W6: Engineering Dependable and Secure Machine Learning Systems
W7: Games and Simulations for Artificial Intelligence
W8: Health Intelligence
W9: Knowledge Extraction from Games
W10: Network Interpretability for Deep Learning
W11: Plan, Activity, and Intent Recognition (PAIR) 2019
W12: Reasoning and Learning for Human-Machine Dialogues (DEEP-DIAL 2019)
W13: Reasoning for Complex Question Answering
W14: Recommender Systems Meet Natural Language Processing
W15: Reinforcement Learning in Games
W16: Reproducible AI
",2019
"
W01 — Affective Content Analysis: Modeling Affect-in-Action (AffCon 2019)
Affect analysis of content to measure emotions and its experiences is an upcoming, multidisciplinary research area, which still has little cross-disciplinary collaboration. The artificial intelligence (AI) and computational linguistics (CL) community are making strides in identifying and measuring affect from user signals, especially language, while the human-computer interaction (HCI) community has independently explored affect through user experience evaluations. Consumer psychology and marketing have pursued a different direction to ground affect in its theoretical underpinnings as well as their real-world applications.
The second Affective Content Analysis workshop aims to bring together researchers from computer science, psychology, and marketing science for stimulating discussions on affect, with a focus on language and text. We are also organizing a shared task with a new corpus, to spur the development of new approaches and methods for affect identification.
Topics
The theme of AffCon 2019 is “Modeling Affect in Action.” The word affect is used to refer to emotion, sentiment, mood, and attitudes including subjective evaluations, opinions, and speculations. Psychological models of affect have been adopted by other disciplines to conceptualize and measure users’ opinions, intentions, and expressions. However, the context-specific characteristics of human affect suggest the need to measure in ways that recognize multiple interpretations of human responses.
We invite papers that offer modeling and measurement of affect and identify the best affect–related dimensions to study consumer behavior. In turn, that allows data models to be more informed in representing behaviors and hence effective in guiding decisions and actions by firms. We welcome submissions on topics including – but not limited to – the following:

Deep learning-based models for affect modeling in content (image, audio, and video)
Affect-aware text generation
Spoken and formal language comparison
Measurement and evaluation of affective content
Modeling consumer’s affect reactions
Affect lexica for online marketing communication
Affective commonsense reasoning
Affective human-agent, -computer, and-robot interaction
Multimodal emotion recognition and sentiment analysis
Computational models for consumer behavior theories
Psycho-linguistics, including stylometrics and typography
Bridging the gap between consumer psychology and computational linguistics
Consumer psychology at scale from big data
Testing consumer behavior theories with big data
Psycho-demographic profiling

We especially invite papers investigating multiple related themes, industry papers, and descriptions of running projects and ongoing work. To address the scarcity of standardized baselines, datasets, and evaluation metrics for cross-disciplinary affective content analysis, submissions describing new language resources, evaluation metrics, and standards for affect analysis and understanding are also strongly encouraged.
Shared Task: CL-Aff: In Pursuit of Happiness
AI and machine learning (ML) algorithms are leading to abundant models with high prediction accuracies for various affect-related tasks. However, the source of specific human expressions or interpretation of model performances is still unexplored and unknown.
We invite submissions for the Computational Linguistics Affect Understanding (CL-Aff) Shared Task around identifying causes of happiness. The details of the task are provided on the website.
Format
This full-day workshop will have several prominent interdisciplinary invited speakers from the fields of linguistics, psychology, and marketing science to lead the presentation sessions. In a poster session in the afternoon, a few papers deemed more suited for a poster than a presentation will be invited to display a poster or a demo. We will end the workshop with a fishbowl-style discussion among the organizers and participants to decide on future directions for the workshop and the research community.
Submissions
EasyChair Submission URL
Submissions should be made via EasyChair and must follow the formatting guidelines for AAAI-2019 (use the AAAI Author Kit). All submissions must be anonymous and conform to AAAI standards for double-blind review. Both full papers (8 page long including references) and short papers (4 page long including references) that adhere to the 2-column AAAI format will be considered for review.
Cochairs
Niyati Chhaya, primary contact (Adobe Research, nchhaya@adobe.com), Kokil Jaidka (University of Pennsylvania, jaidka@sas.upenn.edu), Lyle Ungar (University of Pennsylvania, ungar@cis.upenn.edu), Atanu R Sinha (Adobe Research, atr@adobe.com)
Additional Information
Workshop URL

W02 — Agile Robotics for Industrial Automation Competition (ARIAC)
The objective of the Agile Robotics for Industrial Automation Competition (ARIAC) is to test the agility of industrial robot systems, with the goal of enabling industrial robots on the shop floors to be more productive, more autonomous, and to require less time from shop floor workers. In this context, we define agility broadly to address: Failure identification and recovery, where robot can detect failures in a manufacturing process and automatically recover from those failures; Automated planning, to minimize (or eliminate) the up-front robot programming time when a new product is introduced; Fixtureless environment, where robots can sense the environment and perform tasks on parts that are not in predefined locations; Plug and play robots, where robots from different manufacturers can be swapped in and out without the need for reprogramming.
The competition is a simulation-based contest designed to encourage robot agility research, as well as facilitate technology transfer. The competition has completed its second year and awarded over $17,000 worth of prize money to the winners. We had over 50 teams register for the competition. Additional information regarding the competition can be found at www.nist.gov/ariac.
The objectives of the AAAI workshop are: Describe the overall goal of the competition, how it was implemented, and information about the teams that participated; Describe the ARIAC simulation environments, challenges, and metrics; Present results from the competition and associated findings; Best performing teams to describe their approaches to address the challenges; Opportunity for all teams to describe their approaches and get feedback, through poster presentations; Lessons learned from the competition and get feedback from the participants; Determine the direction for future competitions though presentations from industry and feedback from the community; Provide a forum for other teams to get involved, learning from existing teams and get trained on the software via a hands-on tutorial at the end of the workshop.
Topics
Topics of interest include robot agility, robot error recovery, dynamic replanning, simulation, gazebo, robot planning and control, and robot operating system (ROS).
Workshop Duration and Format
This one-day workshop will be a mix of presentations from the participating teams, invited talks from industry representatives, and general discussion about the potential future direction of the ARIAC Competitions.
Submissions
Please see the supplemental website for submission instructions. Submissions should be directed to:
Workshop Chair Anthony Downs National Institute of Standards and Technology (NIST) 100 Bureau Drive, Stop 8230 Gaithersburg, MD 20877 Phone: 1-301-975-3436 Fax: 1-301-990-9688 Email: anthony.downs@nist.gov
Organizing Committee
Dr. William Harrison, Anthony Downs (Main) , Craig Schlenoff (National Institute of Standards and Technology (NIST))
Additional Information
Workshop URL: http://www.nist.gov/ariac

W03 — Artificial Intelligence for Cyber Security (AICS)
The Artificial Intelligence for Cyber Security workshop will address AI technologies and their applications, such as machine learning, game theory, natural language processing, knowledge representation, automated and assistive reasoning, and human machine interactions. AICS 2019 will emphasize research and applications of techniques to attack and defend machine learning systems (a.k.a. adversarial learning), especially in the context of cyber security.
Machine learning capabilities have recently been shown to offer astounding ability to automatically analyze and classify large amounts of data in complex scenarios, in many cases matching or surpassing human capabilities. However, it has also been widely shown that these same algorithms are vulnerable to attacks, known as adversarial learning attacks, which can cause the algorithms to misbehave or reveal information about their inner workings. In general, attacks take three forms: 1) data poisoning attacks inject incorrectly or maliciously labeled data points into the training set so that the algorithm learns the wrong mapping, 2) evasion attacks perturb correctly classified input samples just enough to cause errors in classification, and 3) inference attacks that repeatedly test the trained algorithm with edge-case inputs in order to reveal the previously hidden decision boundaries. As machine learning-based AI capabilities become incorporated into facets of everyday life, including protecting cyber assets, the need to understand adversarial learning and address it becomes clear.
Challenge Problem *
This year we are asking the AI for cyber security community to submit solutions to a challenge problem focused on solving an adversarial attack scenario based on redacted data. For complete information about the challenge problem, please see http://www-personal.umich.edu/~arunesh/AICS2019/challenge.html.
Understanding and addressing challenges of adversarial learning requires collaboration between several different research and development communities, including the AI, cyber security, game theory, machine learning, and formal reasoning communities. AICS is structured to encourage a lively exchange of ideas between researchers in these communities.
* Challenge Problem sponsored by Crowdstrike
Submissions
Submissions are due by November 5, 2018 and can take one of two forms (up to 8 pages in AAAI format):

Full-length papers
Challenge problem papers

Organizing Committee
William W. Streilein (MIT Lincoln Laboratory, MA, USA), David R. Martinez (MIT Lincoln Laboratory, MA, USA), Howard Shrobe (MIT/CSAIL, MA, USA), Arunesh Sinha (University of Michigan, MI, USA), Jason Matterer (MIT Lincoln Laboratory, MA, USA)
Administrative Contact: Brent Cassella, brent.cassella@ll.mit.edu
Additional Information
Workshop URL: http://www-personal.umich.edu/~arunesh/AICS2019

W04 — Artificial Intelligence Safety (SafeAI 2019)
Safety in Artificial Intelligence (AI) should not be an option, but a design principle. However, there are different levels of safety, different ethical standards and values, and different degrees of liability, for which we face trade-offs or alternative solutions. These choices can only be analyzed holistically if we integrate the technological and the ethical perspectives into the engineering problem, and consider both the theoretical and practical challenges for AI safety. This view must cover a wide range of AI paradigms, including systems that are specific for a particular application, and also those that are more general, and can lead to unanticipated potential risks. We must also bridge short-term with long-term issues, idealistic with pragmatic solutions, operational with policy issues, and industry with academia, to really build, evaluate, deploy, operate and maintain AI-based systems that are truly safe.
This workshop seeks to explore new ideas on AI safety with particular focus on addressing the following questions:

What is the status of existing approaches in ensuring AI and Machine Learning (ML) safety and what are the gaps?
How can we engineer trustable AI software architectures?
How can we make AI-based systems more ethically aligned?
What safety engineering considerations are required to develop safe human-machine interaction?
What AI safety considerations and experiences are relevant from industry?
How can we characterize or evaluate AI systems according to their potential risks and vulnerabilities?
How can we develop solid technical visions and new paradigms about AI Safety?
How do metrics of capability and generality, and the trade-offs with performance affect safety?

The main interest of the proposed workshop is to look holistically at AI and safety engineering, jointly with the ethical and legal issues, to build trustable intelligent autonomous machines.
Topics
Contributions are sought in (but are not limited to) the following topics:

Safety in AI-based system architectures
Continuous V&V and predictability of AI safety properties
Runtime monitoring and (self-)adaptation of AI safety
Accountability, responsibility and liability of AI-based systems
Effect of uncertainty in AI safety
Avoiding negative side effects in AI-based systems
Role and effectiveness of oversight: corrigibility and interruptibility
Loss of values and the catastrophic forgetting problem
Confidence, self-esteem and the distributional shift problem
Safety of Artificial General Intelligence (AGI) systems and the role of generality
Reward hacking and training corruption
Self-explanation, self-criticism and the transparency problem
Human-machine interaction safety
Regulating AI-based systems: safety standards and certification
Human-in-the-loop and the scalable oversight problem
Evaluation platforms for AI safety
AI safety education and awareness
Experiences in AI-based safety-critical systems, including industrial processes, health, automotive systems, robotics, critical infrastructures, among others

Format
To deliver a truly memorable event, we will follow a highly interactive format that will include invited talks and thematic sessions. The thematic sessions will be structured into short pitches and a common panel slot to discuss both individual paper contributions and shared topic issues. Three specific roles are part of this format: session chairs, presenters and paper discussants. The workshop will be organized as a full day meeting.
Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
You are invited to submit short position papers (2-4 pages), full technical papers (6-8 pages) or proposals of technical talk (up one-page abstract). Manuscripts must be submitted as PDF files via EasyChair online submission system: https://easychair.org/conferences/?conf=SafeAI2019
Please keep your paper format according to AAAI Formatting Instructions (two-column format). The AAAI author kit can be downloaded from: https://www.aaai.org/Publications/Templates/AuthorKit19.zip
Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper). The workshop follows a single-blind reviewing process. However, we will also accept anonymized submissions.
Chairs
Mauricio Castillo-Effen (Lockheed Martin, USA), Huáscar Espinoza (CEA LIST, France), Seán Ó hÉigeartaigh (University of Cambridge, UK), Xiaowei Huang (University of Liverpool, UK), José Hernández-Orallo (Universitat Politècnica de València, Spain)
For a full listing of the program committee, please refer to the supplemental workshop website.
Additional Information
Workshop URL: http://www.safeai2019.org

W05 — Dialog System Technology Challenge (DSTC7)
DSTC, the Dialog System Technology Challenge, has been a premier research competition for Dialog Systems since its inception in 2013. This workshop is the 7th edition in the series of DSTC challenges. In 2018, DSTC6 shifted the focus to end-to-end dialog tasks, in order to explore the issue of applying end-to-end technologies to Dialog Systems in a pragmatic way. Given the remarkable success of the first six editions of DSTC, we are organizing the seventh edition of DSTC this year.
DSTC7 has the following three tracks:
1) Noetic End-to-End Response Selection
Organized by Lazaros Polymenakos and Chulaka Gunasekara (IBM Research AI, USA), and Walter S. Lasecki and Jonathan K. Kummerfeld (University of Michigan, USA)
This challenge consists of sub-tasks on two datasets, one focused but small (course advising) and the other more diverse but large (Ubuntu support). In each, participants select the correct next utterances from a set of candidates’ and even indicate that none of the proposed utterances is a good candidate. The objective is to push utterance classification towards real world problems.
2) End-to-End Conversation Modeling: Moving beyond Chitchat – Sentence Generation
Organized by Michel Galley, Chris Brockett, Bill Dolan, and Jianfeng Gao (Microsoft AI&R)
This track proposes an end-to-end conversational modeling task, where the goal is to generate conversational responses that go beyond chitchat, by injecting informational responses that are grounded in external knowledge.
3) Audio Visual Scene-Aware Dialog (AVSD)
Organized by Chiori Hori and Tim K. Marks (Mitsubishi Electric Research Laboratories), and Devi Parikh and Dhruv Batra (Georgia Tech School of Interactive Computing)
This track proposes an end-to-end audio-visual scene-aware dialog system, where the goal is to understand scenes in order to have conversations with the users about the objects and events around them.
For the final evaluation, the test sets will be provided on September 10 and the results will be submitted by October 1. Currently roughly 190 participants are registered for DSTC7. We will have a one-day wrap-up workshop at AAAI-19 to review the state-of-the-art systems, share novel approaches to the DSTC7 tasks, and discuss future directions for dialog technology. We will invite system papers reporting the systems submitted to DSTC7, general technical papers for end-to-end dialog technologies and keynote speakers who have developed cutting-edge approaches to data-driven dialog systems. You can find the information of the previous workshop, DSTC6, at http://workshop.colips.org/dstc6/.
Organizing Committee
Workshop Chair: Chiori Hori (Mitsubishi Electric Research Laboratories (MERL), USA) Challenge Chair: Koichiro Yoshino (Nara Institute of Science and Technology (NAIST), Japan) Publication Chair: Julien Perez (Naver Labs Europe, France) Publicity Chair: Luis Fernando D’Haro )Technical University of Madrid, Spain)
Contact information: dstc7-organizer@is.naist.jp
Additional Information Workshop URL: http://workshop.colips.org/dstc7/

W06 — Engineering Dependable and Secure Machine Learning Systems
Nowadays, machine learning solutions are widely deployed. Like other systems, ML systems must meet quality requirements. However, ML systems may be non-deterministic; they may re-use high-quality implementations of ML algorithms; and, the semantics of models they produce may be incomprehensible. Consequently, standard notions of software quality and reliability such as deterministic functional correctness, black box testing, code coverage, and traditional software debugging become practically irrelevant for ML systems. This calls for novel methods and new methodologies and tools to address quality and reliability challenges of ML systems.
In addition, broad deployment of ML software in networked systems inevitably exposes the ML software to attacks. While classical security vulnerabilities are relevant, ML techniques have additional weaknesses, some already known (e.g., sensitivity to training data manipulation), and some yet to be discovered. Hence, there is a need for research as well as practical solutions to ML security problems.
With these in mind, this workshop solicits original contributions addressing problems and solutions related to dependability, quality assurance and security of ML systems. The workshop combines several disciplines, including ML, software engineering (with emphasis on quality), security, and algorithmic game theory. It further combines academia and industry in a quest for well-founded practical solutions.
Topics
Topics of interest include, but are not limited, to the following:

Software engineering aspects of ML systems and quality implications
Testing and debugging of ML systems
Quality implication of ML algorithms on large-scale software systems
Case studies that highlight quality issues of ML solutions
Correctness of data abstraction, data trust
ML techniques to meet security and quality
Size of the training data, implied guaranties
Application of classical statistics to ML systems quality
Sensitivity to data distribution diversity and distribution drift
The effect of labeling costs on solution quality (semi-supervised learning)
Reliable transfer learning
Vulnerability, sensitivity and attacks against ML
Adversarial ML and adversary-based learning models
Strategy-proof and stable ML algorithms

Submissions
We solicit original papers in two formats – full (8 pages) and short (4 pages, work in progress), in AAAI format. Submission is via EasyChair at the URL below. All authors of accepted papers will be invited to participate. The workshop will include paper presentation sessions. Full papers are allocated 20m presentation and 10m discussion. Short papers 10-minute presentation, plus 5-minute discussion. The last session will be a panel discussion.
Submission site: https://easychair.org/conferences/?conf=edsmls2019
Workshop Chairs
Eitan Farchi (IBM Research, Haifa, farchi@il.ibm.com), Onn Shehory (Bar Ilan University, onn.shehory@biu.ac.il)
Additional Information
Workshop URL: https://sites.google.com/view/edsmls2019/home

W07 — Games and Simulations for Artificial Intelligence
Over the past several years, games and simulations have become a powerful tool for AI research. They have become the default testing grounds for new algorithms thanks to platforms such as Mujoco, Arcade Learning Environment, OpenAI Gym, VizDoom, DeepMind Lab, Facebook House3D, Allen Institute AI2-Thor, Microsoft AirSim, and Unity ML-Agents toolkit. Additionally, they are a mechanism for generating large amounts of training data for learning complex models for tasks such as 3D pose estimation, physics modeling, natural language instruction following, embodied question answering and robotics. Due to the physical and visual realism of several of these platforms, complex models can be trained in a virtual setting and then transferred to an agent or robot in the real world with minor fine-tuning. Recent examples include learning dexterous manipulation behaviors for a robotic hand and training self-driving cars.
This workshop aims to bring together researchers across artificial intelligence interested in the use of games and simulation platforms. This includes the creation of platforms, environments, data sets or benchmarks; novel tasks and algorithms that leverage those platforms; adapting models learned within those platforms for the real world where applicable.
Topics
We invite high-quality paper submissions on topics including, but not limited to, the following:

Novel simulation platforms, data sets and challenges for evaluating algorithms. This includes games and environments with physical and visual-realism.
Mechanisms for learning synthetic data set generation
Novel tasks that can be solved using simulation platforms
Algorithms for learning from large data sets generated by simulation platforms. This includes distributed algorithms that can leverage multiple simulation instances.
Mechanisms for minimizing the reality gap between simulations and the real world. This can be due to better adaptations and fine-tuning or enabling more realistic simulation environments.

Format
The workshop will be a full-day and will include a mix of invited speakers, peer-reviewed papers (talks and poster sessions) and will conclude with a panel discussion.
Attendance
Attendance is open to all; at least one author of each accepted submission must be present at the workshop.
Submissions
EasyChair Submission URL: https://easychair.org/conferences/?conf=gamesim2019
Submissions of technical papers can be up to 8 pages excluding references and appendices. Short or position papers of 2 to 4 pages are welcome. All papers must be submitted in PDF format, using the AAAI author kit. Papers will be peer-reviewed and selected for oral or poster presentations at the workshop.
Organizers
Marwan Mattar (Unity Technologies; marwan@unity3d.com), Roozbeh Mottaghi (Allen Institute for Artificial Intelligence), Julian Togelius (NYU Game Innovation Lab), Danny Lange (Unity Technologies)
Additional Information
Workshop URL: https://www.gamesim.ai

W08 — Health Intelligence (W3PHIAI-19)
Public health authorities and researchers collect data from many sources and analyze these data together to estimate the incidence and prevalence of different health conditions, as well as related risk factors. Modern surveillance systems employ tools and techniques from artificial intelligence and machine learning to monitor direct and indirect signals and indicators of disease activities for early, automatic detection of emerging outbreaks and other health-relevant patterns. To provide proper alerts and timely response public health officials and researchers systematically gather news, and other reports about suspected disease outbreaks, bioterrorism, and other events of potential international public health concern, from a wide range of formal and informal sources. Given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. This is especially the case for non-traditional online resources such as social networks, blogs, news feed, twitter posts, and online communities with the sheer size and ever-increasing growth and change rate of their data. Web applications along with text processing programs are increasingly being used to harness online data and information to discover meaningful patterns identifying emerging health threats. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real-time data on epidemics.
Moreover, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork between patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All of these changes require novel solutions and the AI community is well positioned to provide both theoretical- and application-based methods and frameworks. The goal of this workshop is to focus on creating and refining AI-based approaches that (1) process personalized data, (2) help patients (and families) participate in the care process, (3) improve patient participation, (4) help physicians utilize this participation in order to provide high quality and efficient personalized care, and (5) connect patients with information beyond those available within their care setting. The extraction, representation, and sharing of health data, patient preference elicitation, personalization of “generic” therapy plans, adaptation to care environments and available health expertise, and making medical information accessible to patients are some of the relevant problems in need of AI-based solutions.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. The scope of the workshop includes, but is not limited to, the following areas:

Knowledge representation and extraction
Integrated health information systems
Patient education
Patient-focused workflows
Shared decision making
Geographical mapping and visual analytics for health data
Social media analytics
Epidemic intelligence
Predictive modeling and decision support
Semantic web and web services
Biomedical ontologies, terminologies, and standards
Bayesian networks and reasoning under uncertainty
Temporal and spatial representation and reasoning
Case-based reasoning in healthcare
Crowdsourcing and collective intelligence
Risk assessment, trust, ethics, privacy, and security
Sentiment analysis and opinion mining
Computational behavioral/cognitive modeling
Health intervention design, modeling and evaluation
Online health education and e-learning
Mobile web interfaces and applications
Applications in epidemiology and surveillance (for example, bioterrorism, participatory surveillance, syndromic surveillance, population screening)

Format
The workshop will be one and a half days consisting of a welcome session, keynote and invited talks, full/short paper presentations, demos, posters, and a panel discussion.
Submissions
We invite researchers and industrial practitioners to submit their original contributions following the AAAI format through EasyChair (https://easychair.org/conferences/?conf=w3phiai19). Three categories of contributions are sought: full-research papers up to 8 pages; short papers up to 4 pages; and posters and demos up to 2 pages.
Organizing Committee
Arash Shaban-Nejad, Co-chair, (The University of Tennessee Health Science Center – Oak-Ridge National Lab (UTHSC-ORNL) Center for Biomedical Informatics, ashabann@uthsc.edu); Martin Michalowski, Co-chair, (University of Minnesota – Twin Cities, martinm@umn.edu); Szymon Wilk, (Poznan University of Technology); David L. Buckeridge, (McGill University); John S. Brownstein, (Boston Children’s Hospital, Harvard University); Byron C. Wallace, (Northeastern University); Michael J. Paul, (The University of Colorado Boulder)
Additional Information
Workshop URL: http://w3phiai2019.w3phi.com/

W09 — Knowledge Extraction from Games
Knowledge Extraction from Games (KEG) is a workshop exploring questions of and approaches to the automated extraction of knowledge from games. We use knowledge in the broadest possible sense, including but not limited to design patterns, game rules, character graphics, environment maps, music and sound effects, high-level goals or heuristic strategies, transferable skills, aesthetic standards and conventions, or abstracted models of games.
Games can be understood as simplified models of aspects of reality. They therefore provide useful structuring information for reasoning tasks and provide interesting environments for knowledge extraction and specification recovery—environments like video games, board games, and informal simulations of reality. For example, tasks like quadcopter control and stock market analysis can be understood as games.
Topics
Some examples of work that would be appropriate for KEG include:

Contextual query-answering in games where non-player characters (or visual cues in environment design) offer hints to solve problems
Extracting architectural information from game level layouts
Transfer learning, analogical reasoning, or goal reasoning within or between games or game levels
Game-playing agents which can explain their own actions or policy in terms of the game’s rules
Learning the rules of a game from observation, or learning higher-level rules or goals automatically

KEG unifies these research areas and communities whose goals overlap but whose work mostly proceeds in parallel—planning, general (video) game playing, knowledge representation and reasoning, knowledge extraction, goal reasoning, computer-aided design, and others.
We also hope to include subject experts in game design and criticism; their deep knowledge of the creation and analysis of these highly emergent dynamical systems could inform knowledge representation and problem formulation.
Submissions
KEG will accept a mix of two types of papers (references are not counted against page limits): Full papers are 6-8 pages and are expected to be accompanied by some evaluation or formal proof. Short papers are up to 4 pages, showing promising new directions, nascent ideas, or new applications of existing work. We encourage authors to take whatever space they need; papers will be judged on the merit of their ideas, not length.
KEG 2019 is dedicated to a harassment-free workshop experience for everyone. Our anti-harassment policy can be found on our website.
Organizing Committee
Joseph C. Osborn (Pomona College), Samuel Snodgrass (Drexel University), Matthew Guzdial (Georgia Institute of Technology)
Additional Information
Workshop URL: https://sites.google.com/view/kegworkshop/

W10 — Network Interpretability for Deep Learning
This workshop aims to bring together researchers, engineers, students in both academic and industrial communities who are concerned about the interpretability of deep learning models and, more importantly, the safety of applying these complex deep models in critical applications, such as the medical diagnosis and the autonomous driving. Efforts along this direction are expected to open the black box of deep neural networks for better understanding and to build more transparent deep models that are interpretable to humans. Therefore, the main theme of the workshop is to build up consensus on the emerging topic of the network interpretability, by clarifying the motivation, the typical methodologies, the prospective trends, and the potential industrial applications of the network interpretability.
Topics
Topics of interest include but are not limited to:

Theories of deep neural networks
Visualization of neural networks
Diagnosing and disentangling feature representations of neural networks
Learning representations for neural networks which are interpretable, disentangled and/or compact
Improving interpolation capacity of features for generative models.
Probabilistic logic interpretation of deep learning
Bridging feature representations between visual concepts and linguistic concepts.
Safety and fairness of the deep learning models
Industrial applications of interpretable deep neural networks
Evaluation of the interpretability of neural networks

Format
The one-day workshop will include invited talks, oral and poster presentations of accepted papers, as well as panel discussions.
Attendance
The workshop welcomes scientists, engineers, and students in both academic and industrial communities who are interested in the interpretability of deep learning techniques and, more importantly, the safety of the complex deep learning models.
Submissions
We invite extended abstracts with 2 – 4 pages and full submissions with 6 – 8 pages. All the accepted papers will be published as workshop proceedings on arXiv.org. Please submit papers to networkinterpretability@gmail.com.
Organizing Committee
Quanshi Zhang (Shanghai Jiao Tong University and UCLA, zqs1022@sjtu.edu.cn), Lixin Fan (Nokia Technologies, lixin.fan@nokia.com), Bolei Zhou (Chinese University of Hong Kong and MIT, bzhou@csail.mit.edu)
Additional Information
Workshop URL: http://networkinterpretability.org

W011 — Plan, Activity, and Intent Recognition (PAIR 2019)
Plan recognition, activity recognition, and intent recognition all involve making inferences about other actors from observations of their behavior, i.e., their interaction with the environment and with each other. The observed actors may be software agents, robots, or humans. This synergistic area of research combines and unifies techniques from user modeling, machine vision, automated planning, intelligent user interfaces, human/computer interaction, autonomous and multi-agent systems, natural language understanding, and machine learning. It plays a crucial role in a wide variety of applications including: assistive technology, software assistants, computer and network security, behavior recognition, coordination in robots and software agents, and more.
This workshop seeks to bring together researchers and practitioners from diverse backgrounds, to share ideas and recent results. It aims to identify important research directions, opportunities for synthesis and unification of representations and algorithms for recognition.
Topics
Contributions are sought in the following areas:

Algorithms for plan, activity, intent, or behavior recognition
Machine learning and uncertain reasoning for plan recognition and user modeling
Hybrid probabilistic and logical approach to plan and intent recognition
Modeling users and intents on the web and in intelligent user interface
Modeling users and intents in speech and natural language dialogue
High-level activity and event recognition in video
Algorithms for intelligent proactive assistance
Modeling multiple agents, modeling teams and collaboration teamwork
Modeling social interactions and social network analysis
Adversarial planning, opponent modeling
Intelligent tutoring systems (ITS)
Programming by demonstration
Cognitive models of intent recognition
Inferring emotional states

Related contributions in other fields, are also welcome.
Format
This year’s workshop will be centered around the past and future of PAIR. This will include an introspection of previous approaches and a group discussion about the future directions and vision for the community.
Submissions
We welcome submissions describing either relevant work or proposals for discussion topics that will be of interest to the workshop. Submissions are accepted in PDF format only, using the AAAI-19 formatting guidelines. Submissions must be no longer than 8 pages in length, with the last page including only references and figures. Submissions are anonymous, and must conform to the AAAI-19 instructions for double-blind review. Submission will be accepted through EasyChair, at the following link: https://easychair.org/conferences/?conf=pair19
Questions about submissions can be emailed to sarah.e.keren@gmail.com.
Cochairs
Sarah Keren (primary contact) (Harvard University, sarah.e.keren@gmail.com or skeren@seas.harvard.edu), Reuth Mirsky (primary contact) (Ben-Gurion University, dekelr@post.bgu.ac.il), Christopher Geib (SIFT LLC, cgeib@sift.net)
Additional Information
Workshop URL: http://www.planrec.org/PAIR/Resources.html

W12 — Reasoning and Learning for Human-Machine Dialogues (DEEP-DIAL 2019)
Natural conversation is a hallmark of intelligent systems. Unsurprisingly, dialog systems have been a key sub-area of AI for decades. Their most recent form, chatbots, which can engage people in natural conversation and are easy to build in software, have been in the news a lot lately. There are many platforms to create dialogs quickly for any domain based on simple rules. Further, there is a mad rush by companies to release chatbots to show their AI capabilities and gain market valuation. However, beyond basic demonstration, there is little experience in how they can be designed and used for real-world applications needing decision making under practical constraints of resources and time (e.g., sequential decision making) and being fair to people chatbots interact with. The workshop is a follow-up to the highly successful first AAAI Workshop on Reasoning and Learning for Human-Machine Dialogues (DEEP-DIAL 2018; https://sites.google.com/view/deep-dial-2019/), held in New Orleans, USA in Feb 2018 which attracted over hundred participants. The workshop series is timely to help chatbots realize their full potential.
Moreover, there is increasing interest and need for innovation in human-technology-interaction as addressed in the context of companion technology. Here, the aim is to implement technical systems that smartly adapt their functionality to their users’ individual needs and requirements and are even able to solve problems in close co-operation with human users. To this end, they need to enter into a dialog and should be able to convincingly explain their suggestions and their decision-making behavior.
From research side, statistical and machine learning methods are well entrenched for language understanding and entity detection. However, the wider problem of dialog management is unaddressed with mainstream tools supporting rudimentary rule-based processing. There is an urgent need to highlight the crucial role of reasoning methods, like constraints satisfaction, planning and scheduling, and learning working together with them, can play to build an end-to-end conversation system that evolves over time. From practical side, conversation systems need to be designed for working with people in a manner that they can explain their reasoning, convince humans about choices among alternatives, and can stand up to ethical standards demanded in real life settings.
Topics
With these motivations, some areas of interest for the workshop, but not limited to, are:

Dialog Systems

Design considerations for dialog systems
Evaluation of dialog systems, metrics
Open domain dialog and chat systems
Task-oriented dialogs
Style, voice and personality in spoken dialogue and written text
Novel Methods for NL Generation for dialogs
Early experiences with implemented dialog systems
Mixed-initiative dialogs where a partner is a combination of agent and human
Hybrid methods


Reasoning

Domain model acquisition, especially from unstructured text
Plan recognition in natural conversation
Planning and reasoning in the context of dialog systems
Handling uncertainity
Optimal dialog strategies


Learning

Learning to reason
Learning for dialog management
End2end models for conversation
Explaining dialog policy


Practical Considerations

Responsible chatting
Ethical issues with learning and reasoning in dialog systems
Corpora, Tools and Methodology for Dialogue Systems
Securing one’s chat



The intended audience includes students, academic researchers and practitioners with an industrial background from the AI sub-areas of dialog systems, natural language processing, learning, reasoning, planning, HCI, ethics and knowledge representation.
Submissions
Papers must be formatted in AAAI two-column, camera-ready style (AAAI style files are at: http://www.aaai.org/Publications/Templates/AuthorKit19.zip). Regular research papers may be no longer than 7 pages, where page 7 must contain only references, and no other text whatsoever. Short papers, which describe a position on the topic of the workshop or a demonstration/tool, may be no longer than 4 pages, references included. Papers should be submitted via EasyChair at the following URL: https://easychair.org/conferences/?conf=deepdial19
Important Dates
This workshop will follow a slightly different schedule: November 01, 2018: Workshop paper submissions due November 20, 2018: Notification to authors November 30, 2018:  Camera-ready copies of authors’ papers
Organizing Committee
Biplav Srivastava (IBM Research, USA), Susanne Biundo (University of Ulm, Germany), Ullas Nambiar (Zensar Labs, India), Imed Zitouni (Microsoft AI+R, USA)
Additional Information
Workshop URL: https://sites.google.com/view/deep-dial-2019/

W13 — Reasoning for Complex Question Answering
Question Answering (QA) has become a crucial application problem in evaluating the progress of AI systems in the realm of natural language processing and understanding, and to measure the progress of machine intelligence in general. The computational linguistics communities (ACL, NAACL, EMNLP et al.) have devoted significant attention to the general problem of machine reading and question answering, as evidenced by the emergence of strong technical contributions and challenge datasets such as SQuAD. However, most of these advances have focused on shallow QA tasks that can be tackled very effectively by existing retrieval-based techniques. Instead of measuring the comprehension and understanding of the QA systems in question, these tasks test merely the capability of a technique to attend or focus attention on specific words and pieces of text.
To better align progress in the field of QA with the expectations that we have of human performance and behavior when solving such tasks, a new class of questions – known as “complex” or “challenge” questions – has been proposed. The definition of complex questions varies, but they can most generally be thought of as instances that require intelligent behavior and reasoning on the part of an agent to solve. Such reasoning may also include the systematic retrieval of knowledge from semi-structured and structured sources such as documents, webpages, tables, knowledge graphs etc.; and the exploitation of domain models in generalized representations that are learned from available data. As the knowledge as well as the questions themselves become more complex and specialized, the process of understanding and answering these questions comes to resemble human expertise in specialized domains. Current examples of such complex question answering (CQA) tasks – where humans presently rule the roost – include customer service and support, standardized testing in education, and domain-specific consultancy services such as legal advice, etc.
The main aim of this workshop is to bring together experts from the computational linguistics (CL) and AI communities to: (1) catalyze progress on the CQA problem and create a vibrant test-bed of problems for various AI sub-fields; and (2) present a generalized task that can act as a harbinger of progress in AI.
Submissions
We solicit submissions in the form of papers (short and long), posters, demos, panel ideas, and other suggestions. A submission site will be available soon; in the meantime, suggestions on topics or programs to include in the workshop may be emailed to Kartik Talamadupula (krtalamad@us.ibm.com).
Organizing Committee
Kartik Talamadupula (IBM), Michael Witbrock (IBM), Peter Clark (Allen Institute for Artificial Intelligence), Rajarshi Das (University of Massachusetts Amherst), Mausam (Indian Institute of Technology Delhi)
Additional Information
Workshop URL: http://ibm.biz/complexqa

W14 — Recommender Systems Meet Natural Language Processing (RecNLP)
RecNLP is an interdisciplinary workshop covering the intersection between Recommender Systems (RecSys) and Natural Language Processing (NLP). The primary goal of RecNLP is to identify common ideas and techniques that are being developed in both disciplines, and to further explore the synergy between the two and to bring together researchers from both domains to encourage and facilitate future collaborations.
Topics
We encourage theoretical, experimental, and methodological developments advancing state-of-the-art knowledge at the intersection between RecSys and NLP. Areas of interest include, but are not limited to:

Applications that inherently combine RecSys and NLP. E.g., using textual reviews for improving recommendations
Using NLP techniques for RecSys. E.g., considering recommendations as a language modeling problem.
Using RecSys techniques for NLP. E.g., personalization of sentiment analysis.

Format
The workshop is composed of invited talks and oral talks of refereed papers, where we allow time for fruitful discussion in the end of each talk. Workshop duration is half a day.
Submissions
RecNLP is a venue for discussion, and as such we allow submission of manuscripts that have already been published or are currently under review, as well as original submissions. The ideal length of a paper is between 4-8 pages, but there are no strict page limits. Already-published papers should be accompanied by a short abstract justifying their specific relevance to RecNLP. Manuscripts must be submitted through easychair and will be reviewed by a program committee. The review process is single-blind. That is, authors’ names should not be anonymized. Submissions will be accepted via EasyChair at the following site: https://easychair.org/conferences/?conf=recnlp2019
Organizing Committee
Oren Sar Shalom (Intuit, oren_sarshalom@intuit.com), Vahid Noroozi (University of Illinois at Chicago, vnoroo2@uic.edu), Mengting Wan (UC San Diego, m5wan@ucsd.edu), Julian McAuley (UC San Diego, jmcauley@ucsd.edu)
Additional Information
Workshop URL: https://recnlp2019.github.io

W15 — Reinforcement Learning in Games (RLG)
Games provide an abstract and formal model of environments in which multiple agents interact: each player has a well-defined goal and rules to describe the effects of interactions among the players. The first achievements in playing these games at super-human level were attained with methods that relied on and exploited domain expertise that was designed manually (e.g. chess, checkers). In recent years, we have seen examples of general approaches that learn to play these games via self-play reinforcement learning (RL), as first demonstrated in Backgammon. While progress has been impressive, we believe we have just scratched the surface of what is capable, and much work remains to be done in order to truly understand the algorithms and learning processes within these environments.
The main objective of the workshop is to bring researchers together to discuss ideas, preliminary results, and ongoing research in the field of reinforcement in games.
Topics
We invite participants to submit papers, based on but not limited to, the following topics: RL in various formalisms: one-shot games, turn-based, and Markov games, partially-observable games, continuous games, cooperative games; deep RL in games; combining search and RL in games; inverse RL in games; foundations, theory, and game-theoretic algorithms for RL; opponent modeling; analyses of learning dynamics in games; evolutionary methods for RL in games; RL in games without the rules.
Format
RLG is a one-day workshop. It will start with a 60-minute mini-tutorial covering a brief tour of the history and basics of RL in games, 2-3 invited talks by prominent contributors to the field, paper presentations, a poster session, and will close with a discussion panel.
Submissions
Papers must between 4-8 pages in the AAAI submission format, with the eighth page containing only references. Papers will be submitted electronically using Easychair. Accepted papers will not be archival, and we explicitly allow papers that are concurrently submitted to, currently under review at, or recently accepted in other conferences / venues.
Organizing Committee
Marc Lanctot (DeepMind, lanctot@google.com), Julien Perolat (DeepMind, perolat@google.com), Martin Schmid (DeepMind, mschmid@google.com)
Additional Information
Workshop URL: http://aaai-rlg.mlanctot.info/

W16 — Reproducible AI
Artificial intelligence, like any science, must rely on reproducible experiments to validate results. Still, reproducing results from research in AI is not easily accomplished. This may be because AI research has its own unique reproducibility challenges. These are related to the use of analytical methods that are still a focus of active investigation and problems due to non-determinism in standard benchmark environments and variance intrinsic to AI methods. Acknowledging these difficulties, AI research should be documented properly so that the experiments and results are clearly described.
In this workshop, we aim to create a forum to make a roadmap for improving the reproducibility of research result presented at future AAAI conferences and other AAAI publications.
Topics
We are particularly interested in submissions that report on efforts to reproduce papers accepted for presentation at AAAI-19. Papers from earlier editions of the conference are also welcome. These submissions could be from the authors of the original papers but could also come from others who endeavoured to reproduce the work. These submissions should document how the results of the original paper were reproduced, and discuss reproducibility challenges, lessons learned, and recommendations for best practices. We suggest following the recommendations presented here: http://www.idi.ntnu.no/~odderik/RAI-2019/On_Reproducible_AI-preprint.pdf.
Any topics related to reproducible AI are welcome, including position papers, surveys, recommendations, and comparisons of AI reproducibility with other fields of research. Our focus is especially on practical solutions for how to improve the reproducibility of research presented at AAAI.
Relevant reading See suggested reading list here http://idi.ntnu.no/~odderik/RAI-2019/Suggested_readings.pdf.
Format
The workshop will last a full day and will consist of both oral and poster presentations, as well as panel and open discussion regarding how to make research results presented at AAAI reproducible.
Submissions
Each submission will be in the form of papers of up to 8-pages in length, using the main AAAI conference format. Authors may choose to anonymize their submissions or not. Papers should be submitted via EasyChair at the URL below. Oral presentations and poster session participants will be selected from the submissions.
Submission URL: https://easychair.org/conferences/?conf=rai2019
Workshop Chairs
Yolanda Gil (University of Southern California), Odd Erik Gundersen (Norwegian University of Science and Technology), Satinder Singh (University of Michigan) and Joelle Pineau (McGill University)
Additional Information
Workshop URL: https://www.idi.ntnu.no/~odderik/RAI-2019/",2019
This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2019 AAAI,2019
"AAAI-20 Workshop Program
February 7-8, 2020New York, New York, USA

2020 AAAI Author Kit

AAAI is pleased to present the AAAI-20 Workshop Program. Workshops will be held Friday and Saturday, February 7-8, 2020 at the New York Hilton Midtown in New York, New York, USA. The final schedule will be available in November, and exact locations will be determined in January. The AAAI-20 workshop program includes 23 workshops covering a wide range of topics in artificial intelligence. Workshops are one day unless noted otherwise in the individual description. Participation in each workshop is in the range of 25-65 participants, and participation is usually by invitation from the workshop organizers. However, most workshops also allow general registration by other interested individuals. Please note that there is a separate registration fee for attendance at a workshop. Workshop registration is available for workshop only registrants or for AAAI-20 technical registrants at a discounted rate. Registration information will be mailed directly to all invited participants in December.",2020
"Important Dates for Workshop Organizers


November 15, 2019: Submissions due (unless noted otherwise)
December 4, 2019: Notification of acceptance (unless noted otherwise)
December 13, 2019: Early registration deadline
February 7-8, 2020: AAAI-20 Workshop Program
",2020
" 

W1: Affective Content Analysis (AffCon 2020): Interactive Affective Response
W2: Artificial Intelligence for Cyber Security (AICS)
W3: Artificial Intelligence for Education
W4: Artificial Intelligence in Team Sports
W5: Artificial Intelligence of Things (AIoT)
W6: Artificial Intelligence Safety (SafeAI)
W7: Cloud Intelligence: AI/ML for Efficient and Manageable Cloud Services
W8: Deep Learning on Graphs: Methodologies and Applications
W9: Dialog System Technology Challenge (DSTC8)
W10: Engineering Dependable and Secure Machine Learning Systems
W11: Evaluating Evaluation of AI Systems
W12: Generalization in Planning
W13: Health Intelligence
W14: Intelligent Process Automation — RPA Meets AI
W15: Interactive and Conversational Recommendation Systems (WICRS)
W16: Knowledge Discovery from Unstructured Data in Financial Services
W17: Plan, Activity, and Intent Recognition (PAIR)
W18: Privacy-Preserving Artificial Intelligence
W19: Reasoning and Learning for Human-Machine Dialogues (DEEP-DIAL20)
W20: Reasoning for Complex Question Answering
W21: Reinforcement Learning in Games
W22: Reproducibility in AI (RAI 2020) – Future Direction and Reproducibility Challenge
W23: Statistical Relational AI (StarAI)
",2020
"
W1 — Affective Content Analysis (AffCon 2020): Interactive Affective Response
Analysis of content to measure affect and its experiences is a growing multidisciplinary research area that still has little cross-disciplinary collaboration. The artificial intelligence (AI) and computational linguistics (CL) communities are making strides in identifying and measuring affect from user signals especially in language, while the human-computer interaction (HCI) community independently explores affect through user experience evaluations. Consumer psychology and marketing pursues a different direction to ground affect in its theoretical underpinnings as well as their real-world applications.
The third Affective Content Analysis workshop aims to bring together researchers from computer science, psychology, and marketing science for stimulating discussions on affect, with a focus on language and text. In addition, this workshop offers a Shared Task with a new corpus, to spur the development of new approaches and methods for affect identification.
Topics
The theme of AffCon 2020 is the study of affect in response to interactive content that may evolve over time. The word ‘affect’ is used to refer to emotion, sentiment, mood, and attitudes including subjective evaluations, opinions, and speculations. Psychological models of affect have been adopted by other disciplines to conceptualize and measure users’ opinions, intentions, and expressions. However, the context-specific characteristics of human affect suggest the need to measure in ways that recognize multiple interpretations of human responses.
We invite papers that offer modeling and measurement of affect and identify the best affect–related dimensions to study consumer behavior. In turn, that allows data models to be more informed in representing behaviors and hence effective in guiding decisions and actions by firms. We welcome submissions on topics including – but not limited to – the following:

Deep learning-based models for affect modeling in content (image, audio, and video)
Psycho-demographic profiling
Affective human-agent, -computer, and-robot interaction
Mirroring affect
Affect-aware text generation
Measurement and evaluation of affective content
Consumer psychology at scale from big data
Modeling consumer’s affect reactions
Affect lexica for online marketing communication
Affective commonsense reasoning
Multimodal emotion recognition and sentiment analysis
Affect and Cognitive Content Measurement in Text
Affect in communication
Affectively responsive interfaces
Computational models for consumer behavior theories
Psycho-linguistics, including stylometrics and typography
Bridging the gap between consumer psychology and computational linguistics

We especially invite papers investigating multiple related themes, industry papers, and descriptions of running projects and ongoing work. To address the scarcity of standardized baselines, datasets, and evaluation metrics for cross-disciplinary affective content analysis, submissions describing new language resources, evaluation metrics, and standards for affect analysis and understanding are also strongly encouraged.
Shared Task: CL-Aff
There is a growing interest in understanding how humans initiate and hold conversations. The affective understanding of conversations focuses on the problem of how speakers use affect to react to a situation and to each other. We introduce the OffMyChest Conversation dataset, and invite submissions for the Computational Linguistics Affect Understanding (CL-Aff) Shared Task on Affect in Conversations.
Format
This full-day workshop will have several prominent interdisciplinary invited speakers from the fields of linguistics, psychology, and marketing science to lead the presentation sessions. In a poster session in the afternoon, a few papers deemed more suited for a poster than a presentation will be invited to display a poster or a demo. The workshop will end with a fishbowl-style discussion among the organizers and participants to decide on future directions for the workshop and the research community. Attendance: Expected 60-70 attendees.
Submissions
EasyChair Submission URL
Submissions should be made via EasyChair and must follow the formatting guidelines for AAAI-20 (use the AAAI Author Kit). All submissions must be anonymous and conform to AAAI standards for double-blind review. Both full papers (8 page long including references) and short papers (4 page long including references) that adhere to the 2-column AAAI format will be considered for review.
Cochairs
Niyati Chhaya, Primary Contact (Adobe Research, nchhaya@adobe.com); Kokil Jaidka (Nanyang Technological University, kokil.j@gmail.com); Jennifer Healey (Adobe Research, jehealey@adobe.com); Lyle Ungar (University of Pennsylvania, ungar@cis.upenn.edu); Atanu R Sinha (Adobe Research, atr@adobe.com)
Workshop Chair Address
Niyati Chhaya, Adobe ResearchAdobe Systems, Prestige Platina Tech Park, Marathahalli-Sarjapur Outer Ring Rd, Kadubeesanahalli, Bengaluru- 560087, Indianchhaya@adobe.com
Additional Information
Workshop URL

W2 — Artificial Intelligence for Cyber Security (AICS)
The workshop will focus on the application of artificial intelligence to problems in cyber security. This year’s AICS emphasis will be on human-machine teaming within the context of cyber security problems and will specifically explore collaboration between human operators and AI technologies. The workshop will address applicable areas of AI, such as machine learning, game theory, natural language processing, knowledge representation, automated and assistive reasoning and human machine interactions. Further, cyber security application areas- with a particular emphasis on the characterization and deployment of human-machine teaming- will be the focus. Additional areas can be discussed with similar challenges and solution spaces (e.g. genomic big data, astronomy, and cyberbiosecurity).
As cyber security has rapidly matured, data collection has become easier to instrument, implement, and collect. This has led to a massive increase of the amount of data that must be analyzed to achieve situational awareness- the scale of which is beyond human capabilities. Additionally, with the concurrent advancements in machine learning capabilities, there are algorithms and tools with the impressive ability to automatically analyze and classify massive amounts of data in complex scenarios, but deploying them in specific domains can be challenging. Together, this has created an environment of increased reliance on AI-based systems for humans to interact with the scale of cyber security problems.
Because humans must interact with at least parts of these AI systems, many challenges and arise. Principally among them are: 1) Determining optimal techniques to improve AI performance given targeted, limited human input, 2) understanding the extent to which the interaction between humans and AI introduces an attack surface for adversarial techniques to influence the performance of both the human and computer systems, 3) establishing and quantifying trust between humans and AI systems, 4) providing explainable AI where humans are required to do ‘last mile’ synthesis of information provided from a black box algorithm, and 5) defining the scope in which an AI system can operate autonomously in distinct cyber security domains while maintaining safety. A successful framework for the interaction between humans and AI is extremely important as machine learning based AI capabilities become incorporated into everyday life. Human-computer interactions will continue to increase. If they are not accurate, robust, trustworthy, explainable, and safe the systems will be prone to failure even if the underlying algorithms and/or people are individually effective.
For this workshop we consider general challenges 1-5 in the domain of cyber security as a focus application area. Cyber security is difficult to perform because of its high reliance on subject matter expertise to recognize anomalies in cyber data. Because AI systems are not yet well suited for this context-generating tasks for cyber, there is a human-in-the-loop requirement for most cyber security applications. Cyber security thus provides a unique case study in exploring the relationship between AI systems and humans because each rely on input and parse output from the other.
This year we are asking the AI for cyber security community to submit solutions to a challenge problem. The challenge problem (http://aics.site/AICS2020/challenge.html is focused on a representative cyber security task that generally requires human interaction.Understanding and addressing challenges associated with systems that involve human-machine teaming requires collaboration between several different research and development communities including: artificial intelligence, cyber-security, game theory, machine learning, human factors, as well as the formal reasoning communities. This workshop is structured to encourage a lively exchange of ideas between researchers in these communities from the academic, public, and commercial sectors.
Topics
Topics of interest include, but are not limited to:

Human-machine teaming and human computer interactions
Adversarial machine learning
Cyberbiosecurity
Machine learning approaches to make cyber systems secure and resilient
Formal reasoning, with focus on human element, in cyber systems
Game Theoretic reasoning in cyber security
Robust AI metrics
Multi-agent interaction/agent-based modeling in cyber systems
Modeling and simulation of cyber systems and system components
Decision making under uncertainty in cyber systems
Automation of data labeling and ML techniques that learn to learn
Quantitative human behavior models with application to cyber security
Operational and commercial applications of AI

Challenge Problem
For information on this year’s AICS challenge problem: http://aics.site/AICS2020/challenge.html
Format
The workshop will include invited speakers, presentations, panel and group discussions
Submissions
One of two submissions is solicited:

Full-length papers (up to 8 pages in AAAI format)
Challenge problem papers (up to 8 pages in AAAI format)

Submissions are not anonymized. Please submit PDF via AICS Workshop website.
The deadline to submit papers is November 15, 2019.
Publication
Accepted papers will be published in the AICS Workshop proceedings on arXiv after the event.
Cochairs
Dennis M. Ross (MIT Lincoln Laboratory, MA, USA), Diane P. Staheli (MIT Lincoln Laboratory, MA, USA), David R. Martinez (MIT Lincoln Laboratory, MA, USA), William W. Streilein (MIT Lincoln Laboratory, MA, USA), Arunesh Sinha (Singapore Management University, Singapore), Milind Tambe (Harvard University, MA, USA)
Additional Information
Supplemental workshop site: http://aics.site/AICS2020

W3 — Artificial Intelligence for Education
Artificial Intelligence (AI) has dramatically transformed a variety of domains. However, education, a crucial component of our society still remains a relatively under-explored domain. In fact, the increasingly digitalized education tools and the popularity of the massive open online courses have produced an unprecedented amount of data that provides us with invaluable opportunities for applying AI in education. Recent years have witnessed growing efforts from AI research community devoted to advancing our education. Although it is still in the early stage, promising results have been achieved in solving various critical problems in education. For example, knowledge tracing, which is a intrinsically difficult problem due to the complexity under human learning procedure, has been solved successfully with powerful deep neural networks that can fully take the advantages of massive student exercise data. Besides the achievement in improving the student learning efficiency, similar excitement has been generated in other areas of education. For instance, researchers have also devoted to reducing the monotonous and tedious grading workloads of teaching professionals by building automatic grading systems that are underpinned by effective models from natural language process fields. Despite aforementioned success, developing and applying AI technologies to education is fraught with its unique challenges, including, but not limited to, extreme data sparsity, lack of labeled data, and privacy issues. Therefore, it is timely and necessary to provide a venue, which can bring together academia researchers and education practitioners (1) to discuss the principles, limitations and applications of AI for education; and (2) to foster research on innovative algorithms, novel techniques, and new applications to education.
Topics
We encourage submissions on a broad range of AI technologies for various education domains. Topics of interest include but are not limited to the following:

Emerging Technologies in education
Evaluation of education technologies
Immersive learning and multimedia applications
Implications of big data in education
Self-adaptive learning
Individual and personalized education
Intelligent Learning Systems
Intelligent Tutoring and Monitoring Systems
Automatic assessment in education
Automated grading of assignments
Learning technology for Lifelong Learning
Course development techniques
Mining and web mining in Education
Learning tools experiences and Cases of Study
Lifelong education
MOOC’s and Data Analytics
Social media in education
Smart education
Education Analytic approaches, methods, and tools
Knowledge management for learning
Learning analytics and educational Data Mining
Smart classroom
Dropout prediction
Knowledge tracing
Tracking learning activities
Uses of multimedia for education
Wearable computing technology In e-learning
Analysis of communities of learning
Computer-aided assessment
Course development techniques
Automated feedback and recommendations
Big data analytics for education

Format
The workshop is a full day. It will include 3-4 keynote speeches, a paper poster discussion session and a panel discussion about “ethics in AIED.”
Submissions
We invite the submission of novel research paper (6 pages), demo paper (4), visionary papers (4 pages) as well as extended abstracts (2 pages). Submissions must be in PDF format, written in English, and formatted according to the AAAI camera-ready style. All papers will be peer reviewed, single-blinded. Submitted papers will be assessed based on their novelty, technical quality, potential impact, insightfulness, depth, clarity, and reproducibility. All the papers are required to be submitted via Easychair ystem. For more questions about the workshop and submissions, please send email to wangzh65@msu.edu.
Submission site: https://easychair.org/conferences/?conf=ai4edu
Organizing Committee
Jiliang Tang (Michigan State University), Zitao Liu (TAL Education Group), Kaitlin Torphy (Michigan State University), Ken Frank (Michigan State University), Zhiwei Wang (Michigan State University)
Additional Information
Supplemental workshop site: http://www.cse.msu.edu/~wangzh65/AI4EDU/index.html

W4 — Artificial Intelligence in Team Sports
Sports is a domain that has grown significantly over the last 20 years to become a key driver of many economies. According to a recent report (https://urlzs.com/tsvbY), the estimated size of the global sports industry is $1.3 trillion, and has an audience of over 1 billion. As the market has grown so has the amount of data that is collected. This means that there are a number of challenging problems in sports to predict and optimise performance but, so far, such problems have largely been dealt with by domain experts (e.g., coaches, managers, scouts, and sports health experts) with basic analytics.
The growing availability of datasets in sports presents a unique opportunity for the artificial intelligence (AI) and machine learning (ML) communities to develop, validate, and apply new techniques in the real world. In team sports, real-world data is available over long periods of time, about the same individuals and teams, in a variety of environmental contexts, thereby creating a unique live test-bed for AI and ML techniques. While research in AI for team sports has grown over the last 20 years, it is as yet unclear how they relate to each other or build upon each other as they tend to either focus on specific types of team sports or specific prediction and optimisation problems that are but one part of the whole field. Hence, this workshop will help fuel discussions in the area and bring together the AI and sports analytics communities to encourage new research that will benefit both communities and industry.
Topics
We invite high-quality paper submissions on topics including, but not limited to, the following:

Match Outcome Prediction
Tactical Decision Making, Player Acquisition and Performance Prediction
Fantasy Sports Games
Injury Prediction and Prevention

We are keen to see applications of AI techniques such as:

Machine Learning and Deep Learning
Computer Vision
Optimization
Multi-Agent Systems
Human-Machine Interaction

Format
The workshop will be a full-day and will include a mix of invited talk(s) and peer-reviewed papers (talks and poster sessions). It will conclude with a panel discussion.
Submissions
Two forms of submissions are invited:

Short position papers (2-4 pages) describing initial work or real-world results of applications of AI.
Full technical papers (6-8 pages) describing original research. Note that there will be no formal publications of the workshop proceedings and hence we will accept resubmissions from other venues.

Manuscripts must be submitted as PDF files via EasyChair online submission system.
Please keep your paper format according to AAAI Formatting Instructions (two-column format).Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper).
Organizing Committee
Ryan Beal (University of Southampton, UK), Sarvapali Ramchurn (University of Southampton, UK), Georgios Chalkiadakis (Technical University of Crete, Greece), Onn Shehory (Bar Ilan University, Israel), Tim Swartz (Simon Fraser University, Canada)
Additional Information
Supplemental workshop site: https://www.ai-teamsports.com

W5 — Artificial Intelligence of Things (AIoT)
Internet of Things (IoT) is a disruptive technology that extends data collection to almost everything around us and enables them to react through intelligent data processing. Gartner estimates that the number of connected things will grow to over 20 billion by 2020. With recent innovative network and chip technology, devices are becoming smarter with increasing compute power, bandwidth, and storage available on the device. This enables intelligent decision making and information transfer through devices. Insights derived from data generated by IoT devices power new business scenarios and ensure long term success of existing business. Major IT solution providers have been investing in building IoT data platform to support customers to develop IoT solutions in different industry sectors such as smart cities, manufacturing, health care and transportation. These business scenarios impose technical challenges and opportunities in building intelligent cloud and edge solutions. This workshop provides a forum for researchers, data scientists and practitioners from both academia and industry to present the latest research results, share practical experience of building AI powered IoT solutions, and network with colleagues.
Topics
IoT is an interdisciplinary field that intersects with device, sensor network, stream analytics, and machine learning. AI for IoT is a workshop on IoT with its focus on technologies to enable machine learning algorithms to run on resource constrained, secure, and connected devices. The workshop encourages submissions of innovative technologies and applications that enable IoT scenarios. Topics of interest, include but not limited to:

On device machine learning algorithms
Real-time computer vision and speech processing
Learning-enabled IoT applications
AI for Edge computing
AI for IoT security and privacy
Low-power AI for IoT systems
Distributed inferencing and learning
Optimized Blockchain for IoT
5G and IoT

Format
The workshop will be a full day event with keynote, invited talks, technical paper presentation, and project showcase.
Submissions
We solicit original papers in two formats – Technical Paper (6 pages) and project showcase (2 pages) in AAAI format. Submitted papers will be peer-reviewed and selected for presentation. Accepted papers will be published on the workshop’s website.
Submission site: https://cmt3.research.microsoft.com/AIOTW2019/Submission/Index
Organizing Committee
General Chair: Yiran Chen (Duke University, yiran.chen@duke.edu)Program Chairs: Jian Zhang (Microsoft, jianzha@microsoft.com), Jian Tang (DiDi ChuXing, tangjian@didiglobal.com)Steering Committee: Jie Liu (Harbin Institute of Technology), Jieping Ye (DiDi Chuxing), Marilyn Claire Wolf (Georgia Tech), Mani Srivastava (UCLA), Michael I. Jordan (UC Berkeley), Victor Bahl (Microsoft), Vijaykrishnan Narayanan (Penn State University)
Additional Information
Supplemental workshop site: https://aiotworkshop.github.io/

W6 — Artificial Intelligence Safety (SafeAI)
Safety in Artificial Intelligence (AI) should not be an option, but a design principle. However, there are varying levels of safety, diverse sets of ethical standards and values, and varying degrees of liability, which can only be addressed by taking into account trade-offs and alternative solutions. A holistic analysis should integrate the technological and ethical perspectives into the engineering problem, considering both the theoretical and practical challenges of AI safety. This new view must cover a wide range of AI paradigms, considering systems that are application-specific, and also those that are more general, providing information about risk. We must bridge the short-term with the long-term perspectives, idealistic with pragmatic solutions, operational with policy issues, and industry with academia, in order to build, evaluate, deploy, operate and maintain AI-based systems that are truly safe.
This workshop seeks to explore new ideas on AI safety with particular focus on the following questions:



What is the status of existing approaches in ensuring AI and Machine Learning (ML) safety and what are the gaps?
How can we engineer trustable AI software architectures?
How can we make AI-based systems more ethically aligned?
What safety engineering considerations are required to develop safe human-machine interaction?
What AI safety considerations and experiences are relevant from industry?
How can we characterize or evaluate AI systems according to their potential risks and vulnerabilities?
How can we develop solid technical visions and new paradigms about AI Safety?
How do metrics of capability and generality, and trade-offs with performance affect safety?



The main interest of the proposed workshop is to look holistically at AI and safety engineering, jointly with the ethical and legal issues, to build trustable intelligent autonomous machines. As part of a “sister” workshop (AISafety 2019), we started the “AI Safety Landscape” initiative. This initiative aims at defining a multi-faceted and integrated “view” of the current needs, challenges, and the state of the art and practice of this field.
Topics
Contributions are sought in (but are not limited to) the following topics:







Safety in AI-based system architectures
Continuous V&V and predictability of AI safety properties
Runtime monitoring and (self-)adaptation of AI safety
Accountability, responsibility and liability of AI-based systems
Effect of uncertainty in AI safety
Avoiding negative side effects in AI-based systems
Role and effectiveness of oversight: corrigibility and interruptibility
Loss of values and the catastrophic forgetting problem
Confidence, self-esteem and the distributional shift problem
Safety of Artificial General Intelligence (AGI) systems and the role of generality
Reward hacking and training corruption
Self-explanation, self-criticism and the transparency problem
Human-machine interaction safety
Regulating AI-based systems: safety standards and certification
Human-in-the-loop and the scalable oversight problem
Evaluation platforms for AI safety
AI safety education and awareness
Experiences in AI-based safety-critical systems, including industrial processes, health, automotive systems, robotics, critical infrastructures, among others







Format
To deliver a truly memorable event, we will follow a highly interactive format that will include invited talks and thematic sessions. The thematic sessions will be structured into short pitches and a common panel slot to discuss both individual paper contributions and shared topic issues. Three specific roles are part of this format: session chairs, presenters and paper discussants. The workshop will be organized as a full day meeting. Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
You are invited to submit:







Full technical papers (6-8 pages),
Proposals of technical talk (up to one-page abstract including short Bio of the main speaker),
Position papers for general topics (2-4 pages), and
Position papers for the AI Safety Landscape (2-4 pages).







Manuscripts must be submitted as PDF files via EasyChair online submission system: https://easychair.org/conferences/?conf=SafeAI2020
Please keep your paper format according to AAAI Formatting Instructions (two-column format). The AAAI author kit can be downloaded from: https://www.aaai.org/Publications/Templates/AuthorKit20.zip
Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper). The workshop follows a single-blind reviewing process. However, we will also accept anonymized submissions.
Chairs
Huáscar Espinoza (Commissariat à l´Energie Atomique, France), José Hernández-Orallo (Universitat Politècnica de València, Spain), Cynthia Chen (University of Hong Kong, China), Seán Ó hÉigeartaigh (University of Cambridge, UK), Xiaowei Huang (University of Liverpool, UK), Mauricio Castillo-Effen (Lockheed Martin, USA), Richard Mallah (Future of Life Institute, USA), John McDermid (University of York, UK).
Additional Information
Supplemental workshop site: http://safeaiw.org/

W7 — Cloud Intelligence: AI/ML for Efficient and Manageable Cloud Services
Digital transformation is happening in all industries. Running businesses on top of cloud services (e.g., SaaS, PaaS, IaaS) is becoming the core of digital transformation. However, the large-scale and high complexity of cloud services brings great challenges to the industry. Artificial intelligence and machine learning will play an important role in efficiently and effectively building and operating cloud services. We envision that, with the advance of AI/ML and other related technologies, the cloud industry will achieve significant progress in the following aspects while keeping a sustained and exponential growth:
Highly resilient cloud service. Cloud services will have built-in capabilities of self-monitoring, self-diagnosis, and self-healing – all with low human intervention without compromising the service quality or the user experience.
Intelligence at users’ fingertips. Users can easily use, maintain, and troubleshoot their workloads or get efficient support on top of the underlying cloud service offerings.Highly efficient and effective DevOps (Developer and Operations). Engineers are empowered with intelligent tools to (1) build new capabilities of services and smoothly roll out new capabilities to users; (2) efficiently operate production services.
The industry is calling for AIOps solutions but is still at an early stage towards realizing this vision. We advocate the urgency of driving and accelerating AI/ML for efficient and manageable cloud services through collaborative efforts in multiple areas including but not limited to artificial intelligence, machine learning, software engineering, data analytics, and systems.This workshop provides a forum for researchers and practitioners to present the state of research and practice in AI/ML for efficient and manageable cloud services, and network with colleagues.
Topics
The workshop targets creating an interdisciplinary forum for researchers and practitioners from the fields mentioned above. The workshop encourages submissions on innovative technologies and applications that leverage AI/ML for efficient and manageable cloud services. Topics of interest include AI/ML related techniques, methodologies, and experiences for cloud intelligence and DevOps solutions.







New design, development, and operational patterns
Development of cloud services
Deployment and integration testing
System configuration
Service quality monitoring and anomaly detection
Resource scheduling and optimization
Capacity/workload management and prediction
Hardware/software failure prediction
Auto-diagnosis and problem localization
Incident management
Auto service healing
Data center management
Customer support
Security
Privacy







Format
The workshop will be a full day event with keynote, invited talks, technical paper presentation, and project showcase.
Submissions
We solicit original papers in two formats – technical paper (6 pages) and project showcase (2 pages) in AAAI format. Submitted papers will be peer-reviewed and selected for presentation.
Submission site: https://cmt3.research.microsoft.com/CIEMCS2020/Submission/Index.
Organizing Committee
Program Chair: Jian Zhang (Microsoft, jianzha@microsoft.com)Steering Committee: Ricardo Bianchini (Microsoft Research Redmond), Mike Dahlin (Google), Marcus Fontoura (Microsoft Azure), Ahmed E. Hassan (Queen’s University), Erik Meijer (Facebook), Tao Xie (Peking University), Dongmei Zhang (Microsoft Research Asia ), Yuanyuan Zhou (UCSD)
Additional Information
Supplemental workshop site: https://cloudintelligenceworkshop.github.io/

W8 — Deep Learning on Graphs: Methodologies and Applications (DLGMA’20)
Deep Learning models are at the core of research in Artificial Intelligence research today. It is well- known that deep learning techniques that were disruptive for Euclidean data such as images or sequence data such as text are not immediately applicable to graph-structured data.This gap has driven a tide in research for deep learning on graphs on various tasks such as graph representation learning, graph generation, and graph classification. New neural network architectures on graph-structured data have achieved remarkable performance in these tasks when applied to domains such as social networks, bioinformatics and medical informatics.
This wave of research at the intersection of graph theory and deep learning has also influenced other fields of science, including computer vision, natural language processing, inductive logic programming, program synthesis and analysis, automated planning, reinforcement learning, and financial security. Despite these successes, graph neural networks (GNNs) still face many challenges, namely,







Modeling highly structured data with time-evolving, multi-relational, and multi-modal nature. Such challenges are profound in applications in social attributed networks, natural language processing, inductive logic programming, and program synthesis and analysis. Joint modeling of text or image content with underlying network structure is a critical topic for these domains.
Modeling complex data that involves mapping between graph-based inputs and other highly structured output data such as sequences, trees, and relational data with missing values. Natural Language Generation tasks such as SQL-to-Text and Text-to-AMR are emblematic of such challenge.







This one-day workshop aims to bring together both academic researchers and industrial practitioners from different backgrounds and perspectives to the above challenges. The workshop will consist of contributed talks, contributed posters, and invited talks on a wide variety of methods and applications. Work-in-progress papers, demos, and visionary papers are also welcome. This workshop intends to share visions of investigating new approaches and methods at the intersection of Graph Neural Networks and real-world applications.
Topics of Interest (including but not limited to)
We invite submission of papers describing innovative research and applications around the following topics. Papers that introduce new theoretical concepts or methods, help to develop a better understanding of new emerging concepts through extensive experiments, or demonstrate a novel application of these methods to a domain are encouraged.







Graph neural networks on node-level, graph-level embedding
Graph neural networks on graph matching
Dynamic/incremental graph embedding on heterogeneous networks, knowledge graphs
Deep generative models for graph generation/semantic-preserving transformation
Graph2seq, graph2tree, and graph2graph models
Deep reinforcement learning on graphs
Adversarial machine learning on graphs
Spatial and temporal graph prediction and generation







And with particular focuses but not limited to these application domains:







Learning and reasoning (machine reasoning, theory proving)
Natural language processing (information extraction, semantic parsing, text generation)
Bioinformatics (drug discovery, protein generation, protein structure prediction)
Program synthesis and analysis
Reinforcement learning (multi-agent learning, compositional imitation learning)
Financial security (anti-money laundering)
Cybersecurity (authentication graph, Internet of Things, malware propagation)
Geographical network modeling and prediction (transportation and mobility networks, social networks)







Submissions
Submissions are limited to a total of 4 pages for initial submission (up to 5 pages for final camera-ready submission), excluding references or supplementary materials, and authors should only rely on the supplementary material to include minor details that do not fit in the 4 pages. All submissions must be in PDF format and formatted according to the AAAI style file. Special issues in flagship academic journals are under consideration to host the extended versions of best/selected papers in the workshop.
Submission link: https://easychair.org/conferences/?conf=dlgma2020
Camera-ready deadline for final accepted papers: December 20, 2019
Cochairs
Lingfei Wu (IBM Research AI), Jian Tang (Mila-Quebec AI Institute), Yinglong Xia (Facebook AI), Charu Aggarwal (IBM Research AI)
The full workshop committee is listed at the supplemental workshop site.
Additional Information
Supplemental workshop site: https://deep-learning-graphs.bitbucket.io/dlg-aaai20/
Please contact Linfei Wu at lwu@email.wm.edu for more information

W9 — The Eighth Dialog System Technology Challenge (DSTC8)
DSTC, the Dialog System Technology Challenge, has been a premier research competition for dialog systems since its inception in 2013. Given the remarkable success of the first seven challenges, we are organizing the eighth edition of DSTC this year and we will have a wrap-up workshop at AAAI-20.
Topics
The main goal of this workshop is to share the results of the following four main tracks of DSTC8:







Multi-Domain Task-Completion Dialog Challenge
NOESIS II: Predicting Responses, Identifying Success, and Managing Complexity in
Task-Oriented Dialogue
Audio Visual Scene-Aware Dialog
Schema-Guided Dialogue State Tracking







Format
The one-day workshop will include welcome remarks, track overviews, invited talks, oral presentations, poster sessions, and discussions about future DSTCs.
Submissions
We invite all the teams participated in DSTC8 to submit their work to this workshop. In addition, any other general technical paper on dialog technologies is also welcome. The submissions must follow the formatting guidelines for AAAI-2020 (use the AAAI Author Kit). All submissions must be anonymous and conform to AAAI standards for double-blind review. The papers adhere to the 2-column AAAI format up to 8 pages long with page 8 containing nothing but references, will be considered for review.
Submission link: https://sites.google.com/dstc.community/dstc8/paper-submission
Organizing Committee
Workshop Chair: Michel Galley (Microsoft Research AI)Challenge Chair: Seokhwan Kim (Amazon Alexa AI)Publication Chair: Chulaka Gunasekara (IBM Research AI)Publicity Chair: Sungjin Lee (Amazon Alexa AI)
For a full listing of the track organizers and the steering committee members, please refer to the supplemental workshop website.
Additional Information
Supplemental workshop site: https://sites.google.com/dstc.community/dstc8/home

W10 — Engineering Dependable and Secure Machine Learning Systems
Nowadays, machine learning solutions are widely deployed. Like other systems, ML systems must meet quality requirements. However, ML systems may be non-deterministic; they may re-use high-quality implementations of ML algorithms; and, the semantics of models they produce may be incomprehensible. Consequently, standard notions of software quality and reliability such as deterministic functional correctness, black box testing, code coverage, and traditional software debugging become practically irrelevant for ML systems. This calls for novel methods and new methodologies and tools to address quality and reliability challenges of ML systems.
In addition, broad deployment of ML software in networked systems inevitably exposes the ML software to attacks. While classical security vulnerabilities are relevant, ML techniques have additional weaknesses, some already known (e.g., sensitivity to training data manipulation), and some yet to be discovered. Hence, there is a need for research as well as practical solutions to ML security problems.
With these in mind, this workshop solicits original contributions addressing problems and solutions related to dependability, quality assurance and security of ML systems. The workshop combines several disciplines, including ML, software engineering (with emphasis on quality), security, and algorithmic game theory. It further combines academia and industry in a quest for well-founded practical solutions.
Topics of interest include, but are not limited to:







Software engineering aspects of ML systems and quality implications
Testing of the quality of ML systems over time
Debugging of ML systems
Quality implication of ML algorithms on large-scale software systems
Case studies of successful and unsuccessful applications of ML techniques
Correctness of data abstraction, data trust
Choice of ML techniques to meet security and quality
Size of the training data, implied guaranties
Application of classical statistics to ML systems quality
Sensitivity to data distribution diversity and distribution drift
The effect of labeling costs on solution quality (semi-supervised learning)
Reliable transfer learning
Vulnerability, sensitivity and attacks against ML
Adversarial ML and adversary-based learning models
Strategy-proof ML algorithms







Submissions
We solicit original papers in two formats – full (8 pages) and short (4 pages, work in progress), in AAAI format. Submission will be via EasyChair (a URL will be provided soon). All authors of accepted papers will be invited to participate. The workshop will include paper presentation sessions. Full papers are allocated 20m presentation and 10m discussion. Short papers 10-minute presentation, plus 5-minute discussion.
Organizing Committee
Eitan Farchi (DE, Software Testing Analysis and Reviews, IBM Research, Haifa, farchi@il.ibm.com), Onn Shehory (Intelligent Information Systems, Graduate School of Business Administration, Bar Ilan University, onn.shehory@biu.ac.il), Guy Barash (Machine learning and Algorithm dev. , Western Digital Corporation, Israel, Guy.Barash@wdc.com)
Additional Information
Supplemental workshop site: https://sites.google.com/view/edsmls2020/home

W11 — Evaluating Evaluation of AI Systems
The last decade has seen massive progress in AI research powered by crowdsourced datasets and benchmarks such as Imagenet, Freebase, SQuAD; as well as widespread adoption and increasing use of AI in deployed systems. A crucial ingredient is the role of crowdsourcing in operationalizing empirical ways for evaluating, comparing, and assessing the progress.
The focus of this workshop is not on evaluating AI systems, but on evaluating the quality of evaluations of AI systems. When these evaluations rely on crowdsourced datasets or methodologies, we are interested in the meta-questions around characterization of those methodologies. Some of the expected activities in the workshop include:
Asking the question of “what makes evaluations good’?Defining “what good looks like” in evaluations of different types of AI systems (image recognition, recommender systems, search, voice assistants, etc).Collecting, examining and sharing current evaluation efforts, comprehensive of one system or competitive of multiple systems with the goal of critically evaluating the evaluations themselvesDeveloping an open repository of existing evaluations with methodology fully documented and raw data and outcomes available for public scrutiny
Using crowdsourced datasets for evaluating AI systems’ success at tasks such as image labeling and question answering have proven powerful enablers for research. However, adoption of such datasets is typically driven by the mere existence and size of a dataset without proper scrutiny of its scope, quality, and limitations. While crowdsourcing has enabled a burst of published work on specific problems, determining if that work has resulted in real progress cannot continue without a deeper understanding of how the dataset supports the scientific or performance claims of the AI systems it is evaluating. This workshop will provide a forum for growing our collective understanding of what makes a dataset good, the value of improved datasets and collection methods, and how to inform the decisions of when to invest in more robust data acquisition.
Topics
We invite scientific contributions and positions papers on the following topics:

META-EVALUATION: Quality of evaluation approaches, datasets / benchmarks

 Characteristics of ‘good’ dataset / benchmark?
Shortcomings of existing evaluation approaches, datasets / benchmarks?
Building new / improving existing metrics
Measuring trustworthiness, interpretability and fairness of crowdsourced benchmarks datasets
Measuring added value of improvements to previous versions of benchmark datasets
Comparative evaluations between mainstream AI systems, e.g. recommenders, voice assistants, etc.
Measuring quality of guidelines for content moderation, search evaluation, etc.
Comparison of results between offline (e.g. crowdsourced) and online (e.g. A/B testing) evaluations?
Open questions and challenges in meta-evaluation?




TRANSPARENCY: Making quality and characteristics of (crowdsourced) benchmark datasets transparent and explainable

Reproducibility of crowdsourced datasets
Replicability of crowdsourced evaluations of AI systems
Explainability of crowdsourced evaluations to different stakeholders, e.g. users, scientists, developers




RESOURCE BUILDING: Making existing evaluation methodologies, raw data and outcomes, discoverable, fully documented and available for public scrutiny

How do we make evaluations and related datasets archival and discoverable?
What can we learn from other systematic evaluation efforts and communities such as TREC, SIGIR, etc.?



Submissions
Submission information will be available shortly.

Submission Deadline: November 22, 2019
Notification of acceptance: December 11, 2019
Final camera-ready papers due: December 18, 2019

Organizing Committee
Praveen Paritosh, Kurt Bollacker, Maria Stone, Lora Aroyorigorous-evaluation@googlegroups.com
Additional Information
Supplemental workshop site: http://eval.how/aaai-2020/

W12 — Generalization in Planning
Humans are good at solving sequential decision-making problems, generalizing from few examples, and transferring this knowledge to solve new unseen problems. These problems remain longstanding open problems for Artificial Intelligence (AI). In the last decade, the planning community has improved the performance of automated planning systems to solve decision making problems by including novel search techniques and heuristics. On the other hand, the learning community has made major breakthroughs in reinforcement learning techniques for solving planning problems. However, industry level scalability and skill/task generalization still remains an open challenge for current AI tools.
This workshop will feature a mix of invited talks, survey talks in a highlights format, as well as presentations of submitted papers. We aim to synthesize and highlight recent research on the topic from multiple sub-fields of AI, including those of reinforcement learning, classical planning, planning under uncertainty, as well as learning for planning. At the end of the workshop we expect to come up with new insights and topics to address the challenges of generalization in planning.
Topics
Topics of interest to this workshop bring together research being conducted in a range of areas, including classical planning, knowledge engineering, partial policies and reinforcement learning, plan verification, and model checking. Potential topics include but are not limited to:







Learning and deriving generalized plans
Learning generalizable policies with reinforcement learning
Transfer learning of generalizable policies
Representation of generalizable solutions
Deriving domain control knowledge and partial policies with planning and learning
Program synthesis
Heuristics for plan and policy generalization
Generation and detection of good examples for planning and learning
Generalized planning for problems with partial observability and/or noise
Learning models for generalizable planning
Model checking for generalization guarantees







Format
The workshop will feature multiple invited plenary and highlight talks as well as presentations of submitted technical and position papers. It will also include discussion sessions tuned to the topics presented at the workshop.
Submissions
Papers should be submitted via EasyChair at https://easychair.org/conferences/?conf=genplan20.
Submission deadline: November 1, 2019Notification: December 4, 2019
Organizing Committee
Javier Segovia-Aguas (Institut de Robòtica i Informàtica Industrial (IRI), Spain, jsegovia@iri.upc.edu), Siddharth Srivastava (Arizona State University, USA, siddharths@asu.edu), Raquel Fuentetaja (Universidad Carlos III de Madrid, Spain, rfuentet@inf.uc3m.es), Aviv Tamar (Israel Institute for Technology, Israel, aviv.tamar.mail@gmail.com), Anders Jonsson (Universitat Pompeu Fabra, Spain, anders.jonsson@upf.edu)
Additional Information
Supplemental workshop site: https://sites.google.com/view/genplan20/

W13 — Health Intelligence
Public health authorities and researchers collect data from many sources and analyze these data together to estimate the incidence and prevalence of different health conditions, as well as related risk factors. Modern surveillance systems employ tools and techniques from artificial intelligence and machine learning to monitor direct and indirect signals and indicators of disease activities for early, automatic detection of emerging outbreaks and other health-relevant patterns. To provide proper alerts and timely response, public health officials and researchers systematically gather news and other reports about suspected disease outbreaks, bioterrorism, and other events of potential international public health concern, from a wide range of formal and informal sources. Given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. This is especially the case for non- traditional online resources such as social networks, blogs, news feed, twitter posts, and online communities with the sheer size and ever-increasing growth and change rate of their data. Web applications along with text processing programs are increasingly being used to harness online data and information to discover meaningful patterns identifying emerging health threats. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real-time data on epidemics.
Moreover, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork among patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All of these changes require novel solutions and the AI community is well-positioned to provide both theoretical- and application-based methods and frameworks. The goal of this workshop is to focus on creating and refining AI-based approaches that (1) process personalized data, (2) help patients (and families) participate in the care process, (3) improve patient participation, (4) help physicians utilize this participation in order to provide high quality and efficient personalized care, and (5) connect patients with information beyond that available within their care setting. The extraction, representation, and sharing of health data, patient preference elicitation, personalization of “generic” therapy plans, adaptation to care environments and available health expertise, and making medical information accessible to patients are some of the relevant problems in need of AI-based solutions.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. The scope of the workshop includes, but is not limited to, the following areas:







Knowledge Representation and Extraction
Integrated Health Information Systems
Patient Education
Patient-Focused Workflows
Shared Decision Making
Geographical Mapping and Visual Analytics for Health Data
Social Media Analytics
Epidemic Intelligence
Predictive Modeling and Decision Support
Semantic Web and Web Services
Biomedical Ontologies, Terminologies, and Standards
Bayesian Networks and Reasoning under Uncertainty
Temporal and Spatial Representation and Reasoning
Case-based Reasoning in Healthcare
Crowdsourcing and Collective Intelligence
Risk Assessment, Trust, Ethics, Privacy, and Security
Sentiment Analysis and Opinion Mining
Computational Behavioral/Cognitive Modeling
Health Intervention Design, Modeling and Evaluation
Online Health Education and E-learning
Mobile Web Interfaces and Applications
Applications in Epidemiology and Surveillance (e.g. Bioterrorism, Participatory Surveillance,
Syndromic Surveillance, Population Screening)
Explainable AI (XAI) in Health and Medical domain
Precision Medicine and Health







Format
The workshop will consist of a welcome session, a keynote talk, full/short paper presentations, demos, and posters.
Submissions
We invite researchers and industrial practitioners to submit their original contributions following the AAAI format through EasyChair (https://easychair.org/conferences/?conf=w3phiai20). Three categories of contributions are sought: full-research papers up to 8 pages; short papers up to 4 pages; and posters and demos up to 2 pages.
Organizing Committee
Martin Michalowski, Cochair, (University of Minnesota – Twin Cities, martinm@umn.edu); Arash Shaban-Nejad, Cochair, (The University of Tennessee Health Science Center – Oak-Ridge National Lab (UTHSC-ORNL) Center for Biomedical Informatics, ashabann@uthsc.edu); Szymon Wilk, (Poznan University of Technology); David L. Buckeridge, (McGill University); John S. Brownstein, (Boston Children’s Hospital, Harvard University); Byron C. Wallace, (Northeastern University); Michael J. Paul, (The University of Colorado Boulder)
Additional Information
Supplemental workshop site: http://w3phiai2020.w3phi.com/

W14 — Intelligent Process Automation
How to free people from the mundane and repetitive parts of their daily workload? Robotic Process Automation (RPA) addresses this problem by developing software agents (robots) that can mimic human users to perform a variety of business tasks on their computers.
Current RPA systems are mostly rule-based. Artificial Intelligence (AI) promises to take RPA to new heights, but so far the AI research efforts related to the different aspects of RPA have been largely isolated. This AAAI-2020 workshop aims to bridge the gap between the rapidly growing RPA software industry and the AI research community.
Topics
Technical topics include, but are not limited to:







demo2process (learning a task-completion software agent from human demonstrations or behaviour logs): interactive task learning, imitation learning, program induction, programming by example, process mining, …
text2process (learning a task-completion software agent from step-by-step natural language text descriptions of the process): learning by instruction, conversational machine learning, natural language programming, natural language grounding, …
task2process (learning a task-completion software agent directly from the task as defined by an environment with its reward function or some input/output examples): reinforcement learning, neural program synthesis, Bayesian program learning, …







The common theme is that the learning system’s output would not be simply class labels or numerical predictions, but structured & executable processes, which makes it more challenging than most of today’s machine learning research problems. In addition, such automated processes should be safe, robust and explainable.
Submissions
This workshop also encourages submissions on the following interdisciplinary topics:







human-in-the-loop: the interaction between human users and software robots.
human-outside-the-loop: the social and organizational impacts of software robots.







We welcome submissions of long (6-8 pages) or short (2-4 pages) papers describing new, previously unpublished research in this field. All submissions should be done electronically through EasyChair. The accepted papers will be published on arXiv and they will be included in a non-archival workshop proceedings. Blue Prism will sponsor a Best Paper Award of $1000.
Format
This workshop will last one full day. It will include invited talks, presentations of contributed papers, and a panel discussion. A complimentary lunch will be provided for workshop participants at Blue Prism’s New York office.
Organizing Committee
Dell Zhang, Cochair (Birkbeck, University of London, Malet Street, London WC1E 7HX, UK, dell.z@ieee.org), Andre Freitas, Cochair (University of Manchester, Kilburn Building, Oxford Road, Manchester M13 9PL, UK, andre.freitas@manchester.ac.uk), Dacheng Tao (University of Sydney, dacheng.tao@sydney.edu.au), Dawn Song (UC Berkeley, dawnsong@cs.berkeley.edu)
Additional Information
Supplemental workshop site: https://www.blueprism.com/events/AAAI-20-Workshop-on-Intelligent-Process-Automation

W15 — Interactive and Conversational Recommendation Systems (WICRS)
This workshop is positioned as a forum to present and discuss novel research directions in interactive and conversational recommender systems as well as constituent AI technologies that represent the next generation of recommender systems and personalized, conversational assistants.
Historical work on recommender systems focused on interactive and conversational aspects as evidenced by the large literature on critiquing-based interaction dating back to the 1990’s. With the dawn of the Netflix Challenge, a sizable fraction of recommendation research shifted away from interaction and conversation and focused more on formal machine learning aspects of training objectives and optimization on offline data. However, recent years have seen an increase in work in interactive, sequential (e.g., session-based) interactions with recommender systems. Furthermore, the rise of Conversational AI-based assistants in the form of Apple’s Siri, Amazon’s Alexa, and the Google Assistant have re-invigorated interest in dialog-based sequential interaction, with a limited degree of personalization.
Encouraged by this recent interest in interactive and conversational recommender systems, the workshop aspires to bring together AI researchers from recommender systems, machine and reinforcement learning, dialog systems, natural language processing, human computer interaction, psychology and econometrics for a day of research presentations and open discussion about the future of this high impact and highly cross-disciplinary research area.
Topics
Topics include (but are not limited to):







Goal-directed and Personalized Conversational AI
Critiquing-based Recommendation Systems
Reinforcement Learning in Multi-turn Interactions
User Privacy and Security
Multimodal Context and Situation-aware Modeling
Preference Elicitation and Preference Construction
Recommendation with Complex Preferences
Explanations and Endorsements in Recommendation
Human-Computer Interaction in Recommendation
Grounding Dialog in Preferences and Constraints
Natural Language Expression of Preferences
Expressing Preferences over Latent Embeddings
Simulation Environments and Benchmark Datasets
Evaluation and Metrics
User Choice Modeling
Theory of Mind and Mental Model Representations







Submissions
We welcome previously unsubmitted work, papers submitted to the main AAAI conference, and papers reporting research already published provided they align well with the workshop topic.
Three types of submissions are solicited:







Full-length papers (up to 7 pages + 1 page for references in AAAI format)
Challenge or position papers (2 pages + 1 page for references in AAAI format)
Already published papers (1 page: an abstract in AAAI format with a link to the full paper)







Paper Submissions should be made through the workshop EasyChair web site: https://easychair.org/conferences/?conf=wicrs20
Organizing Committee
Scott Sanner (University of Toronto), Tyler Lu (Google Research), Joyce Chai (University of Michigan), Deepak Ramachandran (Google Research)Email: wicrs20@easychair.org
Additional Information
Supplemental workshop site: https://sites.google.com/view/wicrs2020

W16 — Knowledge Discovery from Unstructured Data in Financial Services
Knowledge discovery from unstructured data has gained the attention of many practitioners over the past decades. In spite of major AI research focusing on data sources like news, web, and social media, its application to data in professional settings such as legal documents and financial filings, still present huge challenges.
In the financial services industry in particular, vast analysis work requires knowledge discovery from various data sources, such as SEC filings, loan documents, and industry reports. The manual knowledge discovery and extraction process is usually low in efficiency, error prone, and inconsistent. It is one of the key bottlenecks for financial services companies in improving their operating productivity. Furthermore, alternative data like social media feeds and news are gaining traction as promising knowledge sources for financial institutions as they provide additional perspectives when they make investment decisions. However, the valuable knowledge is always comingled with immense noise and the precision and recall requirements for extracted knowledge to be used in business process are fastidious.
These challenges and issues call for the need of robust artificial intelligence (AI) algorithms and systems. The design and implementation of these AI techniques to meet financial business operations requires the joint effort between academia researchers and industry practitioners.
Topics
We invite submissions of original contributions on methods, applications, and systems on artificial intelligence, machine learning, and data analytics, with a focus on knowledge discovery and extraction in the financial services domain. The scope of the workshop includes, but is not limited to, the following areas:







Knowledge representation
Natural language processing and understanding for financial documents
Search and question answering systems designed for financial corpora
Named-entity recognition, disambiguation, relationship discovery, ontology learning and extraction from financial documents
Knowledge alignment and integration from heterogeneous data;
AI assisted data tagging and labeling
Data acquisition, augmentation, feature engineering, and analysis for investment and risk management
Data acquisition, augmentation, feature engineering, and analysis for investment and risk management
Automatic knowledge extraction from financial fillings and quality verification
AI systems for relationship extraction and risk assessment from legal documents
Event discovery from alternative data and impact on organization equity price







We also encourage submissions of studies or applications pertinent to finance using other types of unstructured data such as financial transactions, sensors, mobile devices, satellites, social media.
Format
KDF is a one-day workshop. The program of the workshop will include invited speakers, paper presentations, and poster sessions.
We cordially welcome researchers, practitioners, and students from academic and industrial communities who are interested in the topics to participate; at least one author of each accepted submission must be present at the workshop.
Submissions
We invite submissions of relevant work that be of interest to the workshop. All submissions must be original contributions, following the AAAI-20 formatting guidelines. We accept two types of submissions – full research paper no longer than 8 pages and short/poster paper with 2-4 pages.
Submissions will be accepted via EasyChair submission website https://easychair.org/conferences/?conf=kdf2020
Organizing Committee
Xiaomo Liu (S&P Global, xiaomo.liu@spglobal.com), Sameena Shah (S&P Global, sameena.shah@spglobal.com), Manuela M. Veloso (J.P. Morgan Chase and Carnegie Mellon University, manuela.veloso@jpmchase.com), Quanzhi Li (Alibaba Group, quanzhi.li@alibaba-inc.com), Le Song (Ant Financial and Georgia Institute of Technology, e.song@antfin.com)
Additional Information
Supplemental workshop site: https://aaai-kdf2020.github.io/

W17 — Plan, Activity, and Intent Recognition (PAIR)
Plan recognition, activity recognition, and intent recognition all involve making inferences about other actors from observations of their behavior, i.e., their interaction with the environment and with each other. The observed actors may be software agents, robots, or humans. This synergistic area of research combines and unifies techniques from user modeling, machine vision, intelligent user interfaces, human/computer interaction, autonomous and multi-agent systems, natural language understanding, and machine learning. It plays a crucial role in a wide variety of applications including:







Assistive technology
Software assistants
Computer and network security
Behavior recognition
Coordination in robots and software agents
E-commerce and collaborative filtering







This wide-spread diversity of applications and disciplines, while producing a wealth of ideas and results, has contributed to fragmentation in the field, as researchers publish relevant results in a wide spectrum of journals and conferences. As there is no commonly accepted conference for this work, the workshop we propose will provide a valuable place to discuss, standardize and improve past work of this sub-field.
This workshop seeks to bring together researchers and practitioners from diverse backgrounds, to share ideas and recent results. It will aim to identify important research directions, opportunities for synthesis and unification of representations and algorithms for recognition. Contributions of research results are sought in the following areas of:







Plan, activity, intent, or behavior recognition
Adversarial planning, opponent modeling
Modeling multiple agents, modeling teams
User modeling on the web and in intelligent user interfaces
Acquaintance models
Plan recognition and user modeling in marketplaces and e-commerce
Intelligent tutoring systems (ITS)
Machine learning for plan recognition and user modeling
Personal software assistants
Social network learning and analysis
Monitoring agent conversations (overhearing)
Observation-based coordination and collaboration (teamwork)
Multi-agent plan recognition
Observation-based failure detection
Monitoring multi-agent interactions
Uncertainty reasoning for plan recognition
Commercial applications of user modeling and plan recognition
Representations for agent modeling
Modeling social interactions
Inferring emotional states
Reverse engineering and program recognition
Programming by demonstration
Imitation







Due to the diversity of disciplines engaging in this area, related contributions in other fields, are also welcome.
This year’s workshop will be centered around the relationship between data-driven and model-based approaches to recognition, and the need to bridge the gap between the two approaches. We hope this workshop will provide opportunities and incentives for future work. Specifically, we intend to extend our community by reaching out to recognition researchers from the machine learning community and encourage them to submit their work to the workshop.
Submissions
All submissions must be original. If a work is under submission for the main conference as well or for a different conference, it should be written in the title. Papers must be in trouble-free, high-resolution PDF format, formatted for US Letter (8.5″ x 11″) paper, using Type 1 or TrueType fonts. Submissions are anonymous, and must conform to the AAAI-20 instructions for double-blind review.
CFP website (EasyChair): https://easychair.org/cfp/PAIR2020Submission website (EasyChair): https://easychair.org/conferences/?conf=pairaaai2020
Notification: December 10, 2019
Full PapersWe accept full paper submissions. Papers must be formatted in AAAI two-column, camera-ready style; see the 2020 author kit for details: http://www.aaai.org/Publications/Templates/AuthorKit20.zipSubmissions may have up to 8 pages with page 8 containing nothing but references. The last page of final papers may contain text other than references, but all references in the submitted paper should appear in the final version, unless superseded.
Demo TrackThis year the PAIR workshop will include a demo track. Authors are required to submit two items: (1) a 2-page short paper describing their system, formatted in AAAI two-column style, and (2) a video (of duration up to 10 minutes) of the proposed demonstration. Slides are also permitted in lieu of video, but greater weight will be given to submissions accompanied by videos. The paper must present the technical details of the demonstration, discuss related work, and describe the significance of the demonstration. The demo track will be chaired by Dr. Mor Vered; questions regarding demos should be referred to mor.vered@unimelb.edu.au.
PostersAuthors whose papers accepted to the workshop would be able to present their work in a joint poster session and panel.
Cochairs
Sarah Keren (primary contact)Harvard University,School of Engineering and Applied SciencesCambridge, MAEmail: sarah.e.keren@gmail.com or skeren@seas.harvard.edu
All questions about submissions should be emailed to Sarah Keren at sarah.e.keren@gmail.com.
Reuth MirskyUniversity of TexasDepartment of Computer ScienceAustin, TXEmail: reuth@cs.utexas.edu
Christopher GeibSIFT LLC319 1st Ave. North, Suite 400Minneapolis MN 55401-1689Email: cgeib@sift.net
Additional InformationSupplemental workshop site: http://www.planrec.org/PAIR/Resources.html

W18 — Privacy-Preserving Artificial Intelligence
The availability of massive amounts of data, coupled with high-performance cloud computing platforms, has driven significant progress in artificial intelligence and, in particular, machine learning and optimization. Indeed, much scientific and technological growth in recent years, including in computer vision, natural language processing, transportation, and health, has been driven by large-scale data sets which provide a strong basis to improve existing algorithms and develop new ones. However, due to their large-scale and longitudinal collection, archiving these data sets raise significant privacy concerns. They often reveal sensitive personal information that can be exploited, without the knowledge and/or consent of the involved individuals, for various purposes including monitoring, discrimination, and illegal activities.
The goal of the AAAI-20 Workshop on Privacy-Preserving Artificial Intelligence is to provide a platform for researchers to discuss problems and present solutions related to privacy issues arising within AI applications. The workshop will focus on both theoretical and practical challenges arising in the design of privacy-preserving AI systems and algorithms. It will place particular emphasis on algorithmic approaches to protect data privacy in the context of learning, optimization, and decision making that raise fundamental challenges for existing technologies. Additionally, it will welcome algorithms and frameworks to release privacy-preserving benchmarks and datasets.
Topics
We invite paper submissions on the following (and related) topics:







Applications of privacy-preserving AI systems
Architectures and privacy-preserving learning protocols
Constrained-based approaches to privacy
Differential privacy: theory and applications
Distributed privacy-preserving algorithms
Human-aware private algorithms
Incentive mechanisms and game theory
Privacy-preserving machine learning
Privacy-preserving algorithms for medical applications
Privacy-preserving algorithms for temporal data
Privacy-preserving test cases and benchmarks
Privacy and policy-making
Secure multi-party computation
Secret sharing techniques
Trade-offs between privacy and utility







Position, perspective, and vision papers are also welcome. Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and datasets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples.
Format
The workshop will be a full-day and will include a mix of invited speakers, peer-reviewed papers (talks and poster sessions) and will conclude with a panel discussion. Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-20 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentation at the workshop.
Submission Site: https://easychair.org/conferences/?conf=ppai20
Cochairs
Ferdinando Fioretto (Georgia Institute of Technology, fioretto@gatech.edu, http://nandofioretto.com), Pascal Van Hentenryck (Georgia Institute of Technology, pascal.vanhentenryck@isye.gatech.edu, http://pwp.gatech.edu/pascal-van-hentenryck/), Rachel Cummings (Georgia Institute of Technology, rachelc@gatech.edu, https://pwp.gatech.edu/rachel-cummings/)
Additional Information
Supplemental workshop site: https://www2.isye.gatech.edu/~fferdinando3/cfp/PPAI20

W19 — Reasoning and Learning for Human-Machine Dialogues (DEEP-DIAL20)
Natural conversation is a hallmark of intelligent systems. Unsurprisingly, dialog systems have been a key sub-area of AI for decades. Their most recent form, chatbots, which can engage people in natural conversation and are easy to build in software, have been in the news a lot lately. There are many platforms to create dialogs quickly for any domain based on simple rules. Further, there is a mad rush by companies to release chatbots to show their AI capabilities and gain market valuation. However, beyond basic demonstration, there is little experience in how they can be designed and used for real-world applications needing decision making under practical constraints of resources and time (e.g., sequential decision making) and being fair to people chatbots interact with.
The workshop is the third edition of the Workshop on Reasoning and Learning for Human-Machine Dialogues. Both the first edition, DEEP-DIAL18 (http://www.zensar.com/deep-dial18) held at AAAI-18 at New Orleans, USA in February 2018 and the second edition, DEEP-DIAL19 (https://sites.google.com/view/deep-dial-2019/), held at AAAI-19 at Honolulu, Hawaii, USA in January 2019, were huge successes attracting 100+ AI researchers to discuss a variety of topics.
DEEP-DIA20 will have reviewed paper presentations, invited talks, panels and open contributions of datasets and chatbots. The workshop is partially funded by a grant from AI Journal.
There is ever increasing interest and need for innovation in human-technology-interaction as addressed in the context of companion technology. Here, the aim is to implement technical systems that smartly adapt their functionality to their users’ individual needs and requirements and are even able to solve problems in close cooperation with human users. To this end, they need to enter into a dialog and should be able to convincingly explain their suggestions and their decision-making behavior.
From the research side, statistical and machine learning methods are well entrenched for language understanding and entity detection. However, the wider problem of dialog management is unaddressed with mainstream tools supporting rudimentary rule-based processing. There is an urgent need to highlight the crucial role of reasoning methods, like constraints satisfaction, planning and scheduling, and learning working together with them, can play to build an end-to-end conversation system that evolves over time. From the practical side, conversation systems need to be designed for working with people in a manner that they can explain their reasoning, convince humans about choices among alternatives, and can stand up to ethical standards demanded in real life settings.
Topics
With these motivations, some areas of interest for the workshop, but not limited to, are:







Dialog Systems

Design considerations for dialog systems
Evaluation of dialog systems, metrics
Open domain dialog and chat systems
Task-oriented dialogs
Style, voice and personality in spoken dialogue and written text
Novel Methods for NL Generation for dialogs
Early experiences with implemented dialog systems
Mixed-initiative dialogs where a partner is a combination of agent and human
Hybrid methods


Reasoning

Domain model acquisition, especially from unstructured text
Plan recognition in natural conversation
Planning and reasoning in the context of dialog systems
Handling uncertainty of conversation and data
Optimal dialog strategies


Learning

Learning to reason
Learning for dialog management
End2end models for conversation
Explaining dialog policy


Practical Considerations

Responsible chatting
Ethical issues with learning and reasoning in dialog systems
Corpora, Tools and Methodology for Dialogue Systems
Securing one’s chat









Submissions
Submissions must be formatted in AAAI two-column, camera-ready style (see https://www.aaai.org/Publications/Templates/AuthorKit20.zip). Regular research papers may be no longer than 7 pages, where page 7 must contain only references, and no other text whatsoever. Short papers, which describe a position on the topic of the workshop or a demonstration/tool, may be no longer than 4 pages, references included. The accepted papers will be linked from the workshop website to the public versions on ArXiv.
Electronic submissions to be uploaded at https://easychair.org/conferences/?conf=deepdial20
Notifications: November 30, 2019Camera-ready copy due: December 3, 2019:
Workshop Chairs
Ullas Nambiar (Accenture, India), Imed Zitouni (Google, USA), Kshitij Fadnis (IBM Research, USA), Biplav Srivastava (IBM, USA)
Additional Information
Supplemental workshop site: https://sites.google.com/view/deep-dial2020

W20 — Reasoning for Complex Question Answering
Question Answering (QA) has become a crucial application problem in evaluating the progress of AI systems in the realm of natural language processing and understanding, and to measure the progress of machine intelligence in general. At AAAI-20, the Reasoning for Complex Question Answering (RCQA) workshop series will feature a special focus on Commonsense Reasoning, and the overall umbrella area of Machine Common Sense (MCS). Commonsense Reasoning has long been a problem of interest to the AI community, and has spurred various efforts over the years that seek to standardize and encode commonsense knowledge for use by various AI systems. Machine Common Sense (MCS), taking after the name of a recent DARPA program, has once again become an area of focus. A large part of this is due to the realization that MCS may be the one of the biggest missing components in the transition of current day narrow AI systems into truly broader general AI systems.
Making progress on the MCS problem unlocks many potential solution techniques for AI systems, and makes them truly useful in various real world domains in related fields such as NLP and Computer Vision. However, such progress is contingent on addressing key problems such as: how to obtain commonsense knowledge; how to encode it into usable models and structures that are suitably agnostic of the specific reasoning technique employed; the (automated) construction of large-scale and cross-domain knowledge bases that store such knowledge; and measuring the progress in the state-of-the-art models and showing an advantage from using commonsense knowledge on standardized datasets.
Submissions
The workshop welcomes three kinds of paper submissions:(i) challenge papers (up to 2 pages long) that describe a new challenge in the workshop’s focus area;(ii) short papers (up to 4 pages long) which focus on a single, specific contribution; and(iii) full papers (up to 8 pages long);
with unrestricted following pages for references only. Submission length should be commensurate to the contribution of the paper, following the rough guidelines above. Submissions must be formatted in the AAAI submission format. Submissions will be reviewed for their relevance to the workshop topic, relevance to this year’s special focus, novelty of ideas, significance of results, and reusability of the contributions. The workshop is non-archival, and we welcome relevant submissions that have been published elsewhere in the very-recent past.
Organizing Committee
Kartik Talamadupula, IBM ResearchVered Shwartz, University of Washington / AI2Jay Pujara, ISI / USCRachel Rudinger, AI2 / UMDMausam, IIT DelhiNanyun Peng, ISI / USCPavan Kapanipathi, IBM Research
Additional Information
Supplemental workshop site: https://rcqa-ws.github.io/

W21 — Reinforcement Learning in Games
Games provide an abstract and formal model of environments in which multiple agents interact: each player has a well-defined goal and rules to describe the effects of interactions among the players. The first achievements in playing these games at super-human level were attained with methods that relied on and exploited domain expertise that was designed manually (e.g. chess, checkers). In recent years, we have seen examples of general approaches that learn to play these games via self-play reinforcement learning (RL), as first demonstrated in Backgammon. While progress has been impressive, we believe we have just scratched the surface of what is capable, and much work remains to be done in order to truly understand the algorithms and learning processes within these environments.
The main objective of the workshop is to bring researchers together to discuss ideas, preliminary results, and ongoing research in the field of reinforcement in games.
Topics
We invite participants to submit papers based on, but not limited to, the following topics: RL in various formalisms: one-shot games, turn-based, and Markov games, partially-observable games, continuous games, cooperative games; deep RL in games; combining search and RL in games; inverse RL in games; foundations, theory, and game-theoretic algorithms for RL; opponent modeling; analyses of learning dynamics in games; evolutionary methods for RL in games; RL in games without the rules; and Monte Carlo tree search, online learning in games.
Format
RLG is a full-day workshop. It will start with a 60-minute mini-tutorial covering a brief tutorial and basics of RL in games, 2-3 invited talks by prominent contributors to the field, paper presentations, a poster session, and will close with a discussion panel.
Submissions
Papers must between 4-8 pages in the AAAI submission format, with the eighth page containing only references. Papers will be submitted electronically using EasyChair. Accepted papers will not be archival, and we explicitly allow papers that are concurrently submitted to, currently under review at, or recently accepted in other conferences / venues.
Organizing Committee
Julien Perolat, Chair (perolat@google.com), Marc Lanctot (DeepMind, lanctot@google.com), Julien Perolat (DeepMind, perolat@google.com), Martin Schmid (DeepMind, mschmid@google.com)
Additional Information
Supplemental workshop site: http://aaai-rlg.mlanctot.info/

W22 — Reproducibility in AI (RAI 2020) — Future Direction and Reproducibility Challenge
Artificial Intelligence (AI), like any science, must rely on reproducible experiments to validate results. However, reproducing results from AI research publications is not easily accomplished. This may be because AI research has its own unique reproducibility challenges. For example, these include (1) the use of analytical methods that are still a focus of active investigation and (2) problems due to non-determinism in standard benchmark environments and variance intrinsic to AI methods. Acknowledging these difficulties, empirical AI research should be documented properly so that the experiments and results are clearly described.
AAAI does not provide any recommendations on how researchers can enhance the reproducibility of their work. In this AAAI-20 workshop, we aim to develop such recommendations, and to encourage future AAAI conferences to implement them.The goal is to finalize recommendations for AAAI 2021 and discuss how these should be evaluated. This year’s workshop is a continuation of the AAAI 2019 Workshop on Reproducible AI (RAI 2019) where we had several presentations and the attendees started discussing such recommendations.
Reproducibility ChallengeAs input to the discussion on recommendations, we will emphasize the submission and acceptance of papers in which researchers describe their experiences from attempting to reproduce a paper(s) accepted at a previous AAAI conference(s) (i.e., try to reproduce the results from a previous AAAI conference paper and report your results).
Submissions should contain a description of the experiment, whether the results of the original paper were reproduced or not, a discussion on reproducibility challenges, lessons learned, and recommendations for best practices as well as a short note on each of the 24 variables presented in by Gundersen, Gil and Aha (2018) (https://folk.idi.ntnu.no/odderik/RAI-2020/On_Reproducible_AI-preprint.pdf).
Topics
Any topics related to reproducible AI are welcome, including position papers, surveys, recommendations, and comparisons of AI reproducibility with other fields of research. Our focus is especially on practical solutions for how to improve the reproducibility of research presented at AAAI.
Relevant reading: See suggested reading list at https://folk.idi.ntnu.no/odderik/RAI-2020/Suggested_Readings.pdf.
Format
The workshop will last span a full day and will include invited talks, oral and poster presentations of submitted work, a panel and open discussion on how to make research results presented at AAAI reproducible.
Submissions
Each submission will be in the form of a maximum 8-page paper including reference, using the main AAAI conference format. Authors can optionally anonymize their submissions. Papers should be submitted via EasyChair. Oral presentation authors and poster session participants will be selected from the submissions. Please send an email to the workshop chairs if you are considering submitting a paper.
Submission site: https://easychair.org/conferences/?conf=rai2020
Chairs
Odd Erik Gundersen (Norwegian University of Science and Technology, odderik@ntnu.no),David W. Aha (Naval Research Laboratory, david.aha@nrl.navy.mil), Daniel Garijo (Univeristy of Southern California, dgarijo@isi.edu)
Additional Information
Supplemental workshop site: https://folk.idi.ntnu.no/odderik/RAI-2020/

W23 — Statistical Relational AI (StarAI)
The purpose of the Statistical Relational AI (StarAI) workshop is to bring together researchers and practitioners from three fields: logical (or relational) AI/learning, probabilistic (or statistical) AI/learning and neural approaches for AI/learning with knowledge graphs and other structured data. These fields share many key features and often solve similar problems and tasks. Until recently, however, research in them has progressed independently with little or no interaction. The fields often use different terminology for the same concepts and, as a result, keeping-up and understanding the results in the other field is cumbersome, thus slowing down research. Our long term goal is to change this by achieving synergy between logical, statistical and neural AI. As a stepping stone towards realising this big-picture view on AI, we are organizing the Ninth International Workshop on Statistical Relational AI at AAAI-20.
Topics
StarAI is currently provoking a lot of new research and has tremendous theoretical and practical implications. The focus of the workshop will be on general-purpose representation, reasoning and learning tools for StarAI as well as practical applications. Specifically, the workshop will encourage active participation from researchers in the following communities, and integration thereof: satisfiability, knowledge representation, constraint satisfaction and programming, (inductive) logic programming, graphical models and probabilistic reasoning, statistical learning, relational embeddings, neural-symbolic integration, graph mining and probabilistic databases. It will also actively involve researchers from more applied communities, such as natural language processing, information retrieval, vision, semantic web and robotics. We seek to invite researchers in all subfields of AI to attend the workshop and to explore together how to reach the goals imagined by the early AI pioneers.
Format
StarAI will be a one-day workshop with short paper presentations, a poster session, and three invited speakers. Attendance is open to all.
Submissions
Authors should submit one of the following:







a full paper reporting on novel technical contributions or work in progress (AAAI style, up to 7 pages excluding references),
a short position paper (AAAI style, up to 2 pages excluding references),
an already published work (verbatim, no page limit, citing original work) in PDF format via EasyChair.







All submitted papers will be carefully peer-reviewed by multiple reviewers and low-quality or off-topic papers will be rejected.
Submission site: https://easychair.org/conferences/?conf=starai2020
Organizing Committee
Sebastijan Dumančić (KU Leuven, sebastijan.dumancic@cs.kuleuven.be), Angelika Kimmig (Cardiff University, KimmigA@cardiff.ac.uk), David Poole (UBC, poole@cs.ubc.ca), Jay Pujara (USC, jay@cs.umd.edu)
Additional Information
Supplemental workshop site: http://www.starai.org/2020",2020
"This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2019 AAAI
",2020
"AAAI-21 Workshop Program
The Thirty-Fifth AAAI Conference on Artificial IntelligenceFebruary 8-9, 2021A Virtual Conference

2020 AAAI Author Kit

AAAI is pleased to present the AAAI-21 Workshop Program. Workshops will be held virtually Monday and Tuesday, February 8-9, 202. The final schedule will be available in October. The AAAI-21 workshop program includes 26 workshops covering a wide range of topics in artificial intelligence. Workshops are one day unless otherwise noted in the individual descriptions. Registration in each workshop is required by all active participants, and is also open to all interested individuals. Workshop registration is available to AAAI-21 technical registrants at a discounted rate, or separately to workshop only registrants. Registration information will be mailed directly to all invited participants in December. ",2021
"Important Dates for Workshop Organizers


November 9: Submissions due (unless noted otherwise)
 November 30: Notification of acceptance (unless noted otherwise)
 December 18: Early registration deadline
 February 8-9: AAAI-21 Workshop Program
",2021
" 

W1: Affective Content Analysis (AffCon@AAAI 2021)
W2: AI for Behavior Change
W3: AI for Urban Mobility
W4: Artificial Intelligence Safety (SafeAI)
W5: Combating Online Hostile Posts in Regional Languages during Emergency Situations (CONSTRAINT-2021)
W6: Commonsense Knowledge Graphs (CSKGs)
W7: Content Authoring and Design
 W8: Deep Learning on Graphs: Methods and Applications (DLG-AAAI’21)
W9: Designing AI for Telehealth
W10: 9th Dialog System Technology Challenge (DSTC9)
W11: Explainable Agency in Artificial Intelligence 
W12: Graphs and More Complex Structures for Learning and Reasoning (GCLR) 
W13: 5th International Workshop on Health Intelligence (W3PHIAI-21) 
W14: Hybrid Artificial Intelligence
W15: Imagining Post-COVID Education with AI
W16: Knowledge Discovery from Unstructured Data in Financial Services
W17: Learning Network Architecture During Training
W18: Meta-Learning and Co-Hosted Competition
W19: Meta-Learning for Computer Vision (ML4CV)
W20: Plan, Activity, and Intent Recognition (PAIR) 2021
W21: Privacy-Preserving Artificial Intelligence
W22: Reasoning and Learning for Human-Machine dialogs (DEEP-DIAL21)
W23: Reinforcement Learning in Games
W24: Scientific Document Understanding
W25: Towards Robust, Secure and Efficient Machine Learning
W26: Trustworthy AI for Healthcare
",2021
"
W1: Affective Content Analysis (AffCon)
AffCon-2021 is the fourth Affective Content Analysis workshop @ AAAI. The workshop series (i) builds upon the state of the art in neural and AI methods, for modeling affect in interpersonal interactions and behaviors and (ii) brings a confluence of research viewpoints representing several disciplines.
The word ‘affect’ refers to emotion, sentiment, mood, and attitudes including subjective evaluations, opinions, and speculations. Psychological models of affect are adopted by several disciplines to conceptualize and measure users’ opinions, intentions, motives, and expressions. Computational models of such measurement may not recognize the context of affect generated in and through human interactions.
Topics
The 2021 edition of the workshop takes interaction in yet another new direction. A large share of content created are outcomes of collaboration. A basic question worth examining is whether and how collaboration among creatives impact the affective characteristics of the content. A follow up question then is how to model and computationally measure affect in collaborative creation.
This year, collaboration takes on an extra meaning in a physically distanced world. Understanding the dynamics of affect in collaborative content is more topical. The theme for AffCon@AAAI-2021 is ‘Affect in Collaborative Creation’. This is relevant for increasingly decentralized workplaces, asynchronous collaborations, and computer-mediated communication. Studying and codifying user reactions in this setup can help understand the society and aid towards better tools for content analysis.
We invite research spanning both creation and consumption of content, especially for cooperative tasks. Our focus on affective content in collaborations includes, but is not limited to, collectively created content, reactions in groups, interactions through avatars, and multi-modal interfaces. We also strongly encourage research that explores these themes, and group dynamics in content creation and in affective reactions.

Affect in Collaborative Content
Affect in Communication co-creation
Affective Reactions in Co-creation and collaboration
Affectively responsive interfaces
Deep learning-based models for affect modeling in content (image, audio, and video)
Mirroring affect
Psycho–demographic Profiling
Affect–based Text Generation
Multi-modal Affect
Stylometrics, Typographics, and Psycho-linguistics
Cognitive and psychological computational models of creativity
Affective needs and Firm-Consumer co-creation Behavior
Computational models for Consumer Behavior theories of innovation
Affective Lexica for Online Marketing Communication
Affective human-agent, human-computer, and human-robot interaction

We especially invite papers investigating multiple related themes, industry papers, and descriptions of running projects and ongoing work. To address the scarcity of standardized baselines, datasets, and evaluation metrics for cross- disciplinary affective content analysis, submissions describing new language resources, evaluation metrics, and standards for affect analysis and understanding are also strongly encouraged.
Shared Task: CL-Aff
We are pleased to announce the 2021 CL-Aff Shared Task: GoTeam, which will examine the challenges of affect in collaboration in a multimodal dataset comprising both, textual communication and interpersonal actions.
Format
This full-day workshop will have several prominent interdisciplinary invited speakers from the fields of linguistics, psychology, and marketing science to lead the presentation sessions. Each session will consist of a keynote, followed by research presentations, and a short informal poster session. There are expected to be approximately 70-80 attendees.
Submissions
EasyChair Submission URL
Submissions should be made via EasyChair and must follow the formatting guidelines for AAAI-2021 (use the 2020 AAAI Author Kit). All submissions must be anonymous and conform to AAAI standards for double-blind review. Both full papers (8 page long including references) and short papers (4 page long including references) that adhere to the 2-column AAAI format will be considered for review.
Organizing Committee
Niyati Chhaya, Primary Contact (Adobe Research, nchhaya@adobe.com), Kokil Jaidka (Nanyang Technological University, kokil.j@gmail.com ), Jennifer Healey (Adobe Research, jehealey@adobe.com), Lyle Ungar (University of Pennsylvania, ungar@cis.upenn.edu), Atanu R Sinha (Adobe Research, atr@adobe.com)
Additional Information
Workshop URL

W2: AI for Behavior Change
In domains as wide-ranging as medication adherence, vaccination, college enrollment, retirement savings, and energy consumption, behavioral interventions have been shown to encourage people towards making better choices. For many applications of AI in these areas, one needs to design systems that learn to motivate people to take actions that maximize their welfare. Large data sources, both conventionally used in social sciences (EHRs, health claims, credit card use, college attendance records) and unconventional (social networks, fitness apps), are now available, and are increasingly used to personalize interventions. These datasets can be leveraged to learn individuals’ behavioral patterns, identify individuals at risk of making sub-optimal or harmful choices, and target them with behavioral interventions to prevent harm or improve well-being. At the same time, there is an increasing interest in AI in moving beyond traditional supervised learning approaches towards learning causal models, which can support the identification of targeted behavioral interventions. These research trends inform the need to explore the intersection of AI with behavioral science and causal inference, and how they can come together for applications in the social and health sciences.
This workshop will focus on AI and ML-based approaches that can (1) identify individuals in need of behavioral interventions, and/or predict when they need them; (2) help design and target optimal interventions; and (3) exploit observational and/or experimental datasets in domains including social media, health records, claims data, fitness apps, etc. for causal estimation in the behavior science world.
Topics
The goal of this workshop is to bring together the causal inference, artificial intelligence, and behavior science communities, gathering insights from each of these fields to facilitate collaboration and adaptation of theoretical and domain-specific knowledge amongst them. We invite thought-provoking submissions on a range of topics in these fields, including, but not limited to the following areas:

Intervention design
Adaptive treatment assignment
Heterogeneity estimation
Optimal assignment rules
Targeted nudges
Observational-experimental data
Mental health/wellness; habit formation
Social media interventions
Precision health

Format
The full-day workshop will start with a keynote talk, followed by an invited talk and contributed paper presentations in the morning. The post-lunch session will feature a second keynote talk, two invited talks, and contributed paper presentations. Papers more suited for a poster, rather than a presentation, would be invited for a poster session. We will also select up to 5 best posters for spotlight talks (2 minutes each). We will end the workshop with a panel discussion by top researchers from these fields to enlist future directions and enhancement to this workshop.
Invited Speakers
Invited speakers will include Susan Athey, keynote (Economics of Technology, Stanford University, Sendhil Mullainathan, keynote (Computation and Behavioral Science, University of Chicago), Eric Tchetgen Tchetgen (Statistics, University of Pennsylvania), Jon Kleinberg (Computer Science, Cornell University), and Munmun De Choudhury (Interactive Computing, Georgia Tech)
Submissions
The audience of this workshop will be researchers and students from a wide array of disciplines including, but not limited to, statistics, computer science, economics, public policy, psychology, management, and decision science, who work at the intersection of causal inference, machine learning, and behavior science. AAAI, specifically, is a great venue for our workshop because its audience spans many ML and AI communities. We invite novel contributions following the AAAI formatting guidelines, camera-ready style. Submissions will be peer reviewed, single-blinded. Submissions will be assessed based on their novelty, technical quality, significance of impact, interest, clarity, relevance, and reproducibility. We accept two types of submissions — full research papers no longer than 8 pages (including references) and short/poster papers with 2-4 pages. References will not count towards the page limit. Submission will be accepted via the Easychair submission website.
Organizing Committee
Lyle Ungar (University of Pennsylvania, ungar@cis.upenn.edu), Sendhil Mullainathan (University of Chicago, Sendhil.Mullainathan@chicagobooth.edu), Eric Tchetgen Tchetgen (University of Pennsylvania, ett@wharton.upenn.edu), Rahul Ladhania, primary contact, (University of Michigan, ladhania@umich.edu)
Additional Information
Supplemental workshop site: https://ai4bc.github.io/ai4bc21/For general inquiries about AI4BC, please write to ai4behaviorchange@gmail.com.

W3: AI for Urban Mobility
This workshop aims to provide a forum for bringing together experts from the different fields of AI to discuss the challenges related to any area of Urban Mobility, from the perspective of how AI techniques can be leveraged to address these challenges and whether novel AI techniques have to be developed.
Topics
This workshop seeks papers ranging from experience reports to the description of new technology leveraging AI various AI for innovation in any area of Urban Mobility and Transportation, such as (but not limited to): Traffic Signal Control, Vehicle Routing, Autonomous Driving, Multi-modal planning, and on-demand transport.
Format
This one-day workshop will consists of paper presentations; each presentation will be allocated between 10 and 15 minutes. The program will also include an invited talk from an expert of the field, and a panel composed by AI experts and transportation experts, with the aim of identifying promising areas of work. The expected attendance is approximately 50 people. Authors of accepted papers will be invited to deliver a talk, and well-recognized experts of the field will be invited to participate in the panel or to deliver an invited talk.
Submissions
Two types of papers can be submitted. Full technical papers with a length up to 8 pages are standard research papers. Short papers with a length between 2 and 4 pages can describe either a particular application, or focus on open challenges. All papers should conform to the AAAI style template. Submissions should be made via EasyChair at https://easychair.org/conferences/?conf=ai4um.
Organizing Committee
Lukas Chrpa (Czech Technical University in Prague, chrpaluk@fel.cvut.cz), Mauro Vallati (University of Huddersfield, m.vallati@hud.ac.uk), Scott Sanner (University of Toronto, ssanner@mie.utoronto.ca), Stephen S. Smith (Carnegie Mellon University, sfs@cs.cmu.edu), Baher Abdulhai (University of Toronto, baher.abdulhai@utoronto.ca)
Additional Information
Supplemental workshop site: http://aium2021.felk.cvut.cz

W4: Artificial Intelligence Safety (SafeAI 2021)
The accelerated developments in the field of Artificial Intelligence (AI) hint at the need for considering Safety as a design principle rather than an option. However, theoreticians and practitioners of AI and Safety are confronted with different levels of safety, different ethical standards and values, and different degrees of liability, that force them to examine a multitude of trade-offs and alternative solutions. These choices can only be analyzed holistically if the technological and ethical perspectives are integrated into the engineering problem, while considering both the theoretical and practical challenges of AI safety. A new and comprehensive view of AI Safety must cover a wide range of AI paradigms, including systems that are application-specific as well as those that are more general, considering potentially unanticipated risks. In this workshop, we want to explore ways to bridge short-term with long-term issues, idealistic with pragmatic solutions, operational with policy issues, and industry with academia, to build, evaluate, deploy, operate and maintain AI-based systems that are demonstrably safe.
This workshop seeks to explore new ideas on AI safety with particular focus on addressing the following questions:

What is the status of existing approaches in ensuring AI and Machine Learning (ML) safety, and what are the gaps?
How can we engineer trustable AI software architectures?
How can we make AI-based systems more ethically aligned?
What safety engineering considerations are required to develop safe human-machine interaction?
What AI safety considerations and experiences are relevant from industry?
How can we characterize or evaluate AI systems according to their potential risks and vulnerabilities?
How can we develop solid technical visions and new paradigms about AI Safety?
How do metrics of capability and generality, and the trade-offs with performance affect safety?

The main interest of the proposed workshop is to look at a new perspective of system engineering where multiple disciplines such as AI and safety engineering are viewed as a larger whole, while considering ethical and legal issues, in order to build trustable intelligent autonomy.
Topics
Contributions are sought in (but are not limited to) the following topics:

Safety in AI-based system architectures
Continuous V&V and predictability of AI safety properties
Runtime monitoring and (self-)adaptation of AI safety
Accountability, responsibility and liability of AI-based systems
Uncertainty in AI
Avoiding negative side effects in AI-based systems
Role and effectiveness of oversight: corrigibility and interruptibility
Loss of values and the catastrophic forgetting problem
Confidence, self-esteem and the distributional shift problem
Safety of AGI systems and the role of generality
Reward hacking and training corruption
Self-explanation, self-criticism and the transparency problem
Human-machine interaction safety
Regulating AI-based systems: safety standards and certification
Human-in-the-loop and the scalable oversight problem
Evaluation platforms for AI safety
AI safety education and awareness
Experiences in AI-based safety-critical systems, including industrial processes, health, automotive systems, robotics, critical infrastructures, among others

Format
To deliver a truly memorable event, we will follow a highly interactive format that will include invited talks and thematic sessions. The thematic sessions will be structured into short pitches and a common panel slot to discuss both individual paper contributions and shared topic issues. Three specific roles are part of this format: session chairs, presenters and paper discussants. The workshop will be organized as a full day meeting. Attendance is virtual and open to all. At least one author of each accepted submission must register and present the paper at the workshop.
Submissions
You are invited to submit:

Full technical papers (6-8 pages),
Proposals of technical talk (up to one-page abstract including short Bio of the main speaker),
Position papers (4-6 pages), and

Manuscripts must be submitted as PDF files via EasyChair online submission system.Please keep your paper format according to AAAI Formatting Instructions (two-column format). The AAAI author kit can be downloaded from: http://www.aaai.org/Publications/Templates/AuthorKit20.zip.
Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper). The workshop follows a single-blind reviewing process. However, we will also accept anonymized submissions.
Organizing Committee
Huáscar Espinoza (Commissariat à l´Energie Atomique, France), José Hernández-Orallo (Universitat Politècnica de València, Spain), Cynthia Chen (University of Hong Kong, China), Seán Ó hÉigeartaigh (University of Cambridge, UK), Xiaowei Huang (University of Liverpool, UK), Mauricio Castillo-Effen (Lockheed Martin, USA), Richard Mallah (Future of Life Institute, USA), John McDermid (University of York, UK)
Additional Information
Supplemental workshop site: http://safeaiw.org/

W5: Combating Online Hostile Posts in Regional Languages during Emergency Situations (CONSTRAINT-2021)
Online hostile posts (e.g., hate speech, fake news, etc.) can have severe consequences, and therefore, its detection is of paramount importance for societal causes. Another important aspect is early detection and prevention of hostile posts in response to a critical/emergency situation (e.g., COVID-19, US presidential election) where the (mis)information spreads rapidly. Moreover, hostile posts are not limited to English; instead, they are available in a variety of regional/local languages (e.g., Indian, some European languages, etc.). The challenges in automatic identification of the hostile posts are more critical in case of these regional languages — primarily because of the lack of resources for such languages.
With the CONSTRAINT-2021 workshop, we aim to attract the attention of the research communities to these important aspects of the hostile posts detection and provide a platform for the high-quality research in this domain.
Topics
We invite the submission of original and high-quality research papers in the relevant fields of misinformation. The list of possible topics includes, but is not limited to: fake news and hate speech detection in regional languages or code-mixed/code-switched environment; evolution of fake news and hate speech; early detection for hostile posts; claim detection and verification related to misinformation; psychological study of the users/spreaders of hostile posts; hate speech normalization; hesource/tool creation for combating hostile posts.
Shared Task
To support research on hostile posts detection, we are also organizing a shared task on fake news detection in microblogging posts. We plan to release two annotated datasets (English and Hindi) for the shared task. We invite researchers to participate and submit their systems. A few systems will be requested to submit their system description papers. https://constraint-shared-task-2021.github.io/.
Attendance
The workshop is open to all researchers, academicians, and industry personnel working in the relevant field. The expected attendance is approximately 100.
Submissions and Notifications
This one-day workshop will conduct a two-phase reviewing process, as well as the release of the shared task. The schedule is as follows:
Phase 1

Oct 20, 2020: Phase 1 full papers due
Nov 20, 2020: Notification of phase 1 papers due
Dec 1, 2020: Camera ready submission due of accepted papers

Phase 2

Dec 5, 2020: Phase 2 full papers due (Only papers rejected from AAAI’21 main track will be considered. Authors need to submit the full reviews and ratings obtained from AAAI)
Dec 20, 2020: Notification of phase 2 papers due
Dec 30, 2020: Camera ready submission due of phase 2 accepted papers

Shared Task

Oct 1, 2020: Release of the training set
Dec 1, 2020: Release of the test set
Dec 10, 2020: Deadline for submitting the final results
Dec 12, 2020: Announcement of the results
Dec 30, 2020: System paper submission deadline

Regular papers (maximum 12 pages) should be prepared in English and follow the Springer CCIS template, downloadable from here (https://www.springer.com/series/7899). All papers must be submitted via our EasyChair submission page and will go through a double-blind peer-review process. Only manuscripts in PDF or Microsoft Word format will be accepted.
All submissions must be made via EasyChair portal at the following link: https://easychair.org/conferences/?conf=constraint2021
Main Contact:
Tanmoy Chakraborty (IIIT Delhi, India, tanmoy@iiitd.ac.in)
Committees
Steering Committee: Tanmoy Chakraborty (IIIT Delhi, India, tanmoy@iiitd.ac.in), Kai Shu (Illinois Institute of Technology, USA, kshu@iit.edu), H. Russell Bernard (Arizona State University, USA, ufruss@ufl.edu), Huan Liu (Arizona State University, USA, huanliu@asu.edu)Organizing Committee: Tanmoy Chakraborty, IIIT Delhi, tanmoy@iiitd.ac.in), Md Shad Akhtar (IIIT Delhi, shad.akhtar@iiitd.ac.in)Shared Task Organizing Committee: Tanmoy Chakraborty (IIIT Delhi, tanmoy@iiitd.ac.in), Md Shad Akhtar (IIIT Delhi, shad.akhtar@iiitd.ac.in), Asif Ekbal (IIT Patna, asif@iitp.ac.in), Amitava Das (Wipro Research amitava.das2@wipro.com)
Additional Information
Supplemental workshop site: http://lcs2.iiitd.edu.in/CONSTRAINT-2021/Twitter handle: @CONSTRAINT_AAAI

W6: Commonsense Knowledge Graphs (CSKGs)
Commonsense knowledge graphs (CSKGs) are sources of background knowledge that are expected to contribute to downstream tasks like question answering, robot manipulation, and planning. The knowledge covered in CSKGs varies greatly, spanning procedural, conceptual, and syntactic knowledge, among others. CSKGs come in a wider variety of forms compared to traditional knowledge graphs, ranging from (semi-)structured knowledge graphs, such as ConceptNet, ATOMIC, and FrameNet, to the recent idea to use language models as knowledge graphs. As a consequence, traditional methods of integration and usage of knowledge graphs might need to be expanded when dealing with CSKGs. Understanding how to best integrate and represent CSKGs, leverage them on a downstream task, and tailor their knowledge to the particularities of the task, are open challenges today. The workshop on CSKGs addresses these challenges, by focusing on the creation of commonsense knowledge graphs and their usage on downstream commonsense reasoning tasks.
Topics
Topics of interest include, but are not limited to:

Creation/extraction of new CSKGs
Integration of existing CSKGs
Exploration of CSKGs
Impact of CSKGs on downstream tasks
Methods of including CSKG knowledge in downstream tasks
Probing for knowledge needs in downstream tasks
Evaluation data/metrics relevant for CSKGs
Identifying and/or filling gaps in CSKGs

Format
The workshop will consist of: (1) two keynote talks, (2) a panel discussion on ‘Are language models enough?’, (3) presentations of full, short, and position papers, and (4) a discussion session.
Submissions
We welcome submissions of long (max. 8 pages), short (max. 4 pages), and position (max. 4 pages) papers describing new, previously unpublished research in this field. The page limits are including the references. Submissions must be formatted in the AAAI submission format. All submissions should be done electronically via EasyChair.
Submission site: https://easychair.org/conferences/?conf=cskgsaaai21
Organizing Committee
Filip Ilievski (Information Sciences Institute, University of Southern California, ilievski@isi.edu), Alessandro Oltramari (Bosch Research and Technology Center, Pittsburgh, Alessandro.Oltramari@us.bosch.com),Deborah McGuinness (Rensselaer Polytechnic Institute, dlm@cs.rpi.edu),Pedro Szekely (Information Sciences Institute, University of Southern California, szekely@usc.edu)
Additional Information
Supplemental workshop site: https://usc-isi-i2.github.io/AAAI21workshop/

W7: Workshop on Content Authoring and Design (CAD2021)
The goal of the Content Authoring and Design (CAD2021) workshop at AAAI is to engage the AI and NLP community around the open problems in authoring, reformatting, optimization, enhancement and beautification of different forms of contents ranging from articles, news, presentation slides, flyers, posters to any material one can find online such as social media posts and advertisement. Content Authoring and Design refers to the interdisciplinary research area of Artificial Intelligence, Computational Linguistics, and Graphic Design. The area addresses open problems in leveraging AI models to assist users during their creative process by estimating the author and audience needs so that the outcome is aesthetically appealing and effectively communicates its intent.
Topics
The goal of the workshop is to gather insights from Artificial Intelligence, Computational Linguistics, Graphic Design and Creativity, Marketing Science, E-learning, as well as Social Media Analysis for content presentation enhancement, specifically, user-generated content, text in online marketing and education. Specific topics in this field include but aren’t restricted to:

Emphasis selection forwritten text in social media data or presentation slides
Font selection based on in put text or other design elements
NLP for color distributions recommendation
Text simplification or automatic text editing for representation improvement
Text appropriateness analysis
Marketing and brand alignment analysis
AI-assisted slide authoring
Document space optimization
Multi-modal content emotion and sentiment analysis
Metrics to assess the visual appeal of content
Machine learning approaches to rate the visual appeal of content
Related AI or AI-assisted approaches to improve the content layout

Shared Task: Presentation Slides Emphasis Selection
We propose a new shared task where participants will be expected to design automated approaches to predict emphasis in presentation slides with the goal of improving their comprehensibility and visual appeal. This shared task builds on our recent SemEval 2020 shared task on “Task 10: Emphasis Selection for Written Text in Visual Media.” More information about the shared task is provided on the workshop website.
Format
We will hold a one-day workshop where approximately two-thirds of the time will be devoted to presentations of regular workshop submissions and an invited talk. The rest of the day will be devoted to the shared task overview and papers.
Submissions
We encourage 2 types of submissions: archival submission of novel and unpublished work, and non-archival submissions that present recently published work.
Archival Submissions: Submissions should report original and unpublished research on topics of interest to the workshop. Accepted papers are expected to be presented at the workshop and will be published in the workshop proceedings. Archival submissions accepted for presentation at the workshop must not be or have been presented at any other meeting with publicly available proceedings.
Non-archival submissions: We welcome submissions of a one-page abstract describing work recently published but that is of relevance to the topics of the workshop. The goal is to increase the visibility of work in this emerging area and facilitate researchers and practitioners with common research interests to meet each other and learn about efforts in this space.
We welcome long (up to 8 pages), short (up to 4 pages) and one-page abstracts. Long/short paper submissions must use the AAAI official templates. The submission site can be found on the workshop website.
Organizing Committee
Thamar Solorio (University of Houston,tsolorio@uh.edu), Franck Dernoncourt (Adobe Research, franck.dernoncourt@adobe.com), Amirreza Shirani (University of Houston,ashirani@uh.edu), Nedim Lipka (Adobe Research, lipka@adobe.com), Paul Asente (Adobe Research, asente@adobe.com), Jose Echevarria (Adobe Research, echevarr@adobe.com)
Additional Information
Supplemental workshop site: https://ritual.uh.edu/aaai-21-workshop-on-content-authoring-and-design/

W8: Deep Learning on Graphs: Method and Applications (DLG-AAAI’21)
Deep Learning models are at the core of research in Artificial Intelligence research today. It is well-known that deep learning techniques that were disruptive for Euclidean data such as images or sequence data such as text are not immediately applicable to graph-structured data. This gap has driven a tide in research for deep learning on graphs on various tasks such as graph representation learning, graph generation, and graph classification. New neural network architectures on graph-structured data have achieved remarkable performance in these tasks when applied to domains such as social networks, bioinformatics and medical informatics.
This wave of research at the intersection of graph theory and deep learning has also influenced other fields of science, including computer vision, natural language processing, inductive logic programming, program synthesis and analysis, automated planning, reinforcement learning, and financial security. Despite these successes, graph neural networks (GNNs) still face many challenges namely,

Modeling highly structured data with time-evolving, multi-relational, and multi-modal nature. Such challenges are profound in applications in social attributed networks, natural language processing, inductive logic programming, and program synthesis and analysis. Joint modeling of text or image content with underlying network structure is a critical topic for these domains.
Modeling complex data that involves mapping between graph-based inputs and other highly structured output data such as sequences, trees, and relational data with missing values. Natural Language Generation tasks such as SQL-to-Text and Text-to-AMR are emblematic of such challenge.

This one-day workshop aims to bring together both academic researchers and industrial practitioners from different backgrounds and perspectives to above challenges. The workshop will consist of contributed talks, contributed posters, and invited talks on a wide variety of the methods and applications. Work-in- progress papers, demos, and visionary papers are also welcome. This workshop intends to share visions of investigating new approaches and methods at the intersection of Graph Neural Networks and real-world applications.
Topics
We invite submission of papers describing innovative research and applications around the following topics. Papers that introduce new theoretical concepts or methods, help to develop a better understanding of new emerging concepts through extensive experiments, or demonstrate a novel application of these methods to a domain are encouraged.

Graph neural networks on node-level, graph-level embedding
Joint learning of graph neural networks and graph structure
Graph neural networks on graph matching
Dynamic/incremental graph-embedding
Learning representation on heterogeneous networks, knowledge graphs
Deep generative models for graph generation/semantic-preserving transformation
Graph2seq, graph2tree, and graph2graph models
Deep reinforcement learning on graphs
Adversarial machine learning on graphs
Spatial and temporal graph prediction and generation

And with particular focuses but not limited to these application domains:

Learning and reasoning (machine reasoning, inductive logic programming, theory proving)
Natural language processing (information extraction, semantic parsing, text generation)
Bioinformatics (drug discovery, protein generation, protein structure prediction)
Program synthesis and analysis
Reinforcement learning (multi-agent learning, compositional imitation learning)
Financial security (anti-money laundering)
Cybersecurity (authentication graph, Internet of Things, malware propagation)
Geographical network modeling and prediction (Transportation and mobility networks, social
networks)

Submissions
Submissions are limited to a total of 5 pages for initial submission (up to 6 pages for final camera-ready submission), excluding references or supplementary materials, and authors should only rely on the supplementary material to include minor details that do not fit in the 5 pages. All submissions must be in PDF format and formatted according to the Standard AAAI Conference Proceedings Template. Following this AAAI conference submission policy, reviews are double-blind, and author names and affiliations should NOT be listed. Submitted papers will be assessed based on their novelty, technical quality, potential impact, and clarity of writing. For papers that rely heavily on empirical evaluations, the experimental methods and results should be clear, well executed, and repeatable. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will beposted on the workshop website and will not appear in the AAAI proceedings. Special issues in flagship academic journals are under consideration to host the extended versions of best/selected papers in the workshop.
Submission site: http://deep-learning-graphs.bitbucket.io/dlg-aaai21/
Organizing Committee
Lingfei Wu (IBM Research AI), Jiliang Tan (Michigan State University), Yinglong Xia (Facebook AI), Jian Pei (Simon Fraser University)
Additional Information
The workshop supplementary site URL will be available soon.

W9: Designing AI for Telehealth
Although telehealth technology has been present for years, appearance of the Covid-19 pandemic dramatically has accelerated its growth. This workshop clearly is timely. Investment currently is strong for numerous types of telehealth systems, many including AI components, and leading enterprises in this work are now recognizing the important need for participatory design. Accordingly, the main objective of this workshop is specifically to gather representatives of AI research and development with those of other stakeholder domains to create a community for sustaining valuable participatory design dialogue.
Topics
Some design topics that emerge during workshop discussion are likely not to be initially familiar to all stakeholder communities present, promising useful gain in shared knowledge. For the AI community, different types of telehealth tend to share abstract design topics that include accuracy, reliability, validity, economy, autonomy, application requirements, privacy, and cybersecurity.
Format
Consistently with its main objective, the workshop welcomes participants who represent distinct but interactive communities of stakeholders in the design of AI applications for telehealth, thus joining participants from AI with those representing patients, physicians, nursing practice, nursing education, healthcare administration, and governmental, pharmaceutical, insurance, and legal enterprises. Ideally, this one-day gathering will contain a presentation representing each of these communities, followed by ample time for open forum discussion.
Timeliness of its topic, use of a virtual medium, and AAAI’s discounted workshop registration for AAAI-21 technical registrants, plus a workshop-only registration option, all suggest that this workshop will attract at least sixty members. Of course, its organizers also seek a gathering size that allows meaningful participation for everyone; fortunately, the workshop is equipped with a website that will post the CFP and accepted workshop papers (pending authors’ permissions) as well as sustain afterward the valuable dialogue generated during the event.
Submissions
Requests to participate and (optional) paper submissions are to be emailed to workshop chair by November 9, 2020. Papers will be 6-to-8-page Word documents. Invitations to participate and decisions concerning selection of papers for presentation will be supplied by November 30, 2020.
Submit to Workshop Chair, Ted Metzler at tmetzler@okcu.edu.
Organizing Committee
Ted Metzler (Oklahoma City University, Kramer School of Nursing, tmetzler@okcu.edu), Lundy Lewis (Southern New Hampshire University, Computer Information Systems, l.lewis@snhu.edu), Elizabeth Diener (Oklahoma City University: Kramer School of Nursing, ejdiener@okcu.edu)
Additional Information
Supplemental workshop site: http://shapingsmarttechnology.org (click on TELEHEALTH to access the workshop page).

W10: 9th Dialog System Technology Challenge (DSTC-9)
DSTC, the Dialog System Technology Challenge, has been a premier research competition for dialog systems since its inception in 2013. Given the remarkable success of the first eight challenges, we are organizing the ninth edition of DSTC this year and we will have a wrap-up workshop at AAAI-21.
Topics
The main goal of this workshop is to share the results of the following four main tracks of DSTC9:

Beyond Domain APIs: Task-oriented Conversational Modeling with Unstructured Knowledge Access (Amazon Alexa AI & National Taiwan University)
Multi-domain Task-oriented Dialog Challenge II (Microsoft Research AI & Tsinghua University)
Interactive Evaluation of Dialog (CMU & USC)
SIMMC: Situated Interactive Multi-Modal Conversational AI (Facebook Assistant & Facebook AI)

Format
The two-day workshop will include welcome remarks, track overviews, invited talks, oral presentations, and discussions about future DSTCs. We invite all the teams who participated in DSTC9 to submit their work to this workshop. In addition, any other general technical paper on dialog technologies is also welcome.
Submissions
The submissions must follow the formatting guidelines for AAAI-2021 (use the AAAI Author Kit). All submissions must be anonymous and conform to AAAI standards for double-blind review. The papers adhere to the 2-column AAAI format up to 7 pages of technical content plus up to two additional pages solely for references will be considered for review.
Submission site: https://dstc9.dstc.community/paper-submission
Organizing Committee
Workshop Chairs: Abhinav Rastogi (Google Research, USA, abhirast@google.com), Yun-Nung (Vivian) Chen (National Taiwan University, Taiwan, y.v.chen@ieee.org)Challenge Chair: Chulaka Gunasekara (IBM Research AI, USA, Chulaka.Gunasekara@ibm.com)Publication Chair: Luis Fernando D’Haro (Universidad Politécnica de Madrid, Spain, lfdharo@die.upm.es)Publicity Chair: Seokhwan Kim (Amazon Alexa AI, USA, seokhwk@amazon.com)
Additional Information
Supplemental workshop site: https://sites.google.com/dstc.community/dstc9/

W11: Explainable Agency in Artificial Intelligence
As artificial intelligence has become tightly intervened in the society having tangible consequences and influence, calls for explainability and interpretability of these systems has also become increasingly prevalent. Explainable AI (XAI) attempts to alleviate concerns of transparency, trust and ethics in AI by making them accountable, interpretable and explainable to humans. This workshop aims to encapsulate these concepts under the umbrella of Explainable Agency and bring together researchers and practitioners working in different facets of explainable AI from diverse backgrounds to share challenges, new directions and recent research in the field. We especially welcome research from fields including but not limited to artificial intelligence, human-computer interaction, human-robot interaction, cognitive science, human factors and philosophy.
Topics
XAI has received substantial but disjoint attention in different sub areas of AI, including machine learning, planning, intelligent agents, and several others. There has been limited interaction among these subareas on XAI, and even less work has focused on promoting and sharing sound designs, methods, and measures for evaluating the effectiveness of explanations (generated by AI systems) in human subject studies. This has led to uneven development of XAI, and its evaluation, in different AI subareas. We aim to address this by encouraging a shared definition of Explainable Agency and by increasing awareness of work on XAI throughout the AI research community and in related disciplines (e.g., human factors, human-computer interaction, cognitive science). With this in mind, we welcome contributions on the following (and related) topic areas:

Explainable/Interpretable Machine Learning
Fairness, Accountability and Transparency
Explainable Planning
Explainable Agency
Human-AI Interaction
Human-Robot Interaction
Cognitive Theories
Philosophical Foundations
Interaction Design for XAI
XAI Evaluation
Agent Policy Summarization
XAI Domains and Benchmarks
Interactive Teaching Strategies and Explainability
User Modelling
Surveys on Explainability

Format
The workshop will be a two-day meeting, with invited talks, panels, paper presentations, lightning presentations and a discussion. We expect ~100 participants and potentially more due to the popularity of this topic and the virtual nature of this workshop.
Submissions
We invite the submission of papers describing novel research contributions (6 pages), survey papers (up to 8 pages) or demonstrations (4 pages). The submissions must be in PDF format, written in English, and formatted according to the AAAI camera-ready style. All papers will be peer reviewed, single-blinded.
Submission site: https://easychair.org/my/conference?conf=xaiaaai21
Organizing Committee
Prashan Madumal, Silvia Tulli, David Aha, Rosina Weber
Additional Information
Supplemental workshop site: https://sites.google.com/view/xaiworkshop/topic

W12: Graphs and More Complex Structures for Learning and Reasoning (GCLR)
The study of complex graphs is a highly interdisciplinary field that aims to study complex systems by using mathematical models, physical laws, inference and learning algorithms, etc. Complex systems are often characterized by several components that interact in multiple ways among each other. Such systems are better modeled by complex graph structures such as edge and vertex labelled graphs (e.g., knowledge graphs), attributed graphs, multilayer graphs, hypergraphs, temporal / dynamic graphs, etc. In this GCLR (Graphs and more Complex structures for Learning and Reasoning) workshop, we will focus on various complex structures along with inference and learning algorithms for these structures. The current research in this area is focused on extending existing ML algorithms as well as network science measures to these complex structures. This workshop aims to bring researchers from these diverse but related fields together and embark on interesting discussions on new challenging applications that require complex system modeling and discovering ingenious reasoning methods. We have invited several distinguished speakers with their research interest spanning from the theoretical to experimental aspects of complex networks.
Topics
We invite submission from participants who can contribute to the theory and applications of modeling complex graph structures such as hypergraphs, multilayer networks, multi-relational graphs, heterogeneous information networks, multi-modal graphs, signed networks, bipartite networks, temporal / dynamic graphs, etc. The topics of interest include, but not limited to:

Constraint satisfaction and programming (CP), (inductive) logic programming (LP and ILP)
Learning with Multi-relational graphs (alignment, knowledge graph construction, completion, reasoning with knowledge graphs, etc.)
Learning with algebraic or combinatorial structure
Link analysis/prediction, node classification, graph classification, clustering for complex graph structures
Network representation learning
Theoretical analysis of graph algorithms or models
Optimization methods for graphs/manifolds
Probabilistic and graphical models for structured data
Social network analysis and measures
Unsupervised graph/manifold embedding methods

Papers will be presented in poster format and some will be selected for oral presentation. Through invited talks and presentations by the participants, this workshop will bring together current advances in network science as well as machine learning, and set the stage for continuing interdisciplinary research discussions.
Format
This is a one-day workshop involving talks by pioneer researchers from respective areas, poster presentations, and short talks of accepted papers. The eligibility criteria for attending the workshop will be registration in the conference/workshop as per AAAI norms. We expect 50-65 people in the workshop.
Submissions
We invite submissions to the AAAI workshop on Graphs and more Complex structures for Learning and Reasoning to be held virtually on February 8 or 9, 2021. We welcome the submissions in the following two formats:

Extended abstracts: We encourage participants to submit preliminary but interesting ideas that have not been published before as extended abstracts. These submissions would benefit from additional exposure and discussion that can shape a better future publication. We also invite papers that have been published at other venues to spark discussions and foster new collaborations. Submissions may consist of up to 4 pages plus one additional page solely for references.
Full papers: Submissions must represent original material that has not appeared elsewhere for publication and that is not under review for another refereed publication. Submissions may consist of up to 7 pages of technical content plus up to two additional pages solely for references.

The submissions should adhere to the AAAI paper guidelines available at https://aaai.org/Conferences/AAAI-21/aaai21call/
Accepted submissions will have the option of being published on the workshop website. For authors who do not wish their papers to be posted online, please mention this in the workshop submission. The submissions need to be anonymized.
See the webpage https://sites.google.com/view/gclr2021/submissions for detailed instructions and submission link. Extended abstracts and full papers are due November 9, 2020.
Organizing Committee
Balaraman Ravindran, Chair (Indian Institute of Technology Madras, India, ravi@cse.iitm.ac.in), Kristian Kersting (TU Darmstadt, Germany, kersting@cs.tu-darmstadt.de), Sarika Jalan (Indian Institute of Technology Indore, India, sarika@iiti.ac.in), Partha Pratim Talukdar (Indian Institute of Science, India, ppt@iisc.ac.in), Sriraam Natarajan (University of Texas Dallas, USA, Sriraam.Natarajan@utdallas.edu), Tarun Kumar (Indian Institute of Technology Madras, India, tkumar@cse.iitm.ac.in), Deepak Maurya (Indian Institute of Technology Madras, India, maurya@cse.iitm.ac.in), Nikita Moghe (The University of Edinburgh, UK, nikita.moghe@ed.ac.uk), Naganand Yadati (Indian Institute of Science, India, y.naganand@gmail.com), Jeshuren Chelladurai (Indian Institute of Technology Madras, India, jeshurench@gmail.com), Aparna Rai (Indian Institute of Technology Guwahati, India, raiaparna13@gmail.com).
Additional Information
Supplemental workshop site: https://sites.google.com/view/gclr2021/ 

W13: 5th International Workshop on Health Intelligence (W3PHIAI-21)
Public health authorities and researchers collect data from many sources and analyze these data together to estimate the incidence and prevalence of different health conditions, as well as related risk factors. Modern surveillance systems employ tools and techniques from artificial intelligence and machine learning to monitor direct and indirect signals and indicators of disease activities for early, automatic detection of emerging outbreaks and other health-relevant patterns. To provide proper alerts and timely response, public health officials and researchers systematically gather news and other reports about suspected disease outbreaks, bioterrorism, and other events of potential international public health concern, from a wide range of formal and informal sources. Given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. This is especially the case for non- traditional online resources such as social networks, blogs, news feed, twitter posts, and online communities with the sheer size and ever-increasing growth and change rate of their data. Web applications along with text processing programs are increasingly being used to harness online data and information to discover meaningful patterns identifying emerging health threats. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real-time data on epidemics.
Moreover, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork among patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All of these changes require novel solutions and the AI community is well-positioned to provide both theoretical- and application-based methods and frameworks. The goal of this workshop is to focus on creating and refining AI-based approaches that (1) process personalized data, (2) help patients (and families) participate in the care process, (3) improve patient participation, (4) help physicians utilize this participation in order to provide high quality and efficient personalized care, and (5) connect patients with information beyond that available within their care setting. The extraction, representation, and sharing of health data, patient preference elicitation, personalization of “generic” therapy plans, adaptation to care environments and available health expertise, and making medical information accessible to patients are some of the relevant problems in need of AI-based solutions.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. This workshop is especially interested in hearing about the challenges and problems data science and AI can address related to the global pandemic, and relevant deployments and experiences in gearing AI to cope with COVID-19. The scope of the workshop includes, but is not limited to, the following areas:

Knowledge Representation and Extraction
Integrated Health Information Systems
Patient Education
Patient-Focused Workflows
Shared Decision Making
Geographical Mapping and Visual Analytics for Health Data
Social Media Analytics


Epidemic Intelligence
Predictive Modeling and Decision Support
Semantic Web and Web Services
Biomedical Ontologies, Terminologies, and Standards
Bayesian Networks and Reasoning under Uncertainty
Temporal and Spatial Representation and Reasoning
Case-based Reasoning in Healthcare
Crowdsourcing and Collective Intelligence
Risk Assessment, Trust, Ethics, Privacy, and Security
Sentiment Analysis and Opinion Mining
Computational Behavioral/Cognitive Modeling
Health Intervention Design, Modeling and Evaluation
Online Health Education and E-learning
Mobile Web Interfaces and Applications
Applications in Epidemiology and Surveillance (e.g. Bioterrorism, Participatory Surveillance, Syndromic Surveillance, Population Screening)
Explainable AI (XAI) in Health and Medical domain
Precision Medicine and Health

Format
The workshop will be two full days, consisting of a welcome session, keynote and invited talks, full/short paper presentations, demos, and posters. The organizers have experience hosting virtual conferences and as such have innovative ideas for engaging participants with both presentations and posters.
Submissions
We invite researchers and industrial practitioners to submit their original contributions following the AAAI format through EasyChair (https://easychair.org/conferences/?conf=w3phiai21). Three categories of contributions are sought: full-research papers up to 8 pages; short papers up to 4 pages; and posters and demos up to 2 pages.
Organizing Committee
Martin Michalowski, Cochair (University of Minnesota – Twin Cities, martinm@umn.edu), Arash Shaban-Nejad, Cochair (The University of Tennessee Health Science Center – Oak-Ridge National Lab (UTHSC-ORNL) Center for Biomedical Informatics, ashabann@uthsc.edu), Szymon Wilk (Poznan University of Technology), David L. Buckeridge (McGill University), John S. Brownstein (Boston Children’s Hospital, Harvard University), Byron C. Wallace (Northeastern University), Michael J. Paul (The University of Colorado Boulder);
Additional Information
Supplemental workshop site: http://w3phiai2021.w3phi.com/

W14: Hybrid Artificial Intelligence
Increased specialization in the sub-fields of AI has led to extreme fragmentation of the field. This has inhibited research on more complete AI systems that will require the coordination of multiple cognitive faculties (language, vision and reasoning) coupled with an ability to act and effect changes in the real world. This workshop will bring together researchers from NLP, computer vision, reasoning and action/robotics to explore end-to-end HAI.
Topics
Among the questions that participants will discuss and seek to answer are:

AI architectures: What should the representational and computational boundaries between modules look like? Can we characterize the best ways in which information shared between modules should be packaged?
Information revision: How should such systems handle feedback loops and the revision of information between modules?
Bounded rationality: How can processing resources best be managed between modules?
Neuro-symbolic: How can machine learning be parceled out among components or can end-to-end learning result in systems that coordinate multi-faculty capabilities? Can HAI systems provide a testing ground for neuro-symbolic computing?
AI Challenge problems: Are there particular challenge problems that would be most appropriate for the study of such systems that would encourage progress in this area?

Format
HAI will be a one-day workshop that will include presentations of accepted papers, a talk by an invited speaker and a panel discussion to discuss the above questions. Attendance is open to all.
Submissions
Full papers (maximum of 8 pages in length) that address the above questions or that report on efforts to combine multiple cognitive/action modules (together with lessons learned) may be submitted. Position papers (maximum of 4 pages in length) may also be submitted. Note that this workshop is not intended to explore AI systems that consist solely of multiple AI technologies (e.g., symbolic and neural nets): the technologies must be deployed in service of multiple coordinated functions (e.g., language plus vision).
Submission site: https://easychair.org/conferences/?conf=hai2021
Please follow the AAAI formatting guidelines (https://www.aaai.org/Publications/Templates/AuthorKit20.zip).
Organizing Committee
Charles Ortiz, Chair (Palo Alto Research Center (PARC), USA, cortiz@parc.com), Sven Dickinson, (University of Toronto and Samsung Toronto AI Research Center, Canada, sven@cs.toronto.edu), Ron Kaplan (Independent and Stanford, USA, Ron.kaplan@post.harvard.edu), Michael Thielscher (University of New South Wales, Australia, mit@unsw.edu.au)
Additional Information
Supplemental workshop site: https://sites.google.com/view/aaai2021workshop/home

W15: Imagining Post-COVID Education with AI
COVID-19 has brought upon us the inevitable transformation towards virtual education. The ensuing need for scalable, personalized learning systems has led to an unprecedented demand for understanding large-scale educational data. However, the field of Artificial Intelligence in Education (AIEd) has received relatively little academic attention compared to the mainstream machine learning areas like vision, natural language processing, and healthcare. In this workshop, we plan to invite AIEd enthusiasts from all around the world through three different channels. First, we will call for papers related to important AIEd topics that can help us imagine what new education will look like. Second, we propose a shared task about various AIEd problems on the largest public dataset, EdNet, which contains 123M interactions from more than 1M students. Finally, we host a global challenge on Kaggle for a fair comparison of state-of-the-art Knowledge Tracing models and invite technical reports from winning teams. Through these initiatives, we aim to provide a common ground for researchers to share their cutting-edge insights on AIEd and encourage the development of practical and large-scale AIEd methods of lasting impact.
Topics
We invite high-quality paper submissions on topics including, but not limited to, the following:

Deploying Educational Systems in Real World
Pre-deployment Considerations of Educational Systems
Behavioral Testing of Intelligent Tutoring Systems
User Interface for Interactive Educational Systems
A/B Testing of Educational Systems
Interpretability in AIEd
AI for Formative Learning
Knowledge Tracing (Response Prediction, Response Correctness Prediction)
Educational Content Recommendation
Question Difficulty Prediction
Score Prediction
Automated Essay Scoring
Personalized Curriculum Generation
Application of Deep Learning in Learning Sciences
Role of Artificial Intelligence in Remote Learning
Student Monitoring
Teacher-Educational System Integration

Format
We plan to host a one-day workshop which consists of the following programs (tentative):

Invited talks, including Daniela Rus, MIT
Presentations from
Kaggle competition top competitors
Shared task participants
Authors of submitted papers
Interactive session
Panel discussion

Attendance
We expect 25 ~ 50 attendees and the criteria for the invitations are the following:

Workshop organizers (8)
Top-ranking Kaggle competition participants (5 ~ 20)
Authors of shared task technical papers (5 ~ 20)
Authors of submitted papers (5 ~ 20)
Invited speakers (2)

Submissions
Submissions of papers including Kaggle competition technical papers, shared task technical papers and general submissions should follow the AAAI format and can be up to 8 pages excluding references and appendices. Submissions should be made in PDF format through OpenReview. Papers will be peer-reviewed and selected for oral or poster presentations at the workshop. Attendance is open to all, and at least one author of each accepted submission must be present at the workshop.
Submission Site: OpenReview, https://easychair.org/cfp/TIPCE2021
Organizing Committee
Paul Kim, Chair (Stanford University), Neil Hefferman, Chair (Worcester Polytechnic Institute), Jineon Baek (University of Michigan), Hoonpyo Jeon (Stanford University), Byungsoo Kim (Riiid! AI Research), Jamin Shin (Riiid! AI Research), Dongmin Shin (Riiid! AI Research), Youngduck Choi, (Yale University)
Additional Information
Supplemental workshop site: https://sites.google.com/view/tipce-2021/home

W16: Knowledge Discovery from Unstructured Data in Financial Services (KDF)
Knowledge discovery from various data sources has gained the attention of many practitioners over the past decades. Its capabilities have expanded from processing structured data (e.g. DB transactions) to unstructured data (e.g. text, images, and videos). In spite of substantial research focusing on discovery from news, web, and social media data, its application to data in professional settings such as legal documents, financial filings, and government reports, still present huge challenges. Possible reasons are that the precision and recall requirements for extracted knowledge to be used in business processes are fastidious, and signals gathered from these knowledge discovery tasks are usually very sparse and thus the generation of supervision signals is quite challenging.
In the financial services industry, in particular, a large amount of financial analysts’ work requires knowledge discovery and extraction from different data sources, such as SEC filings, loan documents, industry reports, etc., before the analysts can conduct any analysis. This manual extraction process is usually inefficient, error-prone, and inconsistent. It is one of the key bottlenecks for financial services companies in improving their operating productivity. These challenges and issues call for robust artificial intelligence (AI) algorithms and systems to help. The automated processing of unstructured data to discover knowledge from complex financial documents requires a series of techniques such as linguistic processing, semantic analysis, and knowledge representation and reasoning. The design and implementation of these AI techniques to meet financial business operations requires a joint effort between academia researchers and industry practitioners.
Topics
We invite submissions of original contributions on methods, theory, applications, and systems on artificial intelligence, machine learning, natural language processing and understanding, big data, statistical learning, data analytics, and deep learning, with a focus on knowledge discovery in the financial services domain. The scope of the workshop includes, but is not limited to, the following areas:

Representation learning, distributed representations learning and encoding in natural language processing for financial documents;
Synthetic or genuine financial datasets and benchmarking baseline models;
Transfer learning application on financial data, knowledge distillation as a method for compression of pre- trained models or adaptation to financial datasets;
Search and question answering systems designed for financial corpora;
Named-entity disambiguation, recognition, relationship discovery, ontology learning and extraction in financial documents;
Knowledge alignment and integration from heterogeneous data;
Using multi-modal data in knowledge discovery for financial applications
AI assisted data tagging and labeling;
Data acquisition, augmentation, feature engineering, and analysis for investment and risk management;
Automatic data extraction from financial fillings and quality verification;
Event discovery from alternative data and impact on organization equity price;
AI systems for relationship extraction and risk assessment from legal documents;
Accounting for Black-Swan events in knowledge discovery methods.

Based on the reflection and feedback from our AAAI-20 KDF workshop, this workshop is particularly interested in financial domain-specific representation learning, open financial datasets and benchmarking, and transfer learning application on financial data.
Although textual data is prevalent in a large amount of finance-related business problems, we also encourage submissions of studies or applications pertinent to finance using other types of unstructured data such as financial transactions, sensors, mobile devices, satellites, social media, etc.
Format
KDF 2021 is a one-day VIRTUAL workshop. The program of the workshop will include invited talks, spotlight paper presentations, and lightning poster presentations. We cordially welcome researchers, practitioners, and students from academia and industrial communities who are interested in the topics to participate; at least one author of each accepted submission must be present at the workshop.
Submissions
We invite submissions of relevant work that would be of interest to the workshop. All submissions must be original contributions, following the AAAI-21 formatting guidelines. We accept two types of submissions – full research paper no longer than 8 pages and short/poster paper with 2-4 pages. Submission will be accepted via EasyChair submission website https://easychair.org/my/conference?conf=kdf21. For general inquiries about KDF or submission questions, please write to inquiry.kdf2021 at easychair.org.
Organizing Committee
Xiaomo Liu (S&P Global), Zhiqiang Ma (S&P Global), Manuela M. Veloso (J.P. Morgan), Sameena Shah (J.P. Morgan), Armineh Nourbakhsh (J.P. Morgan), Gerard de Melo (University of Potsdam), Le Song (Georgia Institute of Technology and Ant Financial), Quanzhi Li (Alibaba Group)
Additional Information
Supplemental workshop site: https://aaai-kdf.github.io/kdf2021

W17: Learning Network Architecture during Training
A fundamental problem in the use of artificial neural networks is that the first step is to guess the network architecture. Fine tuning a neural network is very time consuming and far from optimal. Hyperparameters such as the number of layers, the number of nodes in each layer, the pattern of connectivity, and the presence and placement of elements such as memory cells, recurrent connections, and convolutional elements are all manually selected. If it turns out that the architecture is not appropriate for the task, the user must repeatedly adjust the architecture and retrain the network until an acceptable architecture has been obtained.
There is now a great deal of interest in finding better alternatives to this scheme. Options include pruning a trained network or training many networks automatically. In this workshop we would like to focus on a contrasting approach, to learn the architecture during training. This topic encompasses forms of Neural Architecture Search (NAS) in which the performance properties of each architecture, after some training, are used to guide the selection of the next architecture to be tried. This topic also encompasses techniques that augment or alter the network as the network is trained. An example of the latter is the Cascade Correlation algorithm, as well as others that incrementally build or modify a neural network during training, as needed for the problem at hand.
Main Objectives
Our goal is to build a stronger community of researchers exploring these methods, and to find synergies among these related approaches and alternatives. Eliminating the need to guess the right topology in advance of training is a prominent benefit of learning network architecture during training. Additional advantages are possible, including decreased computational resources to solve a problem, reduced time for the network to make predictions, reduced requirements for training set size, and avoiding “catastrophic forgetting.” We would especially like to highlight approaches that are qualitatively different from some popular but computationally intensive NAS methods.
As deep learning problems become increasingly complex, network sizes must increase and other architectural decisions become critical to success. The deep learning community must often confront serious time and hardware constraints from suboptimal architectural decisions. The growing popularity of NAS methods demonstrates the community’s hunger for better ways of choosing or evolving network architectures that are well-matched to the problem at hand.
Topics
Methods for learning network architecture during training, including Incrementally building neural networks during training, new performance benchmarks for the above. Novel approaches and works in progress are encouraged.
Format
The workshop will include invited speakers, panels, virtual poster sessions, and presentations. Attendance is open to all; at least one author of each accepted submission must be virtually present at the workshop.
Submissions
Please refer and submit through the workshop website listed below.
Organizing Committee
Scott E. Fahlman (School of Computer Science, Carnegie Mellon University, sef@cs.cmu.edu), Kate Farrahi (Electronics and Computer Science Department, University of Southampton, k.farrahi@soton.ac.uk), George Magoulas (Department of Computer Science and Information Systems, Birkbeck College, University of London, gmagoulas@dcs.bbk.ac.uk), Edouard Oyallon (Sorbonne Université – LIP6, Edouard.oyallon@lip6.fr), Bhiksha Raj Ramakrishnan (School of Computer Science, Carnegie Mellon University, bhiksha@cs.cmu.edu), Dean Alderucci (School of Computer Science, Carnegie Mellon University, dalderuc@cs.cmu.edu)
Additional Information
Supplemental workshop site: https://www.cs.cmu.edu/~sef/AAAI-2021-Workshop.htm

W18: Meta-Learning and Co-Hosted Competition
The performance of many machine learning algorithms depends highly upon the quality and quantity of available data, and (hyper)-parameter settings. In particular, deep learning methods, including convolutional neural networks, are known to be ‘data-hungry,’ and require properly tuned hyper-parameters. Meta-Learning is a way to address both issues. Simple, but effective approaches reported recently include pre-training models on similar datasets. This way, a good model or good hyperparameters can be pre-determined or learned model parameters can be transferred to the new dataset. As such, higher performance can be achieved with the same amount of data, or similar performance with less data (few shot learning). This workshop, with a co-hosted competition, will focus on meta-learning and few shot learning.
Topics
Please note that papers beyond the scope of the competition are also welcome. We welcome all types of submissions that feature Meta-learning and few shot learning, but have a specific focus on the following topics:

evaluation protocols and standardized benchmarks
generalization of meta-learning techniques across diverse datasets
papers that describe submissions to the co-hosted ChaLearn competition
traditional meta-learning, including active testing, meta-features and meta-datasets
few shot learning techniques, such as MAML, Few Shot Learning and Matching Networks

Format
The workshop will be held virtually, like all workshops at AAAI. We will organize a one-day workshop, featuring high-profile keynote speakers, a selection of submissions from the workshop, and a panel discussion. All other accepted papers will present their work in a virtual poster session. We already have the following keynote speakers confirmed: Chelsea Finn, Orial Vinyals, Lilian Weng, and Richard Zemel.
Submissions
Papers must be formatted in AAAI two-column, camera-ready style. We welcome two types of submissions, regular papers (max. 7 pages, including references) and short papers (max. 4 pages, including references). All accepted papers will be hosted on the website of the workshop. “Authors of accepted regular papers can opt-in to the formal PMLR proceedings. Submissions are due December 1, 2020.
Submission site: https://cmt3.research.microsoft.com/METALEARNCC2021
Organizing Committee
Adrian El Baz (INRIA and Université Paris Saclay, France), Isabelle Guyon (INRIA and Université Paris Saclay, France, ChaLearn, USA), Zhengying Liu (INRIA and Université Paris Saclay, France), Jan N. van Rijn (LIACS, Leiden University, the Netherlands), Sebastien Treguer (INRIA and Université Paris Saclay, France, ChaLearn, USA), Joaquin Vanschoren (Eindhoven University of Technology, the Netherlands)
Additional Information
Supplemental workshop site: https://metalearning.chalearn.org/

W19: Meta-Learning for Computer Vision (ML4CV)
Machine learning and in particular deep learning has shown significant boost in performance on various computer vision tasks such as object recognition, face recognition, and semantic segmentation in the last decade. Despite this success, the learning mechanism of modern systems remains surprisingly narrow as compared to the way humans learn. For example, contrary to the most current systems which learn just a single model from just a single data set, we humans acquire knowledge from diverse experiences over many years. As an alternative, meta-learning and life-long learning aka never-ending learning has been emerging as a new paradigm in the machine learning literature.
Meta learning and lifelong learning relate to the human ability of continuously learning new tasks with very limited labeled training data. In the current computer vision problems, we train one architecture for every individual problem, as soon as the data distribution or the problem statement changes, the machine learning algorithm has to be retrained or redesigned. Further, once the model is updated to incorporate newer data distribution or task, the knowledge learnt from the previous task is “forgotten.” Meta learning focuses on designing models that utilize prior knowledge learnt from other tasks to perform a new task. Meta learning attempts to build models for “general artificial intelligence.”
Topics
The scope of the workshop includes but are not limited to the following topics:

Efficient models of meta learning for computer vision
Lifelong learning for computer vision
Never-ending multimodal networks for computer vision
Robust approaches to address catastrophic forgetting
Imitation learning for visual understanding
Neural architecture search
Active domain generalization
Meta domain generalization
Domain-shift detection
Learning to learn
AutoML
Meta-learning applications in visual domains including biometrics, medical imaging and action recognition.

Format
This is a one day workshop and will be organized as a combination of presentations by invited speakers and paper presentations. The papers submitted to the workshop will be peer reviewed. There is no restriction on participants willing to attend the workshop.
Submissions
Full papers following the AAAI paper submission guideline should be submitted. We plan to publish the papers accepted in this workshop as a book with Springer in 2021.
Submission Site: https://cmt3.research.microsoft.com/ML4CV2021
Organizing Committee
Mayank Vatsa (IIT Jodhpur, mvatsa@iitj.ac.in), Richa Singh (IIT Jodhpur, richa@iitj.ac.in(, Nalini Ratha (SUNY Buffalo, nratha@buffalo.edu), Vishal Patel (Johns Hopkins University, vpatel36@jhu.edu), Surbhi Mittal, web chair (IIT Jodhpur, mittal.5@iitj.ac.in)
Additional Information
Supplemental workshop site: http://iab-rubric.org/mel4cv/

W20: Plan, Activity, and Intent Recognition (PAIR) 2021
This workshop seeks to bring together researchers and practitioners from diverse backgrounds, to share ideas and recent results. It will aim to identify important research directions, opportunities for synthesis and unification of representations and algorithms for recognition. Contributions of research results are sought in the following areas of:

Plan, activity, intent, or behavior recognition
Adversarial planning, opponent modeling
Modeling multiple agents, modeling teams
User modeling on the web and in intelligent user interfaces
Acquaintance models
Plan recognition and user modeling in marketplaces and e-commerce
Intelligent tutoring systems (ITS)
Machine learning for plan recognition and user modeling
Personal software assistants
Social network learning and analysis
Monitoring agent conversations (overhearing)
Observation-based coordination and collaboration (teamwork)
Multi-agent plan recognition
Observation-based failure detection
Monitoring multi-agent interactions
Uncertainty reasoning for plan recognition
Commercial applications of user modeling and plan recognition
Representations for agent modeling
Modeling social interactions
Inferring emotional states
Reverse engineering and program recognition
Programming by demonstration
Imitation

Due to the diversity of disciplines engaging in this area, related contributions in other fields, are also welcome.
Submissions
All submissions must be original. If a work is under submission for the main conference as well or for a different conference, it should be written in the title. Papers must be in trouble-free, high-resolution PDF format, formatted for US Letter (8.5″ x 11″) paper, using Type 1 or TrueType fonts. Submissions are anonymous, and must conform to the AAAI-21 instructions for double-blind review. All questions about submissions should be emailed to Sarah Keren at sarah.e.keren@gmail.com.
Full Papers: We accept full paper submissions. Papers must be formatted in AAAI two-column, camera-ready style. Submissions may have up to 9 pages with pages 8 and 9 containing nothing but references.
Demo Track: This year the PAIR workshop will include a demo track. Authors are required to submit two items: (1) a 2-page short paper describing their system, formatted in AAAI two-column style, and (2) a video (of duration up to 10 minutes) of the proposed demonstration. Slides are also permitted in lieu of video, but greater weight will be given to submissions accompanied by videos. The paper must present the technical details of the demonstration, discuss related work, and describe the significance of the demonstration. We welcome submission of demos submitted to the demo session of the main conference. The demo track will be chaired by Dr. Ramon Fraga Pereira and Dr. Mor Vered. Questions regarding demos should be referred to ramonfpereira@gmail.com or mor.vered@unimelb.edu.au.
Organizing Committee
Sarah Keren (primary contact) (Harvard University, School of Engineering and Applied Sciences, sarah.e.keren@gmail.com or skeren@seas.harvard.edu), Reuth Mirsky (University of Texas, Department of Computer Science, reuth@cs.utexas.edu), Christopher Geib (SIFT LLC, cgeib@sift.net)
Additional Information
Supplemental workshop site: http://www.planrec.org/PAIR/Resources.html

W21: Workshop on Privacy-Preserving Artificial Intelligence (PPAI-21)
The availability of massive amounts of data, coupled with high-performance cloud computing platforms, has driven significant progress in artificial intelligence and, in particular, machine learning and optimization. It has profoundly impacted several areas, including computer vision, natural language processing, and transportation. However, the use of rich data sets also raises significant privacy concerns: They often reveal personal sensitive information that can be exploited, without the knowledge and/or consent of the involved individuals, for various purposes including monitoring, discrimination, and illegal activities.
The second AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-21) held at the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21) builds on the success of last year’s AAAI PPAI to provide a platform for researchers, AI practitioners, and policymakers to discuss technical and societal issues and present solutions related to privacy in AI applications. The workshop will focus on both the theoretical and practical challenges related to the design of privacy-preserving AI systems and algorithms and will have strong multidisciplinary components, including soliciting contributions about policy, legal issues, and societal impact of privacy in AI.
PPAI-21 will place particular emphasis on: (1) Algorithmic approaches to protect data privacy in the context of learning, optimization, and decision making that raise fundamental challenges for existing technologies; (2) Privacy challenges created by the governments and tech industry response to the Covid-19 outbreak; (3) Social issues related to tracking, tracing, and surveillance programs; and (4) Algorithms and frameworks to release privacy-preserving benchmarks and data sets.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Applications of privacy-preserving AI systems
Attacks on data privacy
Differential privacy: theory and applications
Distributed privacy-preserving algorithms
Human rights and privacy
Privacy issues related to the Covid-19 outbreak
Privacy policies and legal issues
Privacy preserving optimization and machine learning
Privacy preserving test cases and benchmarks
Surveillance and societal issues

Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and data sets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples.
Format
The workshop will be a one-day and a half meeting. The first session (half day) will be dedicated to privacy challenges, particularly those risen by the Covid-19 pandemic tracing and tracking policy programs. The second, day-long, session will be dedicated to the workshop technical content about privacy-preserving AI. The workshop will include a number of (possibly parallel) technical sessions, a virtual poster session where presenters can discuss their work, with the aim of further fostering collaborations, multiple invited speakers covering crucial challenges for the field of privacy-preserving AI applications, including policy and societal impacts, a number of tutorial talks, and will conclude with a panel discussion. Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-21 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentation at the workshop.
Submission site: https://cmt3.research.microsoft.com/PPAI2021
Organizing Committee
Ferdinando Fioretto (Syracuse University), Pascal Van Hentenryck (Georgia Institute of Technology), Richard W. Evans (Rice University)
Additional Information
Supplemental workshop site: https://ppai21.github.io/

W22: Reasoning and Learning for Human-Machine Dialogs (DEEP-DIAL21)
Natural conversation is a hallmark of intelligent systems and thus dialog systems have been a key sub-area of Artificial Intelligence research for decades. Chatbots are their most recent incarnation and have been widely adopted, particularly in the recent COVID-19 pandemic, as sources of information. Given the increasing interest, there has been a surge in the development of easy-to-use platforms to rapidly create dialog agents at different levels of sophistication. Further, with the rapid advances in natural language generation models, there is a need to foster and guide the research on the development and deployment of dialog systems with what users actually value.
The COVID-19 pandemic has been an opportunity to validate the relevance of collaborative assistance technologies for real-world needs. Chatbots have been increasingly used for seeking advice and providing assistance related to symptoms, health facilities and public policies. The usage aim is to implement technical systems that smartly adapt their functionality to their users’ individual needs and requirements and solve problems in close cooperation with users. They need to enter into a dialog and convincingly explain their suggestions and decision-making behavior.
Such applications highlight future research directions for the community. There is a need to build dialog systems that can explain their reasoning and can stand up to ethical standards demanded in real-life settings. The impressive gains of learning-based models to discover insights from data have to be married with pre-known knowledge — e.g., common-sense and spatio-temporal knowledge — to be usable by the common man. There is an urgent need to highlight the crucial role of reasoning methods, like constraints satisfaction, planning, and scheduling can play to build an end-to-end conversation system that evolves over time. The systems have to be deployable at lower cost and usable in situations with limited device capabilities and network connectivity.
These form the motivation for the fourth edition of the Workshop on Reasoning and Learning for Human-Machine Dialogues. The past editions of the workshop were huge successes attracting 100+ AI researchers to discuss a variety of topics. DEEP-DIAL 21 will have reviewed paper presentations, invited talks, panels, and open contributions of datasets and chatbots.
Topics
With these motivations, some areas of interest for the workshop, but not limited to, are:

Dialog Systems

Design considerations for dialog systems
Evaluation of dialog systems, metrics
Open-domain dialog and chat systems
Task-oriented dialog
Style, voice, and personality in spoken dialog and written text
Novel Methods for NL Generation for dialogs
Early experiences with implemented dialog systems
Mixed-initiative dialog where a partner is a combination of agent and human
Hybrid methods


Reasoning

Domain model acquisition, especially from unstructured text
Plan recognition in natural conversation
Planning and reasoning in the context of dialog systems
Handling uncertainty
Optimal dialog strategies


Learning

Learning to reason
Learning for dialog management
End2end models for conversation
Explaining dialog policy


Practical Considerations

Responsible chatting
Ethical issues with learning and reasoning in dialog systems
Corpora, Tools, and Methodology for Dialog Systems
Securing one’s chat



Submissions
Submissions must be formatted in AAAI two-column, camera-ready style. Regular research papers may be no longer than 7 pages, where page 7 must contain only references, and no other text whatsoever. Short papers, which describe a position on the topic of the workshop or a demonstration/tool, may be no longer than 4 pages, references included. The accepted papers will be linked from the workshop website to the public versions on ArXiv.
Organizing Committee
Sathyanarayanan N. Aakur (Oklahoma State University, USA), Ullas Nambiar (Accenture, India), Imed Zitouni (Google, USA), and Biplav Srivastava (AI Institute, University of South Carolina, USA)
Additional Information
Supplemental workshop site: https://sites.google.com/view/deep-dial2021

W23: Reinforcement Learning in Games
Games provide an abstract and formal model of environments in which multiple agents interact: each player has a well-defined goal and rules to describe the effects of interactions among the players. The first achievements in playing these games at super-human level were attained with methods that relied on and exploited domain expertise that was designed manually (e.g. chess, checkers). In recent years, we have seen examples of general approaches that learn to play these games via self-play reinforcement learning (RL), as first demonstrated in Backgammon. While progress has been impressive, we believe we have just scratched the surface of what is capable, and much work remains to be done in order to truly understand the algorithms and learning processes within these environments.
The main objective of the workshop is to bring researchers together to discuss ideas, preliminary results, and ongoing research in the field of reinforcement in games.
We invite participants to submit papers on the 9th of November, based on but not limited to, the following topics: RL in various formalisms: one-shot games, turn-based, and Markov games, partially-observable games, continuous games, cooperative games; deep RL in games; combining search and RL in games; inverse RL in games; foundations, theory, and game-theoretic algorithms for RL; opponent modeling; analyses of learning dynamics in games; evolutionary methods for RL in games; RL in games without the rules; Monte Carlo tree search, online learning in games.
Format
RLG is a full-day workshop. It will start with a 60-minute mini-tutorial covering a brief tutorial and basics of RL in games, and will include 2-3 invited talks by prominent contributors to the field, paper presentations, a poster session, and will close with a discussion panel. Attendance is expected to be 150-200 participants (estimated), including organizers and speakers.
Submissions
Papers must be between 4-8 pages in the AAAI submission format, with the eighth page containing only references. Papers will be submitted electronically using Easychair. Accepted papers will not be archival, and we explicitly allow papers that are concurrently submitted to, currently under review at, or recently accepted in other conferences / venues.
Submissions should be sent to: Martin Schmid (mschmid@google.com)
Workshop Chair
Martin Schmid (mschmid@google.com)
Organizing Committee
Marc Lanctot (DeepMind, lanctot@google.com), Julien Perolat (DeepMind, perolat@google.com), Martin Schmid (DeepMind, mschmid@google.com)
Additional Information
Supplemental workshop site: http://aaai-rlg.mlanctot.info/

W24: Scientific Document Understanding
Scientific documents such as research papers, patents, books, or technical reports are one of the most valuable resources of human knowledge. At the AAAI-21 Workshop on Scientific Document Understanding (SDU@AAAI-21), we aim to gather insights into the recent advances and remaining challenges on scientific document understanding. Researchers from related fields are invited to submit papers on the recent advances, resources, tools, and upcoming challenges for SDU. In addition to that, we propose a shared task on one of the challenging SDU tasks, i.e., acronym identification and disambiguation in scientific text.
Topics
Topics of interest include but are not limited to:

Information extraction and information retrieval for scientific documents;
Question answering and question generation for scholarly documents;
Word sense disambiguation, acronym identification and expansion, and definition extraction; document summarization, text mining, document topic classification, and machine reading comprehension for scientific documents;
Graph analysis applications including knowledge graph construction and representation, graph reasoning and query knowledge graphs;
Biomedical image processing, scientific image plagiarism detection, and data visualization; code/pseudo-code generation from text and image/diagram captioning, New language understanding resources such as new syntactic/semantic parsers, language models or techniques to encode scholarly text;
Survey or analysis papers on scientific document understanding and new tasks and challenges related to each scientific domain;
Factuality, data verification, and anti-science detection

Shared Task
Acronyms, i.e., short forms of long phrases, are common in scientific writing. To push forward the research on acronym understanding in scientific text, we propose two shared tasks on acronym identification (i.e., recognizing acronyms and phrases in text) and disambiguation (i.e., finding the correct expansion for an ambiguous acronym). Participants are welcomed to submit their system reports to be presented in the workshop poster session.
Format
SDU will be a one-day workshop. The full-day workshop will start with an opening remark followed by long research paper presentations in the morning. The post-launch session includes the invited talks, shared task winners’ presentations, and a panel discussion on the resources, findings, and upcoming challenges. SDU will also host a poster session for presenting the short research papers and the system reports of the shared tasks. SDU is expected to host 50-60 attendees. Invited speakers, committee members, authors of the research paper, and the participants of the shared task are invited to attend.
Submissions
Submissions should follow the AAAI formatting guidelines and the AAAI 2021 standards for double-blind review including anonymous submission. SDU accepts both long (8 pages including references) and short (4 pages including references) papers. Accepted papers will be published in the workshop proceedings. System reports should also follow the AAAI formatting guidelines and have 4-6 pages including references. System reports will be presented during poster sessions.
Submission site for papers and system reports: https://easychair.org/conferences/?conf=sduaaai21
Organizing Committee
Thien Huu Nguyen (University of Oregon, thie@cs.uoregon.edu), Walter Chang (Adobe Research, wachang@adobe.com), Amir Pouran Ben Veyseh (University of Oregon, apouranb@uoregon.edu), Leo Anthony Celi (Harvard University and MIT, lceli@bidmc.harvard.edu), Franck Dernoncourt (Adobe Research, franck.dernoncourt@adobe.com)
Additional Information
Supplemental workshop site: https://sites.google.com/view/sdu-aaai21/home

W25: Toward Robust, Secure and Efficient Machine Learning
Machine learning technology has been improving with every passing day and has been extensively applied to nearly every corner of the society that offers substantial benefits to our daily lives. However, machine learning models face various threats. For example, it is known that machine learning models are vulnerable to adversarial samples. The existence of adversarial examples reveals that current machine learning models are vulnerable and can be easily fooled, leading to serious security concerns in machine learning systems such as autonomous driving vehicles or face recognition systems.
More recently, due to both data privacy requirements as specified in the European Union’s General Data Protection Regulation (GDPR), and the limitations of computation power, the training process of machine learning models has extended from centralized to decentralized (i.e. distributed or federated learning) where the model will suffer from even more threats. For example, in a federated learning setting, every client can perform various attacks such as backdoor attacks on the global model as clients have direct access to the global model. How to prevent privacy leaking during information exchange of a decentralized training method is also a critical issue.
At the same time, computation efficiency is a big concern for modern deep learning, both inference and training. For inference, people prefer inference on edge devices due to better privacy, but edge devices have very limited computational resource. For training, gradient or weight exchange is necessary for decentralized training, but such exchange requires communication, which may be slow. Furthermore, models that are robust to adversarial attacks usually require longer training time and orders of magnitude more computation FLOPs than normal networks.
This one-day workshop intends to bring experts from machine learning, security communities, and federated learning together to work more closely in addressing the posed concerns. Specifically, we seek to study threats and defenses to machine learning not only in a single node setting but also in a distributed setting, as well as potential defense strategies in both settings. In summary, we seek solutions to achieve a wholistic solution for robust, secure and efficient machine learning.
Topics

Theoretical contributions of adversarial machine learning.
Training data poisoning, adversarial learning, and adversarial attacks and defenses.
Secure machine learning
Privacy-preserving machine learning
Privacy attacks such as membership inference, and model inversion
Model compression and efficiency improvement in both training and inference
Efficiency improvement of information exchange in distributed training

Format
One day workshop through online zoom meeting, the workshop will include invited speakers, presentations, panel and group discussions.
Submissions
Submissions can be full technical papers (up to 8 pages) or short papers (up to 4 pages), and should be formatted in the AAAI style.
Submission site: https://easychair.org/conferences/?conf=rseml2021
Workshop General Chair
Qiang Yang (WeBank and Hong Kong University of Science and Technology)
Organizing Committee
Dawn Song (University of California, Berkeley), Song Han (Massachusetts Institute of Technology), Han Yu (Nanyang Technological University), Lixin Fan (WeBank), KamWoh Ng, main contact, (jinhewu@webank.com or kamwoh@gmail.com)
Additional Information
Supplemental workshop site: http://federated-learning.org/rseml2021/

W26: Trustworthy AI for Healthcare
AI for healthcare has emerged into a very active research area in the past few years and has made significant progress. While existing results are encouraging, not too many clinical AI solutions are deployed in hospitals or actively utilized by physicians. A major problem is that existing clinical AI methods are less trustworthy. For example, existing approaches make clinical decisions in a black-box way, which renders the decisions difficult to understand and less transparent. Existing solutions are not robust to small perturbations or potentially adversarial attacks, which raises security and privacy concerns. In addition, existing methods are often biased to specific ethnic groups or subpopulations. As a result, physicians are reluctant to use these solutions since clinical decisions are mission-critical and have to be made with high trust and reliability.
Topics
In this workshop, we aim to address the trustworthy issues of clinical AI solutions. We invite submissions of short papers (up to 4 pages excluding references, in AAAI format) studying trustworthy AI for healthcare. The topics include but are not limited to:

Interpretable AI methods for healthcare
Robustness of clinical AI methods
Medical knowledge grounded AI
Physician-in-the-loop AI
Security and privacy in clinical AI
Fairness in AI for healthcare
Ethics in AI for healthcare
Robust and interpretable natural language processing for healthcare
Methods for robust weak supervision

Format
The workshop will feature 14 invited talks, given by the following distinguished speakers (alphabetic order).

Lawrence Carin, Professor, Duke University
Emily Fox, Associate Professor, University of Washington
Russ Greiner, Professor, University of Alberta
Joyce Ho, Assistant Professor, Emory University
Tommi Jaakkola, Professor, Massachusetts Institute of Technology
Heng Ji, Professor, University of Illinois at Urbana-Champaign
Sanmi Koyejo, Assistant Professor, University of Illinois at Urbana-Champaign
Yan Liu, Associate Professor, University of Southern California
Sendhil Mullainathan, Professor, University of Chicago
Susan Murphy, Professor, Harvard University
Tristan Naumann, Senior Researcher, Microsoft Research
Lucila Ohno-Machado, Professor, University of California San Diego
Rajesh Ranganath, Assistant Professor, New York University
Jimeng Sun, Professor, University of Illinois at Urbana-Champaign

Submissions
The AAAI 2021 Workshop on Trustworthy AI for Healthcare invites submissions of short papers (up to 4 pages excluding references, in AAAI format) about trustworthy issues in clinical AI.
Organizing Committee
Pengtao Xie (University of California, San Diego, pengtaoxie2008@gmail.com), Marinka Zitnik (Harvard University, marinka@hms.harvard.edu), Byron Wallace (Northeastern University, byron@ccs.neu.edu), Jennifer G. Dy (Northeastern University, jdy@ece.neu.edu), Eric Xing (Carnegie Mellon University, epxing@cs.cmu.edu)
Additional Information
Supplemental workshop site: https://taih20.github.io/
Contact: taih.aaai21.ws@gmail.com",2021
This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2021 AAAI,2021
"AAAI-22 Workshop Program
The Thirty-Sixth AAAI Conference on Artificial IntelligenceFebruary 28 and March 1, 2022Vancouver Convention CentreVancouver, BC, Canada

2022 AAAI Author Kit

AAAI is pleased to present the AAAI-22 Workshop Program. Workshops will be held Monday and Tuesday, February 28 and March 1, 2022. The final schedule will be available in November. The AAAI-22 workshop program includes 39 workshops covering a wide range of topics in artificial intelligence. Workshops are one day unless otherwise noted in the individual descriptions. Registration in each workshop is required by all active participants, and is also open to all interested individuals. Workshop registration is available to AAAI-22 technical registrants at a discounted rate, or separately to workshop only registrants. Registration information will be mailed directly to all invited participants in December.",2022
"Important Dates for Workshop Organizers


November 12: Submissions due (unless noted otherwise)
December 3: Notification of acceptance (unless noted otherwise)
December 17: Early registration deadline
February 28 – March 1: AAAI-22 Workshop Program
",2022
"
W1: Adversarial Machine Learning and Beyond
W2: AI for Agriculture and Food Systems (AIAFS)
W3: AI for Behavior Change
W4: AI for Decision Optimization
W5: AI for Transportation
W6: AI in Financial Services: Adaptiveness, Resilience & Governance
W7: AI to Accelerate Science and Engineering (AI2ASE)
W8: AI-Based Design and Manufacturing (ADAM) (Half-Day)
W9: Artificial Intelligence for Cyber Security (AICS)(2-Day)
W10: Artificial Intelligence for Education (AI4EDU)
W11: Artificial Intelligence Safety (SafeAI 2022)(1.5-Day)
W12: Artificial Intelligence with Biased or Scarce Data
W13: Combining Learning and Reasoning: Programming Languages, Formalisms, and Representations (CLeaR)
W14: Deep Learning on Graphs: Methods and Applications (DLG-AAAI’22)
W15: DE-FACTIFY :Multi-Modal Fake News and Hate-Speech Detection
W16: Dialog System Technology Challenge (DSTC10)
W17: Engineering Dependable and Secure Machine Learning Systems (EDSMLS 2022) (Half-Day)
W18: Explainable Agency in Artificial Intelligence
W19: Graphs and More Complex Structures for Learning and Reasoning (GCLR)
W20: Health Intelligence (W3PHIAI-22)
W21: Human-Centric Self-Supervised Learning (HC-SSL)
W22: Information-Theoretic Methods for Causal Inference and Discovery (ITCI’22)
W23: Information Theory for Deep Learning (IT4DL)
W24: Interactive Machine Learning
W25: Knowledge Discovery from Unstructured Data in Financial Services (Half-Day)
W26: Learning Network Architecture during Training
W27: Machine Learning for Operations Research (ML4OR) (Half-Day)
W28: Optimal Transport and Structured Data Modeling (OTSDM)
W29: Practical Deep Learning in the Wild (PracticalDL2022)
W30: Privacy-Preserving Artificial Intelligence
W31: Reinforcement Learning for Education: Opportunities and Challenges
W32: Reinforcement Learning in Games (RLG)
W33: Robust Artificial Intelligence System Assurance (RAISA) (Half-Day)
W34: Scientific Document Understanding (SDU) (Half-Day)
W35: Self-Supervised Learning for Audio and Speech Processing
W36: Trustable, Verifiable and Auditable Federated Learning
W37: Trustworthy AI for Healthcare
W38: Trustworthy Autonomous Systems Engineering (TRASE-22)
W39: Video Transcript Understanding (Half-Day)

 ",2022
"
W1: Adversarial Machine Learning and Beyond
Although machine learning (ML) approaches have demonstrated impressive performance on various applications and made significant progress for AI, the potential vulnerabilities of ML models to malicious attacks (e.g., adversarial/poisoning attacks) have raised severe concerns in safety-critical applications. The adversarial ML could also result in potential data privacy and ethical issues when deploying ML techniques in real-world applications. Counter-intuitive behaviors of ML models will largely affect the public trust on AI techniques, while a revolution of machine learning/deep learning methods may be an urgent need. This workshop aims to discuss important topics about adversarial ML to deepen our understanding of ML models in adversarial environments and build reliable ML systems in the real world.
Topics

Malicious attacks for ML models to identify their vulnerability in black-box/real-world scenarios.
Novel algorithms and theories to improve model robustness.
Benchmarks to reliably evaluate attacks/defenses and measure the real progress of the field.
Theoretical understanding of adversarial ML and its connection to other areas.
The positive/negative social impacts and ethical issues related to adversarial ML.
The consideration and experience of adversarial ML from industry and policy making.
Positive applications of adversarial ML, i.e., adversarial for good.

Format
This is a one-day workshop, planned with a 10-minute opening, 6 invited keynotes, ~6 contributed talks, 2 poster sessions, and 2 panel discussions. We’ll also host a competition on adversarial ML along with this workshop.
There will be about 60~85 people to participate, including the program committee, invited speakers, panelists, authors of accepted papers, winners of the competition and other interested people.
Submissions
We consider submissions that haven’t been published in any peer-reviewed venue (except those under review). The accepted papers will be allocated either a contributed talk or a poster presentation. Submissions including full papers (6-8 pages) and short papers (2-4 pages) should be anonymized and follow the AAAI-22 Formatting Instructions (two-column format) at https://www.aaai.org/Publications/Templates/AuthorKit22.zip.
Submit to: https://openreview.net/group?id=AAAI.org/2022/Workshop/AdvML
Workshop Chair
Yinpeng Dong (dyp17@mails.tsinghua.edu.cn, 30 Shuangqing Road, Haidian District, Tsinghua University, Beijing, China, 100084, Phone: +86 18603303421)
Organizing Committee
Yinpeng Dong (Tsinghua University, dyp17@mail.tsinghua.edu.cn), Tianyu Pang (Tsinghua University, pty17@mails.tsinghua.edu.cn), Xiao Yang (Tsinghua University, yangxiao19@mails.tsinghua.edu.cn), Eric Wong (MIT, wongeric@mit.edu), Zico Kolter (CMU, zkolter@cs.cmu.edu), Yuan He (Alibaba, heyuan.hy@alibaba-inc.com )
Additional Information
Workshop URL

W2: AI for Agriculture and Food Systems (AIAFS)
An increasing world population, coupled with finite arable land, changing diets, and the growing expense of agricultural inputs, is poised to stretch our agricultural systems to their limits. By the end of this century, the earth’s population is projected to increase by 45% with available arable land decreasing by 20% coupled with changes in what crops these arable lands can best support; this creates the urgent need to enhance agricultural productivity by 70% before 2050. Current rates of progress are insufficient, making it impossible to meet this goal without a technological paradigm shift. There is increasing evidence that enabling AI technology has the potential to aid in the aforementioned paradigm shift. This AAAI workshop aims to bring together researchers from core AI/ML, robotics, sensing, cyber physical systems, agriculture engineering, plant sciences, genetics, and bioinformatics communities to facilitate the increasingly synergistic intersection of AI/ML with agriculture and food systems. Outcomes include outlining the main research challenges in this area, potential future directions, and cross-pollination between AI researchers and domain experts in agriculture and food systems.
Topics
Specific topics of interest for the workshop include (but are not limited to) foundational and translational AI activities related to:

Plant breeding
Precision agriculture and farm management
Biotic/Abiotic stress prediction
Yield prediction
Agriculture data curation
Annotation efficient learning
Plant growth and development models
Remote sensing
Agricultural robotics
Privacy-preserving data analysis
Human-in-the-loop AI
Multimodal data fusion
High-throughput field phenotyping
(Bio)physics aware hybrid AI modeling
Development of open-source software, libraries, annotation tools, or benchmark datasets

Format
The workshop will be a one day meeting comprising invited talks from researchers in the field, spotlight lightning talks and a poster session where contributing paper presenters can discuss their work. Attendance is open to all registered participants.
Submissions
Submitted technical papers can be up to 4 pages long (excluding references and appendices). Position papers are welcome. All papers must be submitted in PDF format using the AAAI-22 author kit. Papers will be peer-reviewed and selected for spotlight and/or poster presentation.
Submission site: https://openreview.net/group?id=AAAI.org/2022/Workshop/AIAFS
Organizing Committee
Girish Chowdhary (University of Illinois, Urbana Champaign), Baskar Ganapathysubramanian (Iowa State University; contact: baskarg@iastate.edu), George Kantor (Carnegie Mellon University), Soumyashree Kar (Iowa State University), Koushik Nagasubramanian (Iowa State University), Soumik Sarkar (Iowa State University), Katia Sycara (Carnegie Mellon University), Sierra Young (North Carolina State University), Alina Zare (University of Florida, Gainesville)
Additional Information
Supplemental workshop site: https://aiafs-aaai2022.github.io/

W3: AI for Behavior Change
In decision-making domains as wide-ranging as medication adherence, vaccination uptakes, college enrollment, retirement savings, and energy consumption, behavioral interventions have been shown to encourage people towards making better choices. It is important to learn how to use AI effectively in these areas in order to be able to motivate and help people to take actions that maximize their welfare.
At least three research trends are informing insights in this field. First, large data sources, both conventionally used in social sciences (EHRs, health claims, credit card use, college attendance records) and unconventional (social networks, fitness apps), are now available, and are increasingly used to personalize interventions. These datasets can be leveraged to learn individuals’ behavioral patterns, identify individuals at risk of making sub-optimal or harmful choices, and target them with behavioral interventions to prevent harm or improve well-being. Second, psychological experiments in laboratories and in the field, in partnership with technology companies (e.g., using apps), to measure behavioral outcomes are being increasingly used for informing intervention design. Finally, there is an increasing interest in AI in moving beyond traditional supervised learning approaches towards learning causal models, which can support the identification of targeted behavioral interventions. These research trends inform the need to explore the intersection of AI with behavioral science and causal inference, and how they can come together for applications in the social and health sciences.
This proposed workshop will build upon successes and learnings from last year’s successful AI for Behavior Change workshop, and will focus on on advances in AI and ML that aim to (1) design and target optimal interventions; (2) explore bias and equity in the context of decision-making and (3) exploit datasets in domains spanning mobile health, social media use, electronic health records, college attendance records, fitness apps, etc. for causal estimation in behavioral science.
Topics
The goal of this workshop is to bring together the causal inference, artificial intelligence, and behavior science communities, gathering insights from each of these fields to facilitate collaboration and adaptation of theoretical and domain-specific knowledge amongst them. We invite thought-provoking submissions on a range of topics in fields including, but not limited to, the following areas:

Intervention design
Adaptive/optimal treatment assignment
Heterogeneity estimation
Targeted nudges
Bias/equity in algorithmic decision-making
Mental health/wellness
Habit formation
Social media interventions
Psychological science
Precision health
Vaccine Hesitancy/Vaccine Uptake

Format
The full-day workshop will start with a keynote talk, followed by an invited talk and contributed paper presentations in the morning. The post-lunch session will feature a second keynote talk, two invited talks. Papers more suited for a poster, rather than a presentation, would be invited for a poster session. We will also select some of the best posters for spotlight talks (2 minutes each). We will end the workshop with a panel discussion by top researchers in the field.
Invited Speakers
Colin Camerer (California Institute of Technology), Susan Murphy (Harvard University)
Submissions
The audience of this workshop will be researchers and students from a wide array of disciplines including, but not limited to, statistics, computer science, economics, public policy, psychology, management, and decision science, who work at the intersection of causal inference, machine learning, and behavior science. AAAI, specifically, is a great venue for our workshop because its audience spans many ML and AI communities. We invite novel contributions following the AAAI-22 formatting guidelines, camera-ready style. Submissions will be peer reviewed, single-blinded. Submissions will be assessed based on their novelty, technical quality, significance of impact, interest, clarity, relevance, and reproducibility. We accept two types of submissions – full research papers no longer than 8 pages (including references) and short/poster papers with 2-4 pages. References will not count towards the page limit. Submissions will be accepted via the Easychair submission website.
Organizing Committee
Lyle Unga (University of Pennsylvania, ungar@cis.upenn.edu), Rahul Ladhania* (University of Michigan, ladhania@umich.edu, primary contact), Linnea Gandhi (University of Pennsylvania, lgandhi@wharton.upenn.edu), Michael Sobolev (Cornell Tech, michael.sobolev@cornell.edu)
Additional Information
Supplemental workshop site: https://ai4bc.github.io/ai4bc22/
Contact
For any questions, please reach out to us at ai4behaviorchange at gmail dot com

W4: AI for Decision Optimization
This AAAI-22 workshop on AI for Decision Optimization (AI4DO) will explore how AI can be used to significantly simplify the creation of efficient production level optimization models, thereby enabling their much wider application and resulting business values.The desired outcome of this workshop is to drive forward research and seed collaborations in this area by bringing together machine learning and decision-making from the lens of both dynamic and static optimization models.
Topics
Topics include, but our not limited to: learning optimization models from data, constraint and objective learning, AutoAI, especially if combined with decision optimization models or environments, AutoRL, incorporating the inaccuracy of the automatically learnt models in the decision making process, and using machine learning to efficiently solve combinatorial optimization models.
Format
In addition to the keynote and presentations of accepted works, the workshop will include both a general discussion session on defining and addressing the key challenges in this area , and a “lightning tutorial” session that will include brief overviews and demos of relevant tools, including open source frameworks such as Ecole.
Attendance
Participation of researchers from a wide variety of areas is encouraged, including Data Science, Machine Learning, Symbolic AI, Mathematical programming, Constraint Optimization, Reinforcement Learning, Dynamic control and Operations Research.
Submissions
Authors are invited to send a contribution in the AAAI-22 proceedings format. We will accept both original papers up to 8 pages in length (including references) as well as position papers and papers covering work in progress up to 4 pages in length (not including references).Submission will be through Easychair at the AAAI-22 Workshop AI4DO submission site
Workshop Chairs
Professor Bistra Dilkina (dilkina@usc.edu), USC and Dr. Segev Wasserkrug, (segevw@il.ibm.com), IBM Research
Organizing Committee
Prof. Andrea Lodi (andrea.lodi@cornell.edu), Jacobs Technion-Cornell Institute – IIT and Dr. Dharmashankar Subrmanian (dharmash@us.ibm.com), IBM Research
Additional Information
https://research.ibm.com/haifa/Workshops/AAAI-22-AI4DO/

W5: AI for Transportation
In recent years, machine learning techniques (e.g. sup-port vector machine (SVM), decision tree, random forest, etc.) and deep learning techniques (e.g. convolutional neural network (CNN), recurrent neural network (RNN), etc.) have been popularly applied into image recognition and time-series inferences for intelligent transportation systems (ITS). For instance, advanced driver assistance systems and autonomous cars have been developed based on AI techniques to perform forward collision warning, blind spot monitoring, lane departure warning systems, traffic sign recognition, traffic safety, infrastructure management and congestion, and so on. Autonomous vehicles can share their detected information (e.g., traffic signs, collision events, etc.) with other vehicles via vehicular communication systems (e.g., dedicated short range communication (DSRC), vehicular ad hoc networks (VANETs), long term evolution (LTE), and 5G/6G mobile networks) for cooperation. However, the performance and efficiency of these techniques are big challenges for performing real-time applications.
The aim of this workshop is to focus on both original research and review articles on various disciplines of ITS applications, including particularly AI techniques for ITS time-series data analyses, ITS spatio-temporal data analyses, advanced traffic management systems, advanced traveler information systems, commercial vehicle operation systems, advanced vehicle control and safety systems, advanced public transportation services, advanced information management services, etc.
Topics

AI for ITS time-series and spatio-temporal data analyses
AI for the applications of transportation
AI for image recognition
Applications and techniques in image recognition based on AI techniques for ITS
Applications and techniques in autonomous cars and ships based on AI techniques
AI for quality of service in VANET
AI for infrastructure management and congestion.

Format
The workshop is organized by paper presentations.The length of the workshop: 1-day
Submissions
6-8 pages for full papers2-4 for poster/short/position papers
Submission URL: https://easychair.org/conferences/?conf=aaai-2022-workshop 
Workshop Chairs
Wenzhong Guo (Fuzhou University, fzugwz@163.com), Chin-Chen Chang (Feng Chia University, alan3c@gmail.com), Chi-Hua Chen (Fuzhou University, chihua0826@gmail.com), Haishuai Wang (Fairfield University & Harvard University, hwang@fairfield.edu)
Session Chairs
Feng-Jang Hwang (University of Technology Sydney), Cheng Shi (Xi’an University of Technology), Ching-Chun Chang (National Institute of Informatics, Japan)
Additional Information
The excellent papers will be recommended for publications in SCI or EI journals. Detailed information could be found on the website of the workshop.
Workshop URL: https://rail.fzu.edu.cn/info/1014/1064.htm
Contact
Prof. Chi-Hua ChenEmail: chihua0826@gmail.comPostal address: No.2, Xueyuan Rd., Fuzhou, Fujian, ChinaTelephone: +86-18359183858

W6: AI in Financial Services: Adaptiveness, Resilience & Governance
The financial services industry relies heavily on AI and Machine Learning solutions across all business functions and services. However, most models and AI systems are built with conservative operating environment assumptions due to regulatory compliance concerns. In recent months/years, major global shifts have occurred across the globe triggered by the Covid pandemic. These abrupt changes impacted the environmental assumptions used by AI/ML systems and their corresponding input data patterns. As a result, many AI/ML systems faced serious performance challenges and failures. Industry-wide reports highlight large-scale remediation efforts to fix the failures and performance issues. Yet, most of these efforts highlighted the challenges of model governance and compliance processes.
Topics
This workshop starts with acknowledging the fundamental challenges of robustness and adaptiveness in financial services modeling and explores systematic solutions to solve these underlying problems to prevent future failures. Some of the key questions to be explored include:

Why did so many AI/ML models fail during the pandemic?
What are the primary lessons learned from the model failures?
What techniques and approaches can be used to detect and effectively manage similar scenarios in the future?
What approaches emerge in building fundamentally robust and adaptive AI/ML systems?
How can the financial services industry balance the regulatory compliance and model governance pressures with adaptive models

Format
The workshop will take place in person and will span over one day. It will include multiple keynote speakers, invited talks, a panel discussion, and two poster sessions for the accepted papers.
Papers can be submitted here as an extended abstract (4 pages limit excluding references) or a short paper (6 pages limit excluding references). Submissions should follow the AAAI-2022 https://aaai.org/Conferences/AAAI-22/aaai22call/.
Important Dates
Paper Submission: November 12, 2021, 11:59 pm (anywhere on earth) Author Notification: December 3, 2021Full conference: February 22 – March 1, 2022Workshop: February 28 – March 1, 2022
Submissions
The workshop page is https://sites.google.com/view/aaaiwfs2022, and it will include the most up-to-date information, including the exact schedule.
Organizing Committee
Naftali Cohen (JP Morgan Chase & New York University), Eren Kurshan (Bank of America & Columbia University), Senthil Kumar (Capital One), Susan Tibbs (Financial Institutions Regulatory Authority, FINRA), Tucker Balch (JP Morgan Chase & Georgia Institute of Technology), and Kevin Compher (Securities Exchange Commission)

W7: AI to Accelerate Science and Engineering (AI2ASE)
Scientists and engineers in diverse domains are increasingly relying on using AI tools to accelerate scientific discovery and engineering design. This workshop aims to bring together researchers from AI and diverse science/engineering communities to achieve the following goals:
1) Identify and understand the challenges in applying AI to specific science and engineering problems2) Develop, adapt, and refine AI tools for novel problem settings and challenges3) Community-building and education to encourage collaboration between AI researchers and domain area experts
Topics
Some specific topics in the context of scientific discovery and engineering design include (but not limited to):

Methods to combine scientific knowledge and data to build accurate predictive models
Adaptive experiment design under resource constraints
Learning cheap surrogate models to accelerate simulations
Learning effective representations for structured data
Uncertainty quantification and reasoning tools for decision-making
Explainable AI for both prediction and decision-making
Integrating AI tools into existing workflows
Challenges in applying and deployment of AI in the real-world

Format
This will be a one day workshop with a number of paper presentations and poster spotlights, a poster session, several invited talks, and a panel discussion.
Prof. Max Welling, University of Amsterdam and Microsoft ResearchProf. José Miguel Hernández-Lobato, University of CambridgeProf. Connor Coley, Massachusetts Institute of TechnologyProf. Andrew White, University of RochesterDr. Rocío Mercado, Massachusetts Institute of Technology
We will include a panel discussion to close the workshop, in which the audience can ask follow up questions and to identify the key AI challenges to push the frontiers in Chemistry.
Submissions
We welcome submissions of long (max. 8 pages), short (max. 4 pages), and position (max. 4 pages) papers describing research at the intersection of AI and science/engineering domains including chemistry, physics, power systems, materials, catalysis, health sciences, computing systems design and optimization, epidemiology, agriculture, transportation, earth and environmental sciences, genomics and bioinformatics, civil and mechanical engineering etc.
Submissions must be formatted in the AAAI submission format (https://www.aaai.org/Publications/Templates/AuthorKit22.zip) All submissions should be done electronically via EasyChair.
Submission site: TBD
Organizing Committee
Aryan Deshwal (Washington State University, aryan.deshwal@wsu.edu), Syrine Belakaria (Washington State University, syrine.belakaria@wsu.edu), Cory Simon (Oregon State University, cory.simon@oregonstate.edu), Jana Doppa (Washington State University, jana.doppa@wsu.edu), Yolanda Gil (University of Southern California, gil@isi.edu)
Additional Information
Supplemental workshop site: https://ai-2-ase.github.io/
For general inquiries about AI2ASE, please write to the lead organizer aryan.deshwal@wsu.edu or jana.doppa@wsu.edu.

W8: AI-Based Design and Manufacturing (ADAM)
Advances in complex engineering systems such as manufacturing and materials synthesis increasingly seek artificial intelligence/machine learning (AI/ML) solutions to enhance their design, development, and production processes. However, despite increasing interest from various subfields, AI/ML techniques are yet to fulfill their full promise in achieving these advances. Key obstacles include lack of high-quality data, difficulty in embedding complex scientific and engineering knowledge in learning, and the need for high-dimensional design space exploration under constrained budgets. The first AAAI Workshop on AI for Design and Manufacturing, ADAM, aims to bring together researchers from core AI/ML, design, manufacturing, scientific computing, and geometric modeling. Our intent is to facilitate new AI/ML advances for core engineering design, simulation, and manufacturing. Objectives of ADAM include outlining the main research challenges in this area, cross-pollinating collaborations between AI researchers and domain experts in engineering design and manufacturing, and sketching open problems of common interest.
Topics
We invite paper submission on the following (and related) topics:

New theory and fundamentals of AI-aided design and manufacturing,
Novel AI-based techniques to improve modeling of engineering systems,
Integration of AI-based approaches with engineering prototyping and manufacturing,
Novel methods to learn from scarce/sparse, or heterogenous, or multimodal data,
Novel ML methods in the computational material and physical sciences,
Novel ML-accelerated optimization for conceptual/detailed system design,
Novel AI-enabled generative models for system design and manufacturing,
ML-guided rare event modeling and system uncertainty quantification,
Development of software, libraries, or benchmark datasets, and
Identification of key challenges and opportunities for future research.

Format
The workshop will be a 1 day meeting comprising several invited talks from distinguished researchers in the field, spotlight lightning talks and a poster session where contributing paper presenters can discuss their work, and a concluding panel discussion focusing on future directions. Attendance is open to all registered participants.
Submissions
Submitted technical papers can be up to 4 pages long (excluding references and appendices). Position papers are welcome. All papers must be submitted in PDF format using the AAAI-22 author kit. Papers will be peer-reviewed and selected for spotlight and/or poster presentation.
Submission site: https://openreview.net/group?id=AAAI.org/2022/Workshop/ADAM
Organizing Committee
Aarti Singh (Carnegie Mellon University), Baskar Ganapathysubramanian (ISU), Chinmay Hegde (New York University; contact: chinmay.h@nyu.edu), Mark Fuge (University of Maryland), Olga Wodo (University of Buffalo), Payel Das (IBM), Soumalya Sarkar (Raytheon)
Additional Information
Workshop website: https://adam-aaai2022.github.io/

W9: Artificial Intelligence for Cyber Security (AICS)
The workshop will focus on the application of AI to problems in cyber-security. Cyber systems generate large volumes of data, utilizing this effectively is beyond human capabilities. Additionally, adversaries continue to develop new attacks. Hence, AI methods are required to understand and protect the cyber domain. These challenges are widely studied in enterprise networks, but there are many gaps in research and practice as well as novel problems in other domains.
This year the AICS emphasis will be on practical considerations in the real world when deploying AI systems for security with a special focus on convergence of AI and cyber-security in the biomedical field.
In general, AI techniques are still not widely adopted in the real world. Reasons include: (1) a lack of certification of AI for security, (2) a lack of formal study of the implications of practical constraints (e.g., power, memory, storage) for AI systems in the cyber domain, (3) known vulnerabilities such as evasion, poisoning attacks, (4) lack of meaningful explanations for security analysts, and (5) lack of analyst trust in AI solutions. There is a need for the research community to develop novel solutions for these practical issues.
The biomedical space has seen a flurry of activity recently, and cyber criminals have amplified their efforts with health-related phishing attacks, spreading misinformation, and intruding into health infrastructure. These lead to security considerations: (1) securing personal health information, genetic material, intellectual property, and digital health records, (2) balancing privacy rights and data ownership concerns in solutions using network and mobile data, (3) defending AI for biology use cases to deter automated attacks at scale.
Topics
Topics of interest in the biomedical space include:

Securing personal information, genomics, and intellectual property
Adversarial attacks and defenses on biomedical datasets
Detecting and preventing spread of misinformation
Usable security and privacy for digital health information
Phishing and other attacks using health information
Novel use of biometrics to enhance security
Threats to biometric security

Topics of general interest to cyber-security include:

Machine learning (including RL) security and resiliency
Natural language processing
Anomaly detection
Noise reduction
Adversarial learning
Formal reasoning
Game-theoretic reasoning
AI assurance and securing AI systems
Multi-agent interaction modeling
Modeling and simulation of cyber systems
Decision-making under uncertainty
Automation of data labeling and ML techniques
Quantitative human behavior models
Operational and commercial applications of AI
Explanations of security decisions and vulnerability of explanations
Human-AI teaming for cyber security

Submissions
Submission site: https://easychair.org/conferences/?conf=aics22
Organizing Committee
Tamara Broderick (MIT CSAIL, tamarab@mit.edu), James Holt (Laboratory for Physical Sciences, USA, holt@lps.umd.edu), Edward Raff (Booz Allen Hamilton, USA, Raff_Edward@bah.com), Ahmad Ridley (National Security Agency), Dennis Ross (MIT Lincoln Laboratory, USA, dennis.ross@ll.mit.edu), Arunesh Sinha (Singapore Management University, Singapore, aruneshs@smu.edu.sg), Diane Staheli (MIT Lincoln Laboratory, USA, diane.staheli@ll.mit.edu), William W. Streilein (MIT Lincoln Laboratory, USA, wws@ll.mit.edu), Milind Tambe (Harvard University, USA, milind_tambe@harvard.edu), Yevgeniy Vorobeychik (Washington University in Saint Louis, USA, eug.vorobey@gmail.com) Allan Wollaber (MIT Lincoln Laboratory, USA, Allan.Wollaber@ll.mit.edu)
Additional Information
Supplemental workshop site: http://aics.site/ 

W10: Artificial Intelligence for Education (AI4EDU)
Technology has transformed over the last few years, turning from futuristic ideas into today’s reality. AI is one of these transformative technologies that is now achieving great successes in various real-world applications and making our life more convenient and safer. AI is now shaping the way businesses, governments, and educational institutions do things and is making its way into classrooms, schools and districts across many countries.
In fact, the increasingly digitized education tools and the popularity of online learning have produced an unprecedented amount of data that provides us with invaluable opportunities for applying AI in education. Recent years have witnessed growing efforts from the AI research community devoted to advancing our education and promising results have been obtained in solving various critical problems in education. For example, AI tools are built to ease the workload for teachers. Instead of grading each piece of work individually, which can take up a bulk of extra time, intelligent scoring tools allow teachers the ability to have their students work automatically graded. In the coronavirus era, requiring many schools to move to online learning, the ability to give feedback at scale could provide needed support to teachers. What’s more, various AI based models are trained on massive student behavioral and exercise data to have the ability to take note of a student’s strengths and weaknesses, identifying where they may be struggling. These models can also generate instant feedback to instructors and help them to improve their teaching effectiveness. Furthermore, leveraging AI to connect disparate social networks amongst teachers \\cite{karimi2020towards}, we may be able to provide greater resources for their planning, which have been shown to significantly affect students’ achievement.
Despite gratifying achievements that have demonstrated the great potential and bright development prospect of introducing AI in education, developing and applying AI technologies to educational practice is fraught with its unique challenges, including, but not limited to, extreme data sparsity, lack of labeled data, and privacy issues. Hence, this workshop will focus on introducing research progress on applying AI to education and discussing recent advances of handling challenges encountered in AI educational practice.
Format
We propose a full day workshop with the following sessions:

Oral presentations: 10 minute presentation for oral papers.
Poster session: One poster session of all accepted papers which leads for interaction and personal feedback to the research.
Keynotes and invited talks: Several keynotes and invited talks by leading researchers in the area will be presented.
Panel discussion: Interactive Q&A session with a panel of leading researchers

Attendance
25-50 people
Submissions
The workshop solicits paper submissions from participants (2–6 pages). Abstracts of the following flavors will be sought: (1) research ideas, (2) case studies (or deployed projects), (3) review papers, (4) best practice papers, and (5) lessons learned. The format is the standard double-column AAAI Proceedings Style. All submissions will be peer-reviewed. Some will be selected for spotlight talks, and some for the poster session.
Organizing Committee
Zitao Liu (main contact) , TAL Education Group, liuzitao@tal.com, http://www.zitaoliu.com
Jiliang Tang (Michigan State University, tangjili@msu.edu, https://www.cse.msu.edu/~tangjili/), Lihan Zhao (TAL Education Group, zhaolihan@tal.com), and Xiao Zhai (TAL Education Group, zhaixiao@tal.com)
Additional Information
Workshop URL: http://ai4ed.cc/workshops/aaai2022

W11: Artificial Intelligence Safety (SafeAI 2022)
The accelerated developments in the field of Artificial Intelligence (AI) hint at the need for considering Safety as a design principle rather than an option. However, theoreticians and practitioners of AI and Safety are confronted with different levels of safety, different ethical standards and values, and different degrees of liability, that force them to examine a multitude of trade-offs and alternative solutions. These choices can only be analyzed holistically if the technological and ethical perspectives are integrated into the engineering problem, while considering both the theoretical and practical challenges of AI safety. A new and comprehensive view of AI Safety must cover a wide range of AI paradigms, including systems that are application-specific as well as those that are more general, considering potentially unanticipated risks. In this workshop, we want to explore ways to bridge short-term with long-term issues, idealistic with pragmatic solutions, operational with policy issues, and industry with academia, to build, evaluate, deploy, operate and maintain AI-based systems that are demonstrably safe.
This workshop seeks to explore new ideas on AI safety with particular focus on addressing the following questions:

What is the status of existing approaches in ensuring AI and Machine Learning (ML) safety, and what are the gaps?
How can we engineer trustable AI software architectures?
How can we make AI-based systems more ethically aligned?
What safety engineering considerations are required to develop safe human-machine interaction?
What AI safety considerations and experiences are relevant from industry?
How can we characterize or evaluate AI systems according to their potential risks and vulnerabilities?
How can we develop solid technical visions and new paradigms about AI Safety?
How do metrics of capability and generality, and the trade-offs with performance affect safety?
The main interest of the proposed workshop is to look at a new perspective of system engineering where multiple disciplines such as AI and safety engineering are viewed as a larger whole, while considering ethical and legal issues, in order to build trustable intelligent autonomy.

Topics
Contributions are sought in (but are not limited to) the following topics:

Safety in AI-based system architectures
Continuous V&V and predictability of AI safety properties
Runtime monitoring and (self-)adaptation of AI safety
Accountability, responsibility and liability of AI-based systems
Uncertainty in AI
Avoiding negative side effects in AI-based systems
Role and effectiveness of oversight: corrigibility and interruptibility
Loss of values and the catastrophic forgetting problem
Confidence, self-esteem and the distributional shift problem
Safety of AGI systems and the role of generality
Reward hacking and training corruption
Self-explanation, self-criticism and the transparency problem
Human-machine interaction safety
Regulating AI-based systems: safety standards and certification
Human-in-the-loop and the scalable oversight problem
Evaluation platforms for AI safety
AI safety education and awareness
Experiences in AI-based safety-critical systems, including industrial processes, health, automotive systems, robotics, critical infrastructures, among others

Format
To deliver a truly memorable event, we will follow a highly interactive format that will include invited talks and thematic sessions. The thematic sessions will be structured into short pitches and a common panel slot to discuss both individual paper contributions and shared topic issues. Three specific roles are part of this format: session chairs, presenters and paper discussants. The workshop will be organized as a full day meeting. Attendance is virtual and open to all. At least one author of each accepted submission must register and present the paper at the workshop.
Submissions
You are invited to submit:

Full technical papers (6-8 pages),
Proposals of technical talk (up to one-page abstract including short Bio of the main speaker),
Position papers (4-6 pages), and

Manuscripts must be submitted as PDF files via EasyChair online submission system.
Please keep your paper format according to AAAI Formatting Instructions (two-column format). The AAAI author kit can be downloaded from: https://www.aaai.org/Publications/Templates/AuthorKit22.zip.
Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper). The workshop follows a single-blind reviewing process. However, we will also accept anonymous submissions.
Organizing Committee
Gabriel Pedroza (CEA LIST), José Hernández-Orallo (Universitat Politècnica de València, Spain), Xin Cynthia Chen (University of Hong Kong, China), Xiaowei Huang (University of Liverpool, UK), Huascar Espinoza (KDT JU, Belgium), Mauricio Castillo-Effen (Lockheed Martin, USA), Seán Ó hÉigeartaigh (University of Cambridge, UK), Richard Mallah (Future of Life Institute, USA), John McDermid (University of York, UK)
Additional Information
Supplemental workshop site: http://safeaiw.org/

W12: Artificial Intelligence with Biased or Scarce Data
Despite rapid recent progress, it has proven to be challenging for Artificial Intelligence (AI) algorithms to be integrated into real-world applications such as autonomous vehicles, industrial robotics, and healthcare. A primary reason for this is the inherent long-tailed nature of our world, and the need for algorithms to be trained with large amounts of data that includes as many rare events as possible. However, these real-world applications typically translate to problem domains where it is extremely challenging to even obtain raw data, let alone annotated data. Even in cases where one is able to collect data, there are inherently many kinds of biases in this process, leading to biased models.
In light of these issues, and the ever-increasing pervasiveness of AI in the real world, we seek to provide a focused venue for academic and industry researchers and practitioners to discuss research challenges and solutions associated with building AI systems under data scarcity and/or bias.
Topics
We invite the submission of original and high-quality research papers in the topics related to biased or scarce data. The topics for AIBSD 2022 include, but are not limited to:

Algorithms and theories for explainable and interpretable AI models.
Application-specific designs for explainable AI, e.g., healthcare, autonomous driving, etc.
Algorithms and theories for learning AI models under bias and scarcity.
Performance characterization of AI algorithms and systems under bias and scarcity.
Algorithms for secure and privacy-aware machine learning for AI.
Algorithms and theories for trustworthy AI models.
The role of adjacent fields of study (e.g, computational social science) in mitigating issues of bias and trust in AI.
Continuous refinement of AI models using active/online learning.
Meta-learning models from various existing task-specific AI models.
Brave new ideas to learn AI models under bias and scarcity.

Format
This one-day workshop will include invited talks from keynote speakers, and oral/spotlight presentations of the accepted papers. Each oral presentation will be allocated between 10-15 minutes, while the spotlight presentation will be 2 minute each. There will be live Q&A sessions at the end of each talk and oral presentation.
Attendance
We expect 50~75 participants and potentially more according to our past experiences. We cordially welcome researchers, practitioners, and students from academia and industry who are interested in understanding and discussing how data scarcity and bias can be addressed in AI to participate.
Submissions
We welcome full paper submissions (up to 8 pages, excluding references or supplementary materials). The paper submissions must be in pdf format and use the AAAI official templates. All submissions must be anonymous and conform to AAAI standards for double-blind review. The accepted papers will be posted on the workshop website and will not appear in the AAAI proceedings. At least one author of each accepted submission must present the paper at the workshop.
Submit to: https://cmt3.research.microsoft.com/AIBSD2022
Organizing Committee
Kuan-Chuan Peng (Mitsubishi Electric Research Laboratories, kp388@cornell.edu), Ziyan Wu (UII America, Inc., wuzy.buaa@gmail.com)
Additional Information
Supplemental workshop site: https://aibsdworkshop.github.io/2022/index.html

W13: Combining Learning and Reasoning: Programming Languages, Formalisms, and Representations (CLeaR)
This workshop brings together researchers from diverse backgrounds with different perspectives to discuss languages, formalisms and representations that are appropriate for combining learning and reasoning. The workshop aims at bridging formalisms for learning and reasoning such as neural and symbolic approaches, probabilistic programming, differentiable programming, Statistical Relation Learning and using non-differentiable optimization in deep models. It highlights the importance of declarative languages that enable such integration for covering multiple formalisms at a high-level and points to the need for building a new generation of ML tools to help domain experts in designing complex models where they can declare their knowledge about the domain and use data-driven learning models based on various underlying formalisms. This workshop wants to emphasize on the importance of integrative paradigms for solving the new wave of AI applications.
Topics
The main research questions and topics of interest include, but are not limited to:

Programming Languages, Domain specific languages, Libraries and software tools for integration of various learning and reasoning paradigms
Integration of probabilistic inference in training deep models,
Integration of neuro and symbolic approaches,
Integration of logical inference in training deep models,
Integration of Deep Learning and Relational Learning,
Integration of Deep learning and Constraint programming,
Declarative languages and differentiable programming,
Integration of declarative and procedural domain knowledge in learning,
Integration of non-differentiable optimization models in learning.

Format
This will be a one day workshop, including four invited speakers, one panel session, a number of oral presentations of the accepted long papers and two poster sessions for all accepted papers including short and long.
Attendance
We send a public call and we assume the workshop will be of interest to many AAAI main conference audiences; we expect 50 participants. We allow both short (2-4 pages) and long papers (6-8 pages) papers. We will accept the extended abstracts of the relevant and recently published work too.
Submissions
Papers will be submitted to OpenReview system: Waiting for approval, https://openreview.net/forum?id=6uMNTvU-akO
Organizing Committee
Workshop Chair: Parisa Kordjamshidi, +1-2174187004, kordjams@msu.edu
Organizing Committee: Parisa Kordjamshidi (Michigan State University, kordjams@msu.edu), Behrouz Babaki (Mila/HEC Montreal, behrouz.babaki@mila.quebec), Sebastijan Dumančić (KU Leuven, sebastijan.dumancic@cs.kuleuven.be), Alex Ratner (University of Washington, ajratner@cs.washington.edu), Hossein Rajaby Faghihi (Michigan State University, rajabyfa@msu.edu), Hamid Karimian (Michigan State University, karimian@msu.edu)
Organizing Committee:Dan Roth (University of Pennsylvania, danroth@seas.upenn.edu) and Guy Van Den Broeck (University of California Los Angeles, guyvdb@cs.ucla.edu)
Additional Information
Supplemental workshop site: https://clear-workshop.github.io

W14: Deep Learning on Graphs: Methods and Applications (DLG-AAAI’22)
Topics of interest (including but not limited to)
We invite submission of papers describing innovative research and applications around the following topics. Papers that introduce new theoretical concepts or methods, help to develop a better understanding of new emerging concepts through extensive experiments, or demonstrate a novel application of these methods to a domain are encouraged.

Graph neural networks on node-level, graph-level embedding
Joint learning of graph neural networks and graph structure
Graph neural networks on graph matching
Dynamic/incremental graph-embedding
Learning representation on heterogeneous networks, knowledge graphs
Deep generative models for graph generation/semantic-preserving transformation
Graph2seq, graph2tree, and graph2graph models
Deep reinforcement learning on graphs
Adversarial machine learning on graphs
Spatial and temporal graph prediction and generation

And with particular focuses but not limited to these application domains:

Learning and reasoning (machine reasoning, inductive logic programming, theory proving)
Natural language processing (information extraction, semantic parsing, text generation)
Bioinformatics (drug discovery, protein generation, protein structure prediction)
Program synthesis and analysis
Reinforcement learning (multi-agent learning, compositional imitation learning)
Financial security (anti-money laundering)
Cybersecurity (authentication graph, Internet of Things, malware propagation)
Geographical network modeling and prediction (Transportation and mobility networks, social networks)
Computer vision (object relation, graph-based 3D representations like mesh)

Format
Our program consists of two sessions: academic session and industry session. The academic session will focus on most recent research developments on GNNs in various application domains. The industry session will emphasize practical industrial product developments using GNNs. We will also have a panel discussion on the current and future of GNNs on both research and industry. In addition, several invited speakers with distinguished professional background will give talks related the frontier topics of GNN.
The desired LENGTH of the workshop: Full-day (~8 hours)
Attendance
Estimate of the audience size: 400-500 attendees (based on the number of attendees in previous DLG workshops in KDD’19, AAAI’20, KDD’20 and AAAI’21). About 7-8 invited speakers who are distinguished professional in Deep learning on graph will present the frontier research topics. All the workshop chairs, most of the Committees, and the authors of the accepted papers will attend the workshop also.
Submissions
Submissions are limited to a total of 5 pages for initial submission (up to 6 pages for final camera-ready submission), excluding references or supplementary materials, and authors should only rely on the supplementary material to include minor details that do not fit in the 5 pages. All submissions must be in PDF format and formatted according to the new Standard AAAI Conference Proceedings Template. Following this AAAI conference submission policy, reviews are double-blind, and author names and affiliations should NOT be listed. Submitted papers will be assessed based on their novelty, technical quality, potential impact, and clarity of writing. For papers that rely heavily on empirical evaluations, the experimental methods and results should be clear, well executed, and repeatable. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will be posted on the workshop website and will not appear in the AAAI proceedings.
Submit to: Papers are required to submit to: https://easychair.org/conferences/?conf=dlg22
Workshop Chair

Lingfei Wu (JD.Com Silicon Valley Research Center),lwu@email.wm.edu, 757-634-5455, https://sites.google.com/a/email.wm.edu/teddy-lfwu/
Jian Pei (Simon Fraser University), jian_pei@sfu.ca, 778-782-6851, https://sites.google.com/view/jpei/jian-peis-homepage
Jiliang Tang (Michigan State University), tangjili@msu.edu, 408-744-2053, https://www.cse.msu.edu/~tangjili/
Yinglong Xia (Facebook AI), yinglongxia@gmail.com, 213-309-9908, https://sites.google.com/site/yinglongxia/
Xiaojie Guo (JD.Com Silicon Valley Research Center), Xguo7@gmu.edu, 571-224-5527, https://sites.google.com/view/xiaojie-guo-personal-site

Please email to Lingfei Wu: lwu@email.wm.edu for any query.
Organizing Committee
Yuanqi du, George Mason University, USA; Jian Pei, Simon Fraser University, Canada; Charu Aggarwal, IBM Research AI, USA; Philip S. Yu, University of Illinois at Chicago, USA; Xuemin Lin, University of New South Wales, Australia; Jiebo Luo, University of Rochester, USA; Lingfei Wu, JD.Com Silicon Valley Research Center, USA; Yinglong Xia, Facebook AI, USA; Jiliang Tang, Michigan State University, USA; Peng Cui, Tsinghua University, China; William L. Hamilton, McGill University, Canada; Thomas Kipf, University of Amsterdam, Netherlands
Potential Workshop Committee

Ibrahim Abdelaziz, (IBM Research AI)
Sutanay Choudhury (Pacific Northwest National Lab)
Lingyang Chu (Simon Fraser University)
Tyler Derr (Michigan State University)
Stephan Günnemann (Technical University of Munich)
Balaji Ganesan, (IBM Research AI)
William L. Hamilton (McGill University)
Tengfei Ma (IBM Research AI)
Tian Gao (IBM Research AI)
Thomas Kipf (University of Amsterdam)
Renjie Liao (University of Toronto)
Yujia Li, (DeepMind)
Shen Wang, (University of Illinois at Chicago)
Liana Ling (IBM Research AI)
Yizhou Sun (University of California, Los Angeles)
Hanghang Tong (Arizona State University)
Richard Tong (Squirrel AI Learning)
Jian Tang (Mila)
Lingfei Wu (JD.Com Silicon Valley Research Center)
Qing Wang (IBM Research AI)
Yinglong Xia (Facebook AI)
Liang Zhao (George Mason University)
Dawei Zhou (Arizona State University)
Zhan Zheng (Washington University in St. Louis)
Feng Chen (University at Albany – State University of New York)

Additional Information
Workshop URL: https://deep-learning-graphs.bitbucket.io/dlg-aaai22/

W15: DE-FACTIFY :Multi-Modal Fake News and Hate-Speech Detection
Combating fake news is one of the burning societal crises. It is difficult to expose false claims before they create a lot of damage. Automatic fact/claim verification has recently become a topic of interest among diverse research communities. Research efforts and datasets on text fact verification could be found, but there is not much attention towards multi-modal or cross-modal fact-verification. This workshop will encourage researchers from interdisciplinary domains working on multi-modality and/or fact-checking to come together and work on multimodal (images, memes, videos etc.) fact-checking. At the same time, multimodal hate-speech detection is an important problem but has not received much attention. Lastly, learning joint modalities is of interest to both Natural Language Processing (NLP) and Computer Vision (CV) forums.
Topics
It is a forum to bring attention towards collecting, measuring, managing, mining, and understanding multimodal disinformation, misinformation, and malinformation data from social media. This workshop covers (but not limited to) the following topics: —

Development of corpora and annotation guidelines for multimodal fact checking
Computational models for multimodal fact checking
Development of corpora and annotation guidelines for multimodal hate speech detection and classification
Computational models for multimodal hate speech detection and classification
Analysis of diffusion of Multimodal fake news and hate speech in social networks
Understanding the impact of the hate content on specific groups (like targeted groups)
Fake news and hate speech detection in low resourced languages

Format
It is a one day workshop and includes: invited talks, interactive discussions, paper presentations, shared task presentations, poster session etc. We expect 60-70 participants. Our preliminary plan for the schedule is as following –
DEFACTIFY@AAAI-22 Program [tentative]———————————————————–9:00AM-9:15AMInaugurationA brief summary of the shared tasks – number of participants, best results
Session 1 – multimodal fact checkingWorkshop papers – 9:30AM – 10:30AM
10:30AM – 11:00AMBreak
11:00AM – 12:00pmInvited talk 1 – Prof. Rada Mihalcea, University of Michigan
12:00pm – 1:00pmLunch
Session 2 – Best 4/5 papers from FACTIFY & MEMOTION shared taskWorkshop papers – 1:00PM – 2:00PM
2:00PM – 3:30PMInvited talk 2 – Prof. LOUIS-PHILIPPE MORENCY, CMU
3:30PM – 4:00PMBreak
Session 2 – multimodal hate speechWorkshop papers – 4:00PM – 5:00PM
5:00PM-5:15PMClosing – vote of thanks
Submissions
We encourage long papers, short papers and demo papers. Submissions will undergo double blind review. Accepted papers are likely to be archived. We are in a conversation with some publishers – once they confirm, we will announce accordingly.
Primary Contact
Amitava Das (Wipro AI Labs; amitava.santu@gmail.com)
Organizing Committee
Workshop Chairs: Amitava Das (Wipro AI Labs) [India], Amit Sheth (University of South Carolina) [USA], Tanmoy Chakraborty (IIIT Delhi) [India], Asif Ekbal (IIT Patna) [India], Chaitanya Ahuja (CMU) [USA]
Student Volunteers
Parth Patwa (UCLA) [USA], Parul Chopra (CMU) [USA], Amrit Bhaskar (ASU) [USA], Nethra Gunti (IIIT Sri City) [USA], Sathyanarayanan R. (IIIT Sri City) [India], Shreyash Mishra (IIIT Sri City) [India], S. Suryavardan (IIIT Sri City) [India]
Web Chair
Vishal Pallagani (University of South Carolina)
Additional Information
Supplemental workshop site: https://aiisc.ai/defactify/

W16: Dialog System Technology Challenge (DSTC10)
The main goal of the dialog system technology challenge (DSTC) workshop is to share the result of five main tracks of the tenth dialog system technology challenge (DSTC10). We encourage all the teams who participated in the challenge to join the workshop. In addition, any other work on dialog research is welcome to the general technical track.
Topics
Dialog systems and related technologies, including natural language processing, audio and speech processing, and vision information processing.
Format
A 2-day workshop to share knowledge and research on five tracks of DSTC-10 and general related technical track. This will include invited talks, poster sessions and a panel to discuss the achievements of past DSTC series, and future direction.
Attendance
Attendance is open to any interested participants at AAAI-22. We will specifically invite participants of the DSTC10 tasks, track organizers, and authors of accepted papers in the general technical track.
Submissions
The submissions must follow the formatting guidelines for AAAI-22. All submissions must be anonymous and conform to AAAI standard for double-blind review. The papers may consist of up to seven pages of technical content plus up to two additional pages for references. We will receive the paper on the CMT system.
Submission site: https://cmt3.research.microsoft.com/DSTC102022
Organizing Committee Chair
Koichiro Yoshino,Address: 2-2-2, Seika, Sohraku, Kyoto, 6190288, JapanAffiliation: RIKENPhone: +81-774-95-1360Email: koichiro.yoshino@riken.jp
Workshop Co-chair
Yun-Nung (Vivian) ChenAddress: No. 1, Sec. 4, Roosevelt Rd., Taipei, TaiwanAffiliation: National Taiwan UniversityPhone: +1-412-465-0130Email: yvchen@csie.ntu.edu.tw
Workshop Co-chair
Paul CrookAddress: 1 Hacker Way, Menlo Park, CA, USAAffiliation: FacebookPhone: +1-650-885-0094Email: pacrook@fb.com
Additional Information
DSTC 10 home: https://dstc10.dstc.community/homeDSTC 10 CFPs: https://dstc10.dstc.community/calls_1/call-for-workshop-papers

W17: Engineering Dependable and Secure Machine Learning Systems (EDSMLS 2022) (Half-Day)
Nowadays, machine learning solutions are widely deployed. Like other systems, ML systems must meet quality requirements. However, ML systems may be non-deterministic; they may re-use high-quality implementations of ML algorithms; and, the semantics of models they produce may be incomprehensible. Consequently, standard notions of software quality and reliability such as deterministic functional correctness, black box testing, code coverage, and traditional software debugging become practically irrelevant for ML systems. This calls for novel methods and new methodologies and tools to address quality and reliability challenges of ML systems.
In addition, broad deployment of ML software in networked systems inevitably exposes ML software to attacks. While classical security vulnerabilities are relevant, ML techniques have additional weaknesses, some already known (e.g., sensitivity to training data manipulation), and some yet to be discovered. Hence, there is a need for research and practical solutions to ML security problems.With these in mind, this workshop solicits original contributions addressing problems and solutions related to dependability, quality assurance and security of ML systems. The workshop combines several disciplines, including ML, software engineering (with emphasis on quality), security, and game theory. It further combines academia and industry in a quest for well-founded practical solutions.
Topics
Topics of interest include, but are not limited to:

Vulnerability, sensitivity and attacks against ML
Adversarial ML and adversary-based learning models
Strategy-proof ML algorithms
Case studies of successful and unsuccessful applications of ML techniques
Correctness of data abstraction, data trust
Choice of ML techniques to meet security and quality
Size of the training data, implied guaranties
Application of classical statistics to ML systems quality
Sensitivity to data distribution diversity and distribution drift
The effect of labeling costs on solution quality (semi-supervised learning)
Reliable transfer learning
Software engineering aspects of ML systems and quality implications
Testing of the quality of ML systems over time
Debugging of ML systems
Quality implication of ML algorithms on large-scale software systems

Format
One day, comprising keynote, paper presentations and panel sessions. Full papers are allocated 20m presentation and 10m discussion. Short papers – 10m presentation and 5m discussion.
Submissions
Full (8 pages) and short (4 pages, work in progress) papers, AAAI style. Submission at: https://easychair.org/my/conference?conf=edsmls2022. Authors of accepted papers will be invited to participate.
Organizing Committee
Onn Shehory, Bar Ilan University (onn.shehory@biu.ac.il), Eitan Farchi, IBM Research Haifa (farchi@il.ibm.com), Guy Barash, Western Digital (Guy.Barash@wdc.com)
Additional Information
Supplemental workshop site: https://sites.google.com/view/edsmls-2022/home

W18: Explainable Agency in Artificial Intelligence
As Artificial Intelligence (AI) begins to impact our everyday lives, industry, government, and society with tangible consequences, it becomes increasingly important for a user to understand the reasons and models underlying an AI-enabled system’s decisions and recommendations. Explainable Agency captures the idea that AI systems will need to be trusted by human agents and, as autonomous agents themselves “must be able to explain their decisions and the reasoning that produced their choices” (Langley et al., 2017). While most work on XAI has focused on opaque learned models, this workshop also highlights the need for interactive AI-enabled agents to explain their decisions and models.
This workshop aims to bring together researchers and practitioners working on different facets of these problems, from diverse backgrounds to share challenges, new directions, recent research results, and lessons from applications. We especially welcome research from fields including but not limited to AI, human-computer interaction, human-robot interaction, cognitive science, human factors, and philosophy.
Topics
With this in mind, we welcome relevant contributions on the following (and related) topic areas:

Explainable Agents
Explainable/Interpretable Machine Learning
Explainable Reinforcement Learning
Explainable Planning
Agent Policy Summarization
Human-AI Interaction
Human-Robot Interaction
Cognitive Theories
Philosophical Foundations
Interaction Design for XAI
XAI Evaluation
Fairness, Accountability and Transparency
XAI Domains and Benchmarks
Interactive Teaching Strategies and Explainability
Intelligent Tutoring
User Modeling

Submissions
The submissions must be in PDF format, written in English, and formatted according to the AAAI camera-ready style. All papers will be peer-reviewed, single-blinded (i.e., please include author names/affiliations/email addresses on your first page).
Submitted papers will be assessed based on their novelty, technical quality, potential impact, insightfulness, depth, clarity, and reproducibility. The following paper categories are welcome:

Novel Research Contribution describing original methods and/or results (6 pages plus references)
Surveys summarizing and organizing recent research results (up to 8 pages plus references)
Demonstrations detailing applications of research findings, and/or debating relevant challenges and issues in the field (4 pages plus references)

Submission site: https://sites.google.com/view/eaai-ws-2022/call
Organizing Committee
Silvia Tulli (Dept. Computer Science and Engineering, INESC-ID, IST Ulisboa, Lisbon, Portugal – currently at Sorbonne University, Paris, France – silvia.tulli@gaips.inesc-id.pt), Prashan Madumal (Science and Information Systems, University of Melbourne, Parkville, Australia – pmathugama@student.unimelb.edu.au), Mark T. Keane (School of Computer Science, University College Dublin, Dublin, Ireland – mark.keane@ucd.ie), David W. Aha (Navy Center for Applied Research in AI, Naval Research Laboratory, Washington, DC, USA – david.aha@nrl.navy.mil)
Program Committee
Adam Johns (Drexel University, Philadelphia, PA USA), Tathagata Chakraborti (IBM Research AI, Cambridge, MA USA), Kim Baraka (VU University Amsterdam, Netherlands), Isaac Lage (Harvard University, Cambridge, MA USA), David Martens (University of Antwerp, Belgium), Mohamed Chetouani (Sorbonne Université, Paris, France), Peter Flach (University of Bristol, United Kingdom), Kacper Sokol (University of Bristol, United Kingdom), Ofra Amir (Technion, Haifa, Israel), Dimitrios Letsios (King’s College London, London, United Kingdom)
Additional Information
Supplemental workshop site: https://sites.google.com/view/eaai-ws-2022/topic

W19: Graphs and More Complex Structures for Learning and Reasoning (GCLR)
The study of complex graphs is a highly interdisciplinary field that aims to study complex systems by using mathematical models, physical laws, inference and learning algorithms, etc. Complex systems are often characterized by several components that interact in multiple ways among each other. Such systems are better modeled by complex graph structures such as edge and vertex labeled graphs (e.g., knowledge graphs), attributed graphs, multilayer graphs, hypergraphs, temporal/dynamic graphs, etc. In this 2nd instance of GCLR (Graphs and more Complex structures for Learning and Reasoning) workshop, we will focus on various complex structures along with inference and learning algorithms for these structures. The current research in this area is focused on extending existing ML algorithms as well as network science measures to these complex structures. This workshop aims to bring researchers from these diverse but related fields together and embark on interesting discussions on new challenging applications that require complex system modeling and discovering ingenious reasoning methods. We have invited several distinguished speakers with their research interests spanning from the theoretical to experimental aspects of complex networks.
Topics
We invite submissions from participants who can contribute to the theory and applications of modeling complex graph structures such as hypergraphs, multilayer networks, multi-relational graphs, heterogeneous information networks, multi-modal graphs, signed networks, bipartite networks, temporal/dynamic graphs, etc. The topics of interest include, but are not limited to:

Constraint satisfaction and programming (CP), (inductive) logic programming (LP and ILP)
Learning with Multi-relational graphs (alignment, knowledge graph construction, completion, reasoning with knowledge graphs, etc.)
Learning with algebraic or combinatorial structure
Link analysis/prediction, node classification, graph classification, clustering for complex graph structures
Network representation learning
Theoretical analysis of graph algorithms or models
Optimization methods for graphs/manifolds
Probabilistic and graphical models for structured data
Social network analysis and measures
Unsupervised graph/manifold embedding methods

The papers will be presented in poster format and some will be selected for oral presentation. Through invited talks and presentations by the participants, this workshop will bring together current advances in Network Science as well as Machine Learning, and set the stage for continuing interdisciplinary research discussions.
Important Dates
Poster/short/position papers submission deadline: Nov 5, 2021Full paper submission deadline: Nov 5, 2021Paper notification: Dec 3, 2021
Format
This is a 1-day workshop involving talks by pioneer researchers from respective areas, poster presentations, and short talks of accepted papers.
Attendance
The eligibility criteria for attending the workshop will be registration in the conference/workshop as per AAAI norms. We expect 50-65 people in the workshop.
Submissions
We invite submissions to the AAAI-22 workshop on Graphs and more Complex structures for Learning and Reasoning to be held virtually on February 28 or March 1, 2022. We welcome the submissions in the following two formats:

Poster/short/position papers: We encourage participants to submit preliminary but interesting ideas that have not been published before as short papers. These submissions would benefit from additional exposure and discussion that can shape a better future publication. We also invite papers that have been published at other venues to spark discussions and foster new collaborations. Submissions may consist of up to 4 pages plus one additional page solely for references.
Full papers: Submissions must represent original material that has not appeared elsewhere for publication and that is not under review for another refereed publication. Submissions may consist of up to 7 pages of technical content plus up to two additional pages solely for references.

The submissions should adhere to the AAAI paper guidelines.
Accepted submissions will have the option of being posted online on the workshop website. For authors who do not wish their papers to be posted online, please mention this in the workshop submission. The submissions need to be anonymized.
Submission Site: See the webpage https://sites.google.com/view/gclr2022/submissions; for detailed instructions and submission link.
Workshop Chair
Balaraman Ravindran (Indian Institute of Technology Madras, India – ravi@cse.iitm.ac.in)
Workshop Committee
Balaraman Ravindran (Indian Institute of Technology Madras, India Primary contact (ravi@cse.iitm.ac.in), Kristian Kersting (TU Darmstadt, Germany, kersting@cs.tu-darmstadt.de), Sriraam Natarajan (Univ of Texas Dallas, USA, Sriraam.Natarajan@utdallas.edu), Ginestra Bianconi (Queen Mary University of London, UK, ginestra.bianconi@gmail.com), Philip S. Chodrow (University of California, Los Angeles, USA, phil@math.ucla.edu) Tarun Kumar (Indian Institute of Technology Madras, India, tkumar@cse.iitm.ac.in), Deepak Maurya (Purdue University, India, maurya@cse.iitm.ac.in), Shreya Goyal (Indian Institute of Technology Madras, India, Goyal.3@iitj.ac.in)
Additional Information
Workshop URL: https://sites.google.com/view/gclr2022/

W20: Health Intelligence (W3PHIAI-22)
Public health authorities and researchers collect data from many sources and analyze these data together to estimate the incidence and prevalence of different health conditions, as well as related risk factors. Modern surveillance systems employ tools and techniques from artificial intelligence and machine learning to monitor direct and indirect signals and indicators of disease activities for early, automatic detection of emerging outbreaks and other health-relevant patterns. To provide proper alerts and timely response, public health officials and researchers systematically gather news and other reports about suspected disease outbreaks, bioterrorism, and other events of potential international public health concern, from a wide range of formal and informal sources. Given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. This is especially the case for non-traditional online resources such as social networks, blogs, news feed, twitter posts, and online communities with the sheer size and ever-increasing growth and change rate of their data. Web applications along with text processing programs are increasingly being used to harness online data and information to discover meaningful patterns identifying emerging health threats. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real-time data on epidemics.
Moreover, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork among patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All these changes require novel solutions, and the AI community is well-positioned to provide both theoretical- and application-based methods and frameworks. The goal of this workshop is to focus on creating and refining AI-based approaches that (1) process personalized data, (2) help patients (and families) participate in the care process, (3) improve patient participation, (4) help physicians utilize this participation to provide high quality and efficient personalized care, and (5) connect patients with information beyond that available within their care setting. The extraction, representation, and sharing of health data, patient preference elicitation, personalization of “generic” therapy plans, adaptation to care environments and available health expertise, and making medical information accessible to patients are some of the relevant problems in need of AI-based solutions.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. The scope of the workshop includes, but is not limited to, the following areas:

Knowledge Representation and Extraction
Integrated Health Information Systems
Patient Education
Patient-Focused Workflows
Shared Decision Making
Geographical Mapping and Visual Analytics for Health Data
Social Media Analytics
Epidemic Intelligence
Predictive Modeling and Decision Support
Semantic Web and Web Services
Biomedical Ontologies, Terminologies, and Standards
Bayesian Networks and Reasoning under Uncertainty
Temporal and Spatial Representation and Reasoning
Case-based Reasoning in Healthcare
Crowdsourcing and Collective Intelligence
Risk Assessment, Trust, Ethics, Privacy, and Security
Sentiment Analysis and Opinion Mining
Computational Behavioral/Cognitive Modeling
Health Intervention Design, Modeling and Evaluation
Online Health Education and E-learning
Mobile Web Interfaces and Applications
Applications in Epidemiology and Surveillance (e.g., Bioterrorism, Participatory Surveillance, Syndromic Surveillance, Population Screening)
Hybrid methods, combining data driven and predictive forward models
Response to Covid-19

We also invite participants to an interactive hack-a-thon. The theme of the hack-a-thon will be decided before submission is closed and will be focused around finding creative solutions to novel problems in health. Participants will be given access to publicly available datasets and will be asked to use tools from AI and ML to generate insight from the data. Examples of the datasets which may be considered are the DBTex Radiology Mammogram dataset and the Johns Hopkins COVID-19 case reports. The aim of the hack-a-thon is not only to foster innovation and potentially provide answers to outstanding research problems, but rather to engage the community and create new collaborations.
Submissions
We invite workshop participants to submit their original contributions following the AAAI format through EasyChair. Three categories of contributions are sought: full-research papers up to 8 pages; short papers up to 4 pages; and posters and demos up to 2 pages. Participants in the hack-a-thon will be asked to either register as a team or be randomly assigned to a team after registration. Their results will be submitted in either a short paper or poster format. Dataset(s) will be provided to hack-a-thon participants.
Organizing Committee
Martin Michalowski, PhD, FAMIA (Co-chair), University of Minnesota; Arash Shaban-Nejad, PhD, MPH (Co-chair), The University of Tennessee Health Science Center – Oak-Ridge National Lab (UTHSC-ORNL) Center for Biomedical Informatics; Simone Bianco, PhD (Co-chair), IBM Almaden Research Center; Szymon Wilk, PhD, Poznan University of Technology; David L. Buckeridge, MD, PhD, McGill University; John S. Brownstein, PhD, Boston Children’s Hospital
Additional Information
Workshop URL: http://w3phiai2022.w3phi.com/

W21: Human-Centric Self-Supervised Learning (HC-SSL)
Self-supervised learning (SSL) has shown great promise in problems involving natural language and vision modalities. Nonetheless, human-centric problems (such as activity recognition, pose estimation, affective computing, BCI, health analytics, and others) rely on information modalities with specific spatiotemporal properties. To adapt SSL frameworks to build effective human-centric deep learning solutions for human-centric data, a number of key challenges and opportunities need to be explored. The goal of the inaugural HC-SSL workshop is to highlight and facilitate discussions in this area and expose the attendees to emerging potentials of SSL for human-centric representation learning, and promote responsible AI within the context of SSL.
Topics
The workshop invites contribution to novel methods, innovations, applications, and broader implications of SSL for processing human-related data, including (but not limited to):

activity recognition
pose estimation
speech processing
affective computing
biomedical signal analysis/modeling (EEG, ECG, PPG, EMG, fMRI, IMU, medical/clinical data, etc.)

In addition to the above, papers that consider the following are also invited:

responsible development of human-centric SSL (e.g., safety, limitations, societal impacts, and unintended consequences)
ethical and legal implications of using SSL on human-centric data
implications of SSL on robustness and fairness
implications of SSL on privacy and security
interpretability and explainability of human-centric SSL frameworks

Manuscripts that fit only certain aspects of the workshop are also invited. For example:

if your work broadly addresses the use of unlabeled human-centric data with unsupervised or semi-supervised learning
if your work focuses on architectures and frameworks for SSL for sensory data beyond CV and NLP (but not necessarily human-centric data)

Format
The workshop will be a 1-day event with a number of invited talks by prominent researchers, a panel discussion, and a combination of oral and poster presentations of accepted papers.
Submissions

The AAAI template https://aaai.org/Conferences/AAAI-22/aaai22call/ should be used for all submissions.
Two types of submissions will be considered: full papers (6-8 pages + references), and short papers (2-4 pages + references).
Publication in HC-SSL does not prohibit authors from publishing their papers in archival venues such as NeurIPS/ICLR/ICML or IEEE/ACM Conferences and Journals. We also welcome submissions that are currently under consideration in such archival venues.
Submissions will go through a double-blind review process.

Submission site: https://cmt3.research.microsoft.com/AAAI2022HCSSL/Submission/Index
Workshop Chair
Ali Etemad (Queen’s University, ali.etemad@queensu.ca)
Organizing Committee
Ali Etemad (Queen’s University, ali.etemad@queensu.ca), Ahmad Beirami (Facebook AI, ahmad.beirami@gmail.com), Akane Sano (Rice University, akane.sano@rice.edu), Aaqib Saeed (Philips Research & University of Cambridge, aqibsaeed@protonmail.com), Alireza Sepas-Moghaddam (Socure, alireza.sepasm@socure.com), Mathilde Caron (Inria & Facebook AI, mathilde@fb.com), Pritam Sarkar (Queen’s University & Vector Institute, pritam.sarkar@queensu.ca), Huiyuan Yang (Rice University, hy48@rice.edu)
Additional Information
Supplemental website: https://hcssl.github.io/AAAI-22/

W22: Information-Theoretic Methods for Causal Inference and Discovery (ITCI’22)
Causal inference is one of the main areas of focus in artificial intelligence (AI) and machine learning (ML) communities. Causality has received significant interest in ML in recent years in part due to its utility for generalization and robustness. It is also central for tackling decision-making problems such as reinforcement learning, policy or experimental design. Information-theoretic approaches provide a novel set of tools that can expand the scope of classical approaches to causal inference and discovery problems in a variety of applications. Some examples of the success of information theory in causal inference are: the use of directed information, minimum entropy couplings and common entropy for bivariate causal discovery; the use of the information bottleneck principle with applications in the generalization of machine learning models; analyzing causal structures of deep neural networks with information theory; among others.
The goal of ITCI’22 is to bring together researchers working at the intersection of information theory, causal inference and machine learning in order to foster new collaborations and provide a venue to brainstorm new ideas, exemplify to the information theory community causal inference and discovery as an application area and highlight important technical challenges motivated by practical ML problems, draw the attention of the wider machine learning community to the problems at the intersection of causal inference and information theory, and demonstrate to the community the utility of information-theoretic tools to tackle causal ML problems.
Topics
Topics include but are not limited to:

Novel algorithmic solutions to causal inference or discovery problems using information-theoretic tools or assumptions.
Applications of causal inference and discovery in machine learning/deep learning motivated by information-theoretic approaches (e.g. information bottleneck principle)
Characterization of fundamental limits of causal quantities using information theory.
Identification of information-theoretic quantities relevant for causal inference and discovery.

Format
ITCI’22 will be a one-day workshop. The program consists of poster sessions for accepted papers, and invited and spotlight talks. Attendance is open to all; at least one author of each accepted paper must be virtually present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-21 author kit and anonymized. Papers will be peer-reviewed and selected for spotlight and/or poster presentation at the workshop.
Submission site: https://cmt3.research.microsoft.com/ITCI2022
Organizing Committee
Murat Kocaoglu, Chair (Purdue University, mkocaoglu@purdue.edu), Negar Kiyavash (EPFL, negar.kiyavash@epfl.ch), Todd Coleman (UCSD, tpcoleman@ucsd.edu)
Additional Information
Supplemental workshop site: https://sites.google.com/view/itci22

W23: Information Theory for Deep Learning (IT4DL)
Despite the great success of deep neural networks (DNNs) in many artificial intelligence (AI) tasks, they still suffer from limitations, such as poor generalization behavior for out-of-distribution (OOD) data, vulnerability to adversarial examples, and the “black-box” nature of DNNs. Furthermore, DNNs are data greedy in the context of supervised learning, and not well developed for limited label learning, for instance for semi-supervised learning, self-supervised learning, or unsupervised learning.
Information theory has demonstrated great potential to solve the above challenges. In recent years, various information theoretic principles have also been applied to different deep learning related AI applications in fruitful and unorthodox ways. Notable examples include the information bottleneck (IB) approach on the explanation of the generalization behavior of DNNs and the information maximization principle in visual representation learning.
With the rapid development of advanced techniques on the intersection between information theory and machine learning, such as neural network-based or matrix-based mutual information estimator, tighter generalization bounds by information theory, deep generative models and causal representation learning, information theoretic methods can provide new perspectives and methods to deep learning on the central issues of generalization, robustness, explainability, and offer new solutions to different deep learning related AI applications.This workshop aims to bring together both academic researchers and industrial practitioners to share visions on the intersection between information theory and deep learning, and their practical usages in different AI applications.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Information theoretic quantities (entropy, mutual information, divergence) estimation
Information theoretic methods for out-of-domain generalization and relevant problems (such as robust transfer learning and lifelong learning)
Information theoretic methods for learning from limited labelled data, such as few-shot learning, zero-shot learning, self-supervised learning, and unsupervised learning
Information theoretic methods for the robustness of DNNs in AI systems
The explanation of deep learning models (in AI systems) with information-theoretic methods
Information theoretic methods in different AI applications (e.g., NLP, healthcare, robotics, finance)

Format
This workshop will be a one-day workshop, featuring invited speakers, poster presentations, and short oral presentations of selected accepted papers.
Submissions
We invite submissions of technical papers up to 7 pages excluding references and appendices. Extended abstract up to 2 pages are also welcome. The submissions must be in PDF format, written in English, and formatted according to the AAAI camera-ready style. All papers will be peer reviewed, single-blinded.
Submit to: Submissions should be made via EasyChair at https://easychair.org/conferences/?conf=it4dl
Organizing Committee
Jose C. Principe (University of Florida, principe@cnel.ufl.edu), Robert Jenssen (UiT – The Arctic University of Norway, robert.jenssen@uit.no), Badong Chen (Xi’an Jiaotong University, chenbd@mail.xjtu.edu.cn), Shujian Yu (UiT – The Arctic University of Norway, yusj9011@gmail.com)
Additional Information
Supplemental workshop site: https://www.it4dl.org/

W24: Interactive Machine Learning
Recent years have witnessed growing interest in human and AI systems with the increasing realisation that machines can indeed meet objectives specified — but the real question becomes have they been given the right objectives. Interactive Machine Learning (IML) is concerned with the development of algorithms for enabling machines to cooperate with human agents. A challenge is how to integrate people into the learning loop in a way that is transparent, efficient, and beneficial to the human-AI team as a whole, supporting different requirements and users with different levels of expertise.
Advances in IML promise to make AIs more accessible and controllable, more compatible with the values of their human partners and more trustworthy. Such advances would enrich the range of applicability of semi-autonomous systems to real-world tasks, most of which involve cooperation with one or more human partners. This workshop aims to bring together researchers from industry and academia and from different disciplines in AI and surrounding areas to explore challenges and innovations in IML.
Topics
Novel mechanisms for eliciting and consuming user feedback, recommender, structured and generative models, concept acquisition, data processing, optimization; HCI and visualization challenges; Analysis of human factors/cognition and user modelling; Design, testing and assessment of IML systems; Studies on risks of interaction mechanisms, e.g., information leakage and bias; Business use cases and applications.
Format
This one-day workshop will consist of: (1) an ice-breaking session, (2) paper presentations, (3) a poster session, and (4) an ideation brainstorming session. We have the following keynote speakers confirmed: Andreas Holzinger (Medical Univ. of Graz), Cynthia Rudin (Duke Univ.) and Simone Stumpf (Univ. of London).
Attendance
Attendance is open to all prior registration to the workshop/conference. At least one author of each accepted submission must register and present their paper at the workshop. Expected attendance is 40-50 people.
Submissions
Submissions should be formatted using the AAAI-2022 Author Kit. Long papers (up to 6 pages + references) and extended abstracts (2 pages + references) are welcome, including resubmissions of already accepted papers, work-in-progress, and position papers. The review process will be single blind.
Submit to: https://easychair.org/conferences/?conf=imlaaai22
Workshop Chair
Elizabeth DalyAddress: IBM Dublin Technology Campus, Dublin 15, IrelandEmail: elizabeth.daly@ie.ibm.com
Organizing Committee
Elizabeth Daly, IBM Research, Ireland (elizabeth.daly@ie.ibm.com), Öznur Alkan, IBM Research, Ireland (oalkan2@ie.ibm.com), Stefano Teso, University of Trento, Italy (stefano.teso@unitn.it), Wolfgang Stammer, TU Darmstadt, Germany (wolfgang.stammer@cs.tu-darmstadt.de)
Additional Information
Workshop URL: https://sites.google.com/view/aaai22-imlw

W25: Knowledge Discovery from Unstructured Data in Financial Services (Half-Day)
Knowledge discovery from various data sources has gained the attention of many practitioners in recent decades. Its capabilities have expanded from processing structured data (e.g. DB transactions) to unstructured data (e.g. text, images, and videos). In spite of substantial research focusing on discovery from news, web, and social media data, its applications to datasets in professional settings such as financial filings and government reports, still present huge challenges. In the financial services industry particularly, a large amount of financial analysts’ work requires knowledge discovery and extraction from different data sources, such as SEC filings and industry reports, etc., before they can conduct any analysis. This manual extraction process is usually inefficient, error-prone, and inconsistent. It is one of the key bottlenecks for financial services companies to improve their operating productivity. These challenges and issues call for robust artificial intelligence (AI) algorithms and systems to help. The automated processing of unstructured data to discover knowledge from complex financial documents requires a series of techniques such as linguistic processing, semantic analysis, and knowledge representation & reasoning. The design and implementation of these AI techniques to meet financial business operations require a joint effort between academia researchers and industry practitioners.
Topics

Representation learning, distributed representations learning and encoding in natural language processing for financial documents;
Synthetic or genuine financial datasets and benchmarking baseline models;
Transfer learning application on financial data, knowledge distillation as a method for compression of pre-trained models or adaptation to financial datasets;
Search and question answering systems designed for financial corpora;
Named-entity disambiguation, recognition, relationship discovery, ontology learning and extraction in financial documents;
Knowledge alignment and integration from heterogeneous data;
Using multi-modal data in knowledge discovery for financial applications;
AI assisted data tagging and labeling;
Data acquisition, augmentation, feature engineering, and analysis for investment and risk management;
Automatic data extraction from financial fillings and quality verification;
Event discovery from alternative data and impact on organization equity price;
AI systems for relationship extraction and risk assessment from legal documents;
Accounting for Black-Swan events in knowledge discovery methods

Although textual data is prevalent in a large amount of finance-related business problems, we also encourage submissions of studies or applications pertinent to finance using other types of unstructured data such as financial transactions, sensors, mobile devices, satellites, social media, etc.
Format
This half day workshop will focus on research into the use of AI techniques to extract knowledge from unstructured data in financial services. The program of the workshop will include invited talks, paper presentations and a panel discussion. We plan to invite 2-4 keynote speakers from prestigious universities and leading industrial companies. The workshop plans to invite about 50-75 participants.
Submissions
All submissions must be original contributions and will be peer reviewed, single-blinded. All the submissions must follow the AAAI-22 formatting guidelines, camera-ready style. We accept two types of submissions – full research paper no longer than 8 pages (including references) and short/poster paper with 2-4 pages.
Submission site: https://easychair.org/conferences/?conf=kdf22
Organizing Committee
Chair: Xiaomo Liu (J.P. Morgan Chase AI Research, xiaomo.liu@jpmchase.com)
Zhiqiang Ma (J.P. Morgan Chase AI Research), Armineh Nourbakhsh (J.P. Morgan Chase AI Research), Sameena Shah (J.P. Morgan Chase AI Research), Gerard de Melo (Hasso Plattner Institute), Le Song (Mohamed bin Zayed University of Artificial Intelligence)
Additional Information
Workshop URL: https://aaai-kdf.github.io/kdf2022/

W26: Learning Network Architecture during Training
A fundamental problem in the use of artificial neural networks is that the first step is to guess the network architecture. Fine tuning a neural network is very time consuming and far from optimal. Hyperparameters such as the number of layers, the number of nodes in each layer, the pattern of connectivity, and the presence and placement of elements such as memory cells, recurrent connections, and convolutional elements are all manually selected. If it turns out that the architecture is not appropriate for the task, the user must repeatedly adjust the architecture and retrain the network until an acceptable architecture has been obtained.
There is now a great deal of interest in finding better alternatives to this scheme. Options include pruning a trained network or training many networks automatically. In this workshop we would like to focus on a contrasting approach, to learn the architecture during training. This topic encompasses forms of Neural Architecture Search (NAS) in which the performance properties of each architecture, after some training, are used to guide the selection of the next architecture to be tried. This topic also encompasses techniques that augment or alter the network as the network is trained. An example of the latter is the Cascade Correlation algorithm, as well as others that incrementally build or modify a neural network during training, as needed for the problem at hand.
Main Objectives
Our previous workshop at AAAI-21 generated significant interest from the community. We hope to build upon that success.
Our goal is to build a stronger community of researchers exploring these methods, and to find synergies among these related approaches and alternatives. Eliminating the need to guess the right topology in advance of training is a prominent benefit of learning network architecture during training. Additional advantages are possible, including decreased computational resources to solve a problem, reduced time for the network to make predictions, reduced requirements for training set size, and avoiding “catastrophic forgetting”. We would especially like to highlight approaches that are qualitatively different from some popular but computationally intensive NAS methods.
As deep learning problems become increasingly complex, network sizes must increase and other architectural decisions become critical to success. The deep learning community must often confront serious time and hardware constraints from suboptimal architectural decisions. The growing popularity of NAS methods demonstrates the community’s hunger for better ways of choosing or evolving network architectures that are well-matched to the problem at hand.
Topics
Methods for learning network architecture during training, including Incrementally building neural networks during training, new performance benchmarks for the above. Novel approaches and works in progress are encouraged.
Format
Invited speakers, panels, poster sessions, and presentations.
It is anticipated that this will be an in-person workshop, subject to changing travel restrictions and health measures. We will also have a video component for remote participation.
Attendance
Attendance is open to all, subject to any room occupancy constraints. At least one author of each accepted submission must be present at the workshop.
Submissions
Please refer and submit through the Learning Network Architecture During Training workshop website, which has more detailed information.
Organizing Committee
Scott E. Fahlman, School of Computer Science, Carnegie Mellon University (sef@cs.cmu.edu), Edouard Oyallon, Sorbonne Université – LIP6 (Edouard.oyallon@lip6.fr), Dean Alderucci, School of Computer Science, Carnegie Mellon University, (dalderuc@cs.cmu.edu)

W27: Machine Learning for Operations Research (ML4OR) (Half-Day)
The AAAI Workshop on Machine Learning for Operations Research (ML4OR) builds on the momentum that has been directed over the past 5 years, in both the OR and ML communities, towards establishing modern ML methods as a “first-class citizen” at all levels of the OR toolkit. ML4OR will serve as an interdisciplinary forum for researchers in both fields to discuss technical issues at this interface and present ML approaches that apply to basic OR building blocks (e.g., integer programming solvers) or specific applications.
Topics
ML4OR will place particular emphasis on: (1) ML methodologies for enhancing traditional OR algorithms for integer programming, combinatorial optimization, stochastic programming, multi-objective optimization, location and routing problems, etc.; (2) Deep Learning (DL) approaches that can exploit large datasets, particularly Graph Neural Networks (GNNs) and Deep Reinforcement Learning (DRL); (3) End-to-end learning methodologies that mend the gap between ML model training and downstream optimization problems that use ML predictions as inputs; (4) Datasets and benchmark libraries that enable ML approaches for a particular OR application or challenging combinatorial problems.
Format
ML4OR is a one-day workshop consisting of a mix of events: multiple invited talks by recognized speakers from both OR and ML covering central theoretical, algorithmic, and practical challenges at this intersection; a number of technical sessions where researchers briefly present their accepted papers; a virtual poster session for accepted papers and abstracts; a panel discussion with speakers from academia and industry focusing on the state of the field and promising avenues for future research; an educational session on best practices for incorporating ML in advanced OR courses including open software and data, learning outcomes, etc.
While we are planning an in-person workshop to be held at AAAI-22, we aim to accommodate attendees who may not be able to travel to Vancouver by allowing participation via live virtual invited talks and virtual poster sessions.
Submissions
We invite researchers to submit either full-length research papers (8 pages) or extended abstracts (2 pages) describing novel contributions and preliminary results, respectively, to the topics above; a more extensive list of topics is available on the Workshop website. Submissions tackling new problems or more than one of the aforementioned topics simultaneously are encouraged. Submissions will be collected via the OpenReview platform; URL forthcoming on the Workshop website.
Organizing Committee
Ferdinando Fioretto (Syracuse University), Emma Frejinger (Université de Montréal), Elias B. Khalil (University of Toronto), Pashootan Vaezipoor (University of Toronto)
Additional Information
Workshop URL: https://ml4or.github.io/

W28: Optimal Transport and Structured Data Modeling (OTSDM)
The last few years have seen the rapid development of mathematical methods for modeling structured data coming from biology, chemistry, network science, natural language processing, and computer vision applications. Recently developed tools and cutting-edge methodologies coming from the theory of optimal transport have proved to be particularly successful for these tasks. A striking feature of much of this recent work is the application of new theoretical and computational techniques for comparing probability distributions defined on spaces with complex structures, such as graphs, Riemannian manifolds and more general metric spaces.
This workshop aims to provide a premier interdisciplinary forum for researchers in different communities to discuss the most recent trends, innovations, applications, and challenges of optimal transport and structured data modeling.
Topics
The goal of this workshop is to bring together the optimal transport, artificial intelligence, and structured data modeling, gathering insights from each of these fields to facilitate collaboration and interactions. We invite thought-provoking submissions and talks on a range of topics in these fields. The topics of interest include but are not limited to:
Theoretical and Computational Optimal Transport:

Optimal transport theory, including statistical and geometric aspects;
Gromov-Wasserstein distance and its variants;
Geometry of spaces of structured data;
Computational optimal transport.

Optimal Transport-Driven Machine Learning:

Bayesian inference for/with optimal transport;
Gromovization of machine learning methods;
Optimal transport-based generative modeling
Optimal transport-based machine learning paradigms;
Trustworthy machine learning from the perspective of optimal transport.

Optimal Transport-Based Structured Data Modeling:

Optimal transport-based analysis of structured data, such as networks, meshes, sequences, and so on;
The applications of optimal transport in molecule analysis, network analysis, natural language processing, computer vision, and bioinformatics.

Format
The full-day workshop will start with two long talks and one short talk in the morning. The post-lunch session will feature one long talk, two short talks, and a poster session. We will end the workshop with a panel discussion by invited speakers from different fields to enlist future directions.
Invited Speakers
Long talks (50 mins):Gabriel Peyré, (Mathematics, CNRS Senior Researcher);Yusu Wang, (Mathematics, Professor in CSE, UCSD);Caroline Uhler, (Statistics and CS, Associate Professor in EECS and IDSS, MIT);
Short talks (25mins): Titouan Vayer, (Mathematics, Postdoctoral Researcher at ENS Lyon);Tam Le, (Computer Science, Research Scientist at RIKEN);Dixin Luo, (Computer Science, Assistant Professor in CS, Beijing Institute of Technology).
Submissions
We invite the submission of papers with 4-6 pages. References will not count towards the page limit. Papers must be in PDF format, in English, and formatted according to the AAAI template. Submissions will be peer-reviewed, single-blinded, and assessed based on their novelty, technical quality, significance, clarity, and relevance regarding the workshop topics. Submissions introducing interesting experimental phenomena and open problems of optimal transport and structured data modeling are welcome as well. Submissions that are already accepted or under review for another conference or already accepted for a journal are not accepted. This policy also applies to papers that overlap substantially in technical content with papers previously published, accepted, or under review.
The submission website is https://cmt3.research.microsoft.com/OTSDM2022.
Key Dates
All time are 23:59, AoE (Anywhere on Earth)

Submission deadline: November 12, 2021
Notification date:/strong> December 3, 2021
Workshop day:/strong> February 28 or March 1, 2022

Organizing Committee
Hongteng Xu (Renmin University of China, hongtengxu@ruc.edu.cn, main contact), Julie Delon (Université de Paris, julie.delon@u-paris.fr), Facundo Mémoli (Ohio State University, facundo.memoli@gmail.com), Tom Needham (Florida State University, tneedham@fsu.edu)
Additional Information
Workshop site: https://ot-sdm.github.io

W29: Practical Deep Learning in the Wild (PracticalDL2022)
Deep learning has achieved significant success for artificial intelligence (AI) in multiple fields. However, research in the AI field also shows that their performance in the wild is far from practical due to the lack of model efficiency and robustness towards open-world data and scenarios. Regarding efficiency, it is impractical to train a neural network containing billions of parameters and then deploy it to an edge device in practice. And considering robustness, input data with noises frequently occur in open-world scenarios, which presents critical challenges for the building of robust AI systems in practice. Some existing research also presents that there is a trade-off between the robustness and accuracy of deep learning models.
These complex demands have brought profound implications and an explosion of interest for research into the topic of this workshop, namely building practical AI with efficient and robust deep learning models. As far as we know, we are the first workshop to focus on practical deep learning in the wild for AI, which is of great significance.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Network compression
Adversarial attacking deep learning systems
Neural architecture search (NAS)
Robust architectures against adversarial attacks
Hardware implementation and on-device deployment
Benchmark for evaluating model robustness
On-device learning
Few-shot detection
New methodologies and architectures for efficient and robust deep learning

Important Dates

November 14, 2021 – Submission Deadline
December 3, 2021 – Acceptance Notification
February 28, 2022 – Workshop Date

Format
The workshop will be a 1.5-day meeting.
The workshop will include several technical sessions, a virtual poster session where presenters can discuss their work, to further foster collaborations, multiple invited speakers covering crucial aspects for the practical deep learning in the wild, especially the efficient and robust deep learning, some tutorial talks, the challenge for efficient deep learning and solution presentations, and will conclude with a panel discussion.
Attendance
Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-22 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentations at the workshop.
The submission website is https://cmt3.research.microsoft.com/PracticalDL2022.
Invited Speakers
Alan Yuille (Professor, Johns Hopkins University); Hao Su (Assistant Professor, UC San Diego); Rongrong Ji (Professor, Xiamen University); Xianglong Liu (Professor, Beihang University); Jishen Zhao (Associate Professor, UC San Diego); Tom Goldstein (Associate Professor, University of Maryland); Cihang Xie (Assistant Professor, UC Santa Cruz); Yisen Wang (Assistant Professor, Peking University); Bohan Zhuang (Assistant Professor, Monash University)
Workshop Chair
Haotong Qin (Beihang University), Yingwei Li (Johns Hopkins University), Ruihao Gong (SenseTime Research), Xinyun Chen (UC Berkeley), Aishan Liu (Beihang University), Xin Dong (Harvard University)
Workshop Committee (Incomplete list)
Jindong Guo (University of Munich), Yuhang Li (Yale University), Yiming Li (Tsinghua University), Yifu Ding (Beihang University), Mingyuan Zhang (Nanyang Technological University), Jiakai Wang (Beihang University), Jinyang Guo (University of Sydney), Renshuai Tao (Beihang University)
Additional Information
Workshop site: https://practical-dl.github.io/

W30: Privacy-Preserving Artificial Intelligence
The availability of massive amounts of data, coupled with high-performance cloud computing platforms, has driven significant progress in artificial intelligence and, in particular, machine learning and optimization. It has profoundly impacted several areas, including computer vision, natural language processing, and transportation. However, the use of rich data sets also raises significant privacy concerns: They often reveal personal sensitive information that can be exploited, without the knowledge and/or consent of the involved individuals, for various purposes including monitoring, discrimination, and illegal activities.
The third AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-22) builds on the success of previous years PPAI-20 and PPAI-21 to provide a platform for researchers, AI practitioners, and policymakers to discuss technical and societal issues and present solutions related to privacy in AI applications. The workshop will focus on both the theoretical and practical challenges related to the design of privacy-preserving AI systems and algorithms and will have strong multidisciplinary components, including soliciting contributions about policy, legal issues, and societal impact of privacy in AI.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Applications of privacy-preserving AI systems
Attacks on data privacy
Differential privacy: theory and applications
Distributed privacy-preserving algorithms
Human rights and privacy
Privacy and Fairness
Privacy policies and legal issues
Privacy preserving optimization and machine learning
Privacy preserving test cases and benchmarks
Surveillance and societal issues

Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and data sets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples.
Format
The workshop will be a one-day meeting and will include a number of technical sessions, a virtual poster session where presenters can discuss their work, with the aim of further fostering collaborations, multiple invited speakers covering crucial challenges for the field of privacy-preserving AI applications, including policy and societal impacts, a tutorial talk, and will conclude with a panel discussion. Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-22 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentation at the workshop.
The submission website is https://cmt3.research.microsoft.com/PPAI2022.
Organizing Committee
Ferdinando Fioretto (Syracuse University), Aleksandra Korolova (University of Southern California), Pascal Van Hentenryck (Georgia Institute of Technology)
Additional Information
Supplemental Workshop site: https://aaai-ppai22.github.io/

W31: Reinforcement Learning for Education: Opportunities and Challenges
RL4ED is intended to facilitate tighter connections between researchers and practitioners interested in the broad areas of reinforcement learning (RL) and education (ED). The workshop will focus on two thrusts: 1) Exploring how we can leverage recent advances in RL methods to improve state-of-the-art technology for ED; 2) Identifying unique challenges in ED that can help nurture technical innovations and next breakthroughs in RL.
Topics
Topics of interest include but are not limited to: (1) Survey papers summarizing recent advances in RL with applicability to ED; (2) Developing toolkits and datasets for applying RL methods to ED; (3) Using RL for online evaluation and A/B testing of different intervention strategies in ED; (4) Novel applications of RL for ED problem settings; (5) Using pedagogical theories to narrow the policy space of RL methods; (6) Using RL methodology as a computational model of students in open-ended domains; (7) Developing novel offline RL methods that can efficiently leverage historical student data; (8) Combining statistical power of RL with symbolic reasoning to ensure the robustness for ED.
Format
This 1-day workshop will include a mixture of invited speakers, panels (including discussion with the audience), and presentations from authors of accepted submissions.
Attendance
We welcome attendance from individuals who do not have something they’d like to submit but who are interested in RL4ED research. If you are interested, please send a short email to rl4edorg@gmail.com and we can add you to the invitee list.
Submissions
We welcome two types of submissions:



Research track papers reporting the results of ongoing or new research, which have not been published before. In particular, we encourage papers covering late-breaking results and work-in-progress research.
Encore track papers that have been recently published, or accepted for publication in a conference or journal.



Submissions are due by 12 November 2021. Please refer to https://rl4ed.org/aaai2022/index.html for additional information.
Submission URL: https://easychair.org/conferences/?conf=rl4edaaai22.
Workshop Chairs





Neil T. Heffernan, Worcester Polytechnic Institute (Worcester, MA, USA)Email: nth@wpi.edu, Webpage: https://www.neilheffernan.net/
Andrew S. Lan, University of Massachusetts Amherst (Amherst, MA, USA)Email: andrewlan@cs.umass.edu, Webpage: https://people.umass.edu/~andrewlan/
Anna N. Rafferty, Carleton College (Northfield, MN, USA)Email: arafferty@carleton.edu, Webpage: https://sites.google.com/site/annanrafferty/
Adish Singla, Max Planck Institute for Software Systems (Saarbrucken, Germany)Email: adishs@mpi-sws.org, Webpage: https://machineteaching.mpi-sws.org/adishsingla.html





Additional Information
Supplemental Workshop site: https://rl4ed.org/aaai2022/index.html

W32: Reinforcement Learning in Games (RLG)
Games provide an abstract and formal model of environments in which multiple agents interact: each player has a well-defined goal and rules to describe the effects of interactions among the players. The first achievements in playing these games at super-human level were attained with methods that relied on and exploited domain expertise that was designed manually (e.g. chess, checkers). In recent years, we have seen examples of general approaches that learn to play these games via self-play reinforcement learning (RL), as first demonstrated in Backgammon. While progress has been impressive, we believe we have just scratched the surface of what is capable, and much work remains to be done in order to truly understand the algorithms and learning processes within these environments.
Topics
The main objective of the workshop is to bring researchers together to discuss ideas, preliminary results, and ongoing research in the field of reinforcement in games.
We invite participants to submit papers by the 12th of November, based on but not limited to, the following topics: RL in various formalisms: one-shot games, turn-based, and Markov games, partially-observable games, continuous games, cooperative games; deep RL in games; combining search and RL in games; inverse RL in games; foundations, theory, and game-theoretic algorithms for RL; opponent modeling; analyses of learning dynamics in games; evolutionary methods for RL in games; RL in games without the rules; search and planning; and online learning in games.
Format
RLG is a full-day workshop. It will start with a 60-minute mini-tutorial covering the basics of RL in games, and will include 2-4 invited talks by prominent contributors to the field, paper presentations, a poster session, and will close with a discussion panel. Attendance is expected to be 150-200 participants (estimated), including organizers and speakers.
Submissions
Papers must be between 4-8 pages in the AAAI submission format, with the eighth page containing only references. Papers will be submitted electronically using Easychair. Accepted papers will not be archived, and we explicitly allow papers that are concurrently submitted to, currently under review at, or recently accepted in other conferences / venues.
Submission instructions will be available at the workshop web page.
Workshop Chair
Viliam Lisy (viliam.lisy@fel.cvut.cz)
Organizing Committee
Viliam Lisy (Czech Technical University in Prague, viliam.lisy@fel.cvut.cz), Noam Brown (Facebook AI Research, noambrown@fb.com), Martin Schmid (DeepMind, mschmid@google.com)
Additional Information
Supplemental Workshop site: http://aaai-rlg.mlanctot.info/

W33: Robust Artificial Intelligence System Assurance (RAISA) (Half-Day)
The workshop on Robust Artificial Intelligence System Assurance (RAISA) will focus on research, development and application of robust artificial intelligence (AI) and machine learning (ML) systems. Rather than studying robustness with respect to particular ML algorithms, our approach will be to explore robustness assurance at the system architecture level, during both development and deployment, and within the human-machine teaming context. While the research community is converging on robust solutions for individual AI models in specific scenarios, the problem of evaluating and assuring the robustness of an AI system across its entire life cycle is much more complex. Moreover, the operational context in which AI systems are deployed necessitates consideration of robustness and its relation to principles of fairness, privacy, and explainability.
RAISA’s systems-level perspective will be emphasized via three main thrusts:





AI System Robustness: participants will consider techniques for detecting and mitigating vulnerabilities at each of the processing stages of an AI system, including: the input stage of sensing and measurement, the data conditioning stage, during training and application of machine learning algorithms, the human-machine teaming stage, and during operational use.
The robust development and assured deployment of AI systems: Participants will discuss how to leverage and update common software development paradigms, e.g., DevSecOps, to incorporate relevant aspects of system-level AI assurance.
The impact of robustness assurance on other AI ethics principles: RAISA will also explore aspects related to ethical AI that overlap and interact with robustness concerns, including security, fairness, privacy, and explainability.





Topics
AI threat modeling, AI system robustness, explainable AI, system lifecycle attacks, system verification and validation, robustness benchmarks and standards, robustness to black-box and white-box adversarial attacks, defenses against training, operational and inversion attacks, AI system confidentiality, integrity, and availability, AI system fairness and bias
Format
Half day event featuring a panel, invited and keynote speakers and presentations selected through a CFP.
Attendance
25-50 attendees including invited speakers and accepted papers
Submissions
PDF suitable for ArXiv repository (4 to 8 pages). Previously published work (or under-review) is acceptable.
Submission link: https://easychair.org/cfp/raisa-2022
Workshop Chair
William Streilein, MIT Lincoln Laboratory, 244 Wood St., Lexington, MA, 02420, (781) 981-7200, wws@ll.mit.edu
Organizing Committee
Olivia Brown (MIT Lincoln Laboratory, Olivia.Brown@ll.mit.edu), Rajmonda Caceres (MIT Lincoln Laboratory, Rajmonda.Caceres@ll.mit.edu), Tina Eliassi-Rad (Northeastern University, teliassirad@northeastern.edu), David Martinez (MIT Lincoln Laboratory, dmartinez@ll.mit.edu), Sanjeev Mohindra (MIT Lincoln Laboratory, smohindra@ll.mit.edu), Elham Tabassi (National Institute of Standards and Technology, elham.tabassi@nist.gov)
Additional Information
Workshop URL: https://sites.google.com/view/raisa-2022/

W34: Scientific Document Understanding (SDU) (Half-Day)
Scientific documents such as research papers, patents, books, or technical reports are one of the most valuable resources of human knowledge. At the AAAI-22 Workshop on Scientific Document Understanding (SDU@AAAI-22), we aim to gather insights into the recent advances and remaining challenges on scientific document understanding. Researchers from related fields are invited to submit papers on the recent advances, resources, tools, and upcoming challenges for SDU. In addition to that, we propose a shared task on one of the challenging SDU tasks, i.e., acronym extraction and disambiguation in multiple languages text.
Topics
Topics of interest include but are not limited to:





Information extraction and information retrieval for scientific documents;
Question answering and question generation for scholarly documents;
Word sense disambiguation, acronym identification and expansion, and definition extraction; Document summarization, text mining, document topic classification, and machine reading comprehension for scientific documents;
Graph analysis applications including knowledge graph construction and representation, graph reasoning and query knowledge graphs;
Graph analysis applications including knowledge graph construction and representation, graph reasoning and query knowledge graphs;
Biomedical image processing, scientific image plagiarism detection, and data visualization; Code/Pseudo-code generation from text and im-age/diagram captioning, New language understanding resources such as new syn-tactic/semantic parsers, language models or techniques to encode scholarly text;
Survey or analysis papers on scientific document under-standing and new tasks and challenges related to each scientific domain;
Factuality, data verification, and anti-science detection





Shared Task
Acronyms, i.e., short forms of long phrases, are common in scientific writing. To push forward the research on acronym understanding in scientific text, we propose two shared tasks on acronym extraction (i.e., recognizing acronyms and phrases in text) and disambiguation (i.e., finding the correct expansion for an ambiguous acronym). Participants are welcomed to submit their system reports to be presented in the workshop.
Format
SDU will be a one-day workshop. The full-day workshop will start with an opening remark followed by long research paper presentations in the morning. The post-launch session includes the invited talks, shared task winners’ presentations, and a panel discussion on the resources, findings, and upcoming challenges. SDU will also host a session for presenting the short research papers and the system reports of the shared tasks.
Attendance
SDU is expected to host 50-60 attendees. Invited speakers, committee members, authors of the research paper, and the participants of the shared task are invited to attend.
Submissions
Submissions should follow the AAAI 2022 formatting guidelines and the AAAI 2022 standards for double-blind review including anonymous submission. SDU accepts both long (8 pages including references) and short (4 pages including references) papers. Accepted papers will be published in the workshop proceedings. System reports should also follow the AAAI 2022 formatting guidelines and have 4-6 pages including references. System reports will be presented during poster sessions.
Please submit the papers and system reports to EasyChair
Organizing Committee
Thien Huu Nguyen (University of Oregon, thien@cs.uoregon.edu), Walter Chang (Adobe Research, wachang@adobe.com), Amir Pouran Ben Veyseh (University of Oregon, apouranb@uoregon.edu), Viet Dac Lai (University of Oregon, viet@uoregon.edu), Franck Dernoncourt (Adobe Research, franck.dernoncourt@adobe.com)
Additional Information
Workshop URL: https://sites.google.com/view/sdu-aaai22/home

W35: Self-Supervised Learning for Audio and Speech Processing
Babies learn their first language through listening, talking, and interacting with adults. Can AI achieve the same goal without much low-level supervision? Inspired by the question, there is a trend in the machine learning community to adopt self-supervised approaches to pre-train deep networks. Self-supervised learning utilizes proxy supervised learning tasks, for example, distinguishing parts of the input signal from distractors, or generating masked input segments conditioned on the unmasked ones, to obtain training data from unlabeled corpora. These approaches make it possible to use a tremendous amount of unlabeled data available on the web to train large networks and solve complicated tasks. BERT and GPT in NLP and SimCLR and BYOL in CV are famous examples in this direction. Recently self-supervised approaches for speech/audio processing are also gaining attention. There were two workshops on similar topics hosted at ICML 2020 and NeurIPS 2020, and both workshops observed positive feedback and overwhelming participation. We are excited to continue promoting innovation in self-supervision for the speech/audio processing fields and inspiring the fields to contribute to the general machine learning community. The goal of this workshop is to connect researchers in self-supervision inside and outside the speech and audio fields to discuss cutting-edge technology, inspire ideas and collaborations, and drive the research frontier.
Topics

The workshop welcomes the submission of work on, but not limited to, the following research directions.
New self-supervised proxy tasks or new approaches using self-supervised models in speech and audio processing.
Theoretical or empirical studies focusing on understanding why self-supervision methods work for speech and audio.
Exploring the limits of self-supervised learning approaches for speech and audio processing, for example, adverse environment conditions, multiple languages, or generalization across downstream tasks.
Comparison or integration of self-supervised learning methods and other semi-supervised and transfer learning methods in speech and audio processing tasks.
Self-supervised learning approaches involving the interaction of speech/audio and other modalities.

The workshop also welcomes participants of SUPERB and Zero Speech challenge to submit their results.

SUPERB is a benchmarking platform that allows the community to train, evaluate, and compare the speech representations on diverse downstream speech processing tasks. The challenge requires participants to build competitive models for diverse downstream tasks with limited labeled data and trainable parameters, by reusing self-supervised pre-trained networks.
Zero Speech challenge is to build language models only based on audio or audio-visual information, without using any textual input. The trained models are intended to assign scores to novel utterances, assessing whether they are possible or likely utterances in the training language.

Format
This one-day workshop will bring concentrated discussions on self-supervision for the field of speech/audio processing via keynote speech, invited talks, contributed talks and posters based on community-submitted high-quality papers, and the result representation of SUPERB and Zero Speech challenge.
Attendance
Attendance is open to all; at least one author of each accepted submission must be physically/virtually present at the workshop. We expect ~60 attendees.
Submissions
Papers must be between 4-8 pages with the AAAI submission format submitted to the track of regular paper, SUPERB or Zero Speech result paper. Each paper will be reviewed by three reviewers in double-blind. Accepted papers will not be archived but will be hosted on the workshop website. We allow papers that are concurrently submitted to or currently under review at other conferences or venues. We encourage authors to contact the organizers to discuss possible overlap.
Submission Site: https://cmt3.research.microsoft.com/SAS2022
Organizing Committee
Abdelrahman Mohamed (Facebook, abdo@fb.com), Hung-yi Lee (NTU, hungyilee@ntu.edu.tw), Shinji Watanabe (CMU, shinjiw@ieee.org), Tara Sainath (Google, tsainath@google.com), Karen Livescu (TTIC, klivescu@ttic.edu), Shang-Wen Li (Facebook, shangwel@fb.com), Ewan Dunbar (University of Toronto, ewan.dunbar@utoronto.ca) Emmanuel Dupoux (EHESS/Facebook, dpx@fb.com)
Additional Information
Workshop URL: https://aaai-sas-2022.github.io/

W36: Trustable, Verifiable and Auditable Federated Learning
Federated learning (FL) is one promising machine learning approach that trains a collective machine learning model using sharing data owned by various parties. It leverages many emerging privacy-preserving technologies (SMC, Homomorphic Encryption, differential privacy, etc.) to protect data owner privacy in FL. It has gained popularity in some domains such as image classification, speech recognition, smart city, and healthcare. However, FL also faces multiple challenges that may potentially limit its applications in real-world use scenarios. For example, FL is still at the risk of various kinds of attacks that may result in leakage of individual data source privacy or degraded joint model accuracy. In other words, many existing FL solutions are still exposed to various security and privacy threats. This workshop aims to bring together FL researchers and practitioners to address the additional security and privacy threats and challenges in FL to make its mass adoption and widespread acceptance in the community. The discussion in the workshop can lead to implementing FL solutions that are more accurate, robust and interpretable, and gain the trust of the FL participants.
Topics
Topics of interest include, but are not limited to:

Interpret Federated Learning
Trade-Off between Privacy-Preserving and Explainable Federated Learning Federated Learning Multi-Party Computation
Federated Learning Homomorphic Encryption
Federated Learning Differential Privacy
Federated Transfer Learning
Federated Learning Personalization Techniques
Federated Learning Attacks and Defenses
Federated Learning Blockchain Network
Federated Learning Secure Aggregation
Federated Learning Fairness and Accuracy
Federated Learning with Non-IID Data
Federated Learning Incentive Mechanism
Federated Learning Meets Mean-Field Game Theory
Federated Learning-based Corporate Social Responsibility
Social Responsible Federated Learning
Decentralized Federated Learning
Vertical Federated Learning

Format
The workshop is a full day. Each accepted paper presentation will be allocated between 15 and 20 minutes. The invited speakers, who are well-recognized experts of the field, will give a 30 minute talk.
Attendance
Typically, we receive around 40~60 submissions to each previous workshop. Out of these, around 20~30 papers are accepted. For previous workshops held physically, each workshop attracts around 150~300 participants.
Submissions
We invite a long research paper (8 pages) and a demo paper (4 pages) (including references). The submitted papers written in English must be in PDF format according to the AAAI camera ready style.
The submission website is https://easychair.org/conferences/?conf=fl-aaai-22.
Organizing Committee
Qiang Yang, Hong Kong University of Science and Technology/ WeBank, China, (qyang@cse.ust.hk ), Sin G. Teo, Institute for Infocomm Research, Singapore (teosg@i2r.a-star.edu.sg), Han Yu, Nanyang Technological University, Singapore (han.yu@ntu.edu.sg), Lixin Fan, WeBank, China (lixinfan@webank.com), Chao Jin, Institute for Infocomm Research, Singapore (jin_chao@i2r.a-star.edu.sg), Le Zhang, University of Electronic Science and Technology of China (zhangleuestc@gmail.com), Yang Liu, Tsinghua University, China (liuy03@air.tsinghua.edu.cn), Zengxiang Li, Digital Research Institute, ENN Group, China (lizengxiang@enn.cn)
Additional Information
Workshop site: http://federated-learning.org/fl-aaai-2022/

W37: Trustworthy AI for Healthcare
In this workshop, we aim to address the trustworthy issues of clinical AI solutions. We aim to bring together researchers in AI, healthcare, medicine, NLP, social science, etc. and facilitate discussions and collaborations in developing trustworthy AI methods that are reliable and more acceptable to physicians. Previous healthcare-related workshops focus on how to develop AI methods to improve the accuracy and efficiency of clinical decision-making, including diagnosis, treatment, triage. The trustworthy issues of clinical AI methods were not discussed. In our workshop, we specifically focus on the trustworthy issues in AI for healthcare, aiming to make clinical AI methods more reliable in real clinical settings and be willingly used by physicians.
Topics

interpretable AI methods for healthcare.
robustness of clinical AI methods.
medical knowledge grounded AI.
physician-in-the-loop AI.
security and privacy in clinical AI.
fairness in AI for healthcare.
ethics in AI for healthcare.
robust and interpretable natural language processing for healthcare.
methods for robust weak supervision.

Format
The workshop will be a one-day workshop, featuring speakers, panelists, and poster presenters from machine learning, biomedical informatics, natural language processing, statistics, behavior science.
Attendance
At AAAI 2021, we successfully organized this workshop (https://taih20.github.io/). We received 38 paper submissions and accepted 23 of them. The workshop attracted about 100 attendees.
Submissions
We invite submissions of full papers, as well as works-in-progress, position papers, and papers describing open problems and challenges. While original contributions are preferred, we also invite submissions of high-quality work that has recently been published in other venues or is concurrently submitted. Papers should be up to 4 pages in length (excluding references) formatted using the AAAI template. All the submissions should be anonymous. The accepted papers are allowed to be submitted to other conference venues. This workshop has no archival proceedings.
The submission website is https://cmt3.research.microsoft.com/TAIH2022.
Organizing Committee

Pengtao Xie (main contact), Assistant Professor, University of California, San Diego, pengtaoxie2008@gmail.com Engineer Ln, San Diego, CA 92161 (Tel)4123206230
Marinka Zitnik, Assistant Professor, Harvard University, marinka@hms.harvard.edu 10 Shattuck Street, Boston, MA 02115 (Tel)6503086763
Byron Wallace, Assistant Professor, Northeastern University, byron@ccs.neu.edu 177 Huntington Ave, Boston, MA 02115 (Tel)4135120352
Eric P. Xing, Professor, Carnegie Mellon University, epxing@cs.cmu.edu 5000 Forbes Ave, Pittsburgh, PA 15213 (Tel)4122682559
Ramtin Hosseini, PhD Student, University of California, San Diego, rhossein@eng.ucsd.edu (Tel) 3104293825

Additional Information
Workshop site: https://taih21.github.io/

W38: Trustworthy Autonomous Systems Engineering (TRASE-22)
Advances in AI technology, particularly perception and planning, have enabled unprecedented advances in autonomy, with autonomous systems playing an increasingly important role in day-to-day lives, with applications including IoT, drones, and autonomous vehicles. In nearly all applications, reliability, safety, and security of such systems is a critical consideration. For example, failures in IoT can result in infrastructure disruptions, and failures in autonomous cars can lead to congestion and crashes. While there have been extensive independent research threads on the subject of safety and reliability of specific sub-problems in autonomy, such as the problem of robust control, as well as recent considerations of robust AI-based perception, there has been considerably less research on investigating robustness and trust in end-to-end autonomy, where AI-based perception is integrated with planning and control in an open loop. This workshop on Trustworthy Autonomous Systems Engineering (TRASE) offers an opportunity to highlight state of the art research in trustworthy autonomous systems, as well as provide a vision for future foundational and applied advances in this critical area at the intersection of AI and Cyber-Physical Systems.
The mission of the TRASE workshop is to bring together researchers from multiple engineering disciplines, including Computer Science, and Computer, Mechanical, Electrical, and Systems Engineering, who focus their energies in understanding both specific TRASE subproblems, such as perception, planning, and control, as well as robust and reliable end-to-end integration of autonomy.
Topics
We are interested in a broad range of topics, both foundational and applied. Topics of interest include, but are not limited to:

Security and reliability of AI
Robust visual perception
Robust control
Reliability in real-time systems
Robust dynamical systems
Robust planning
Ethics and fairness in autonomous systems
Robust multiagent systems
Robust robotic design, particularly of autonomous drones and/or vehicles

Important Dates

Submissions due: November 12
Acceptance decisions: December 3
Workshop dates: February 28/March 1

Submissions
Paper submissions will be in two formats: full paper (8 pages) and position paper (4 pages):
Research papers (8 pages in length for main content + 2 pages for references in AAAI format): we are soliciting research papers, both relatively mature, as well as early stage, on both the foundational and applied topics related to autonomous systems engineering.
Position papers (4 pages in length for main content + 2 pages for references in AAAI format): we are seeking position papers that advocate for a particular approach or set of approaches, or present an overview of a promising relevant research area.

The submission website is https://easychair.org/conferences/?conf=trase2022.
Organizing Committee
Yevgeniy Vorobeychik (Washington University in St. Louis), Bruno Sinopoli (Washington University in St. Louis), Jinghan Yang (Washington University in St. Louis), Bo Li (UIUC), Atul Prakash (University of Michigan)
Additional Information
Supplemental Workshop site: https://jinghany.github.io/trase2022/

W39: Video Transcript Understanding (Half-Day)
Videos have become an omnipresent source of knowledge: courses, presentations, conferences, documentaries, live streams, meeting recordings, vlogs. This has created a strong demand for transcript understanding. However, the quality of audio and video content shared online and the nature of speech and video transcripts pose many challenges to the existing natural language processing.
Topics
At the AAAI 2022 Workshop on Video Transcript Understanding (VTU @ AAAI 2022), we aim to bring together researchers from various domains to make the best of the knowledge that all these videos contain. Researchers from related domains are invited to submit papers on recent advanced technologies, resources, tools and challenges for VTU. We will also organize 3 shared tasks in this workshop: punctuation restoration, domain adaptation for punctuation restoration, and chitchat detection.
Format
The workshop is being organized by application area or other, panels, invited speakers, interactive, small groups, discussions, presentations. Please specify the length of the workshop (1-day, 1.5-day, 2-day, or half-day.)
The workshop will be organized as half-day event with 2 invited speakers, follow by presentation from accepted papers (both ordinary papers, and shared task paper)
Attendance
40 attendees including: invited speakers, authors of accepted papers and shared task participants.
Submissions
The papers have to be submitted through EasyChair.
The VTU workshops accepts both short paper (4 pages) and long paper (8 pages)
Submission URL: https://easychair.org/my/conference?conf=vtuaaai2022.
Workshop Chairs

Franck Dernoncourt;88 E San Fernando St, San Jose, CA 95113, United States; dernonco@adobe.com
Viet Dac Lai234 Deschutes Hall, University of Oregon, Eugene, OR 97403, USA; vietl@cs.uoregon.edu; (+1)541-515-2996

Organizing Committee
Cesa Salaam (Howard University, USA), Hwanhee Lee (Seoul National University, South Korea), Jaemin Cho (University of North Carolina at Chapel Hill, USA), Jielin Qiu (Carnegie Mellon University, USA), Joseph Barrow (University of Maryland, US), Mengnan Du (Texas A&M University, USA), Minh Van Nguyen (University of Oregon, USA), Nicole Meister (Princeton University, USA), Sajad Sotudeh Gharebagh (Georgetown University, USA), Sampreeth Chebolu (University of Houston, USA), Sarthak Jain (Northeastern University, USA),Shufan Wang (University of Massachusetts Amherst, USA)
Additional Information
Supplemental Workshop site: https://vtuworkshop.github.io/2022/
 ",2022
This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2022 AAAI,2022
"AAAI-23 Workshop Program
The Thirty-Seventh AAAI Conference on Artificial IntelligenceFebruary 13 – 14, 2023Walter E. Washington Convention CenterWashington, DC, USA
Sponsored by the Association for the Advancement of Artificial Intelligence
AAAI-23 Workshops
(The workshop schedule will be available in November 2022.)",2023
"
W1: AI for Agriculture and Food Systems 
W2: AI for Behavior Change
W3: AI for Credible Elections: A Call to Action with Trusted AI 
W4: AI for Energy Innovation
W5: AI for Web Advertising
W6: AI to Accelerate Science and Engineering
W7: AI4EDU: AI for Education
W8: Artificial Intelligence and Diplomacy
W9: Artificial Intelligence for Cyber Security (AICS)
W10: Artificial Intelligence for Social Good (AI4SG)
W11: Artificial Intelligence Safety (SafeAI)
W12: Creative AI Across Modalities
W13: Deep Learning on Graphs: Methods and Applications (DLG-AAAI’23)
W14: DEFACTIFY: Multimodal Fact-Checking and Hate Speech Detection
W15: Deployable AI (DAI)
W16: DL-Hardware Co-Design for AI Acceleration
W17: Energy Efficient Training and Inference of Transformer Based Models
W18: Graphs and More Complex Structures for Learning and Reasoning (GCLR)
W19: Health Intelligence (W3PHIAI-23)
W20: Knowledge-Augmented Methods for Natural Language Processing
W21: Modelling Uncertainty in the Financial World (MUFin’23)
W22: Multi-Agent Path Finding
W23: Multimodal AI for Financial Forecasting (Muffin)
W24: Practical Deep Learning in the Wild (Practical-DL)
W25: Privacy-Preserving Artificial Intelligence
W26: Recent Trends in Human-Centric AI
W27: Reinforcement Learning Ready for Production
W28: Scientific Document Understanding
W29: Systems Neuroscience Approach to General Intelligence
W30: Uncertainty Reasoning and Quantification in Decision Making (UDM’23)
W31: User-Centric Artificial Intelligence for Assistance in At-Home Tasks
W32: When Machine Learning Meets Dynamical Systems: Theory and Applications
",2023
"
W1: AI for Agriculture and Food Systems
An increasing world population, coupled with finite arable land, changing diets, and the growing expense of agricultural inputs, is poised to stretch our agricultural systems to their limits. By the end of this century, the earth’s population is projected to increase by 45% with available arable land decreasing by 20% coupled with changes in what crops these arable lands can best support; this creates the urgent need to enhance agricultural productivity by 70% before 2050. Current rates of progress are insufficient, making it impossible to meet this goal without a technological paradigm shift. There is increasing evidence that enabling AI technology has the potential to aid in the aforementioned paradigm shift. This AAAI workshop aims to bring together researchers from core AI/ML, robotics, sensing, cyber physical systems, agriculture engineering, plant sciences, genetics, and bioinformatics communities to facilitate the increasingly synergistic intersection of AI/ML with agriculture and food systems. Outcomes include outlining the main research challenges in this area, potential future directions, and cross-pollination between AI researchers and domain experts in agriculture and food systems.
Topics
Specific topics of interest for the workshop include (but are not limited to) foundational andtranslational AI activities related to:

Plant breeding
Precision agriculture and farm management
Biotic/Abiotic stress prediction
Yield prediction
Agriculture data curation
Annotation efficient learning
Plant growth and development models
Remote sensing
Agricultural robotics
Privacy-preserving data analysis
Human-in-the-loop AI
Multimodal data fusion
High-throughput field phenotyping
(Bio)physics aware hybrid AI modeling
Development of open-source software, libraries, annotation tools, or benchmark datasets

Format
The workshop will be a one-day meeting comprising invited talks from researchers in the field, spotlight lightning talks and a poster session where contributing paper presenters can discuss their work. Attendance is open to all registered participants.
Submissions
Submitted technical papers can be up to 4 pages long (excluding references and appendices). Position papers are welcome. All papers must be submitted in PDF format using the AAAI-23 author kit. Papers will be peer-reviewed and selected for spotlight and/or poster presentation.
Organizing Committee
Girish Chowdhary (University of Illinois, Urbana Champaign), Baskar Ganapathysubramanian (Iowa State University; contact: baskarg@iastate.edu), George Kantor (Carnegie Mellon University), Soumik Sarkar (Iowa State University), Sierra Young (North Carolina State University), Ananth Kalyanaraman (Washington State University), Ilias Tagkopoulos (UC Davis).
Additional Information
https://aiafs-aaai.github.io/

W2: AI for Behavior Change
In decision-making domains as wide-ranging as medication adherence, vaccination uptake, college enrollment, financial savings, and energy consumption, behavioral interventions have been shown to encourage people towards making better choices. AI can play an important, and in some cases crucial, role in these areas to motivate and help people take actions that maximize welfare. It is also important to be cognizant of any unintended consequences of leveraging AI in these fields, such as problems of bias that algorithmic approaches can introduce, replicate, and/or exacerbate in complex social systems. A number of research trends are informing insights in this field. First, large data sources, both those conventionally used in social sciences (EHRs, health claims, credit card use, college attendance records) and the relatively unconventional (social networks, wearables, mobile devices), are now available, and are increasingly used to personalize interventions. These datasets can be leveraged to learn individuals’ behavioral patterns, identify individuals at risk of making sub-optimal or harmful choices, and target them with behavioral interventions to prevent harm or improve well-being. Second, psychological experiments in laboratories and in the field, in partnership with technology companies, to measure behavioral outcomes are increasingly used for informing intervention design. Third, there is an increasing interest in AI in moving beyond traditional supervised learning approaches towards learning causal models, which can support the identification of targeted behavioral interventions and flexible estimation of their effects. At the intersection of these trends is also the question of fairness – how to design or evaluate interventions fairly. These research trends inform the need to explore the intersection of AI with behavioral science and causal inference, and how they can come together for applications in the social and health sciences.  This workshop will build upon the success of the last two editions of the AI for Behavior Change workshop, and will focus on advances in AI and ML that aim to (1) study equitable exploration for unbiased behavioral interventions, (2) design and target optimal interventions, and (3) exploit datasets in domains spanning mobile health, social media use, electronic health records, college attendance records, fitness apps, etc. for causal estimation in behavioral science.Keywords: causal inference, behavior science, adaptive experiments, reinforcement learning, equitable exploration, optimal assignment, bias in decision-making, heterogeneous treatment effects, experiment design, mobile health
Topics
The goal of this workshop is to bring together the causal inference, artificial intelligence, and behavior science communities, gathering insights from each of these fields to facilitate collaboration and adaptation of theoretical and domain-specific knowledge amongst them. There will be two keynotespeakers, two to three invited speakers, a panel discussion of early career researchers working at the intersection of these fields, a submitted paper session and a poster session from participants.  We invite thought-provoking submissions on a range of topics in these fields, including:

Intervention design
Adaptive treatment assignment
Optimal assignment rules
Targeted nudges
Bias/equity in algorithmic decision-making
Mental health/wellness; habit formation
Recommender systems and digital data
Reinforcement Learning for efficient exploration

Format
The full-day workshop will start with a keynote talk, followed by an invited talk and contributed paper presentations in the morning. The post-lunch session will feature a second keynote talk, two invited talks. Papers more suited for a poster, rather than a presentation, would be invited for a poster session. We will end the workshop with a panel discussion by top researchers in the field.
Submissions
The audience of this workshop will be researchers and students from a wide array of disciplines including, but not limited to, statistics, computer science, economics, public policy, psychology, management, and decision science, who work at the intersection of causal inference, machine learning, and behavior science. AAAI, specifically, is a great venue for our workshop because its audience spans many ML and AI communities. We invite novel contributions following the AAAI-23 formatting guidelines, camera-ready style. Submissions will be peer reviewed. Submissions will be assessed based on their novelty, technical quality, significance of impact, interest, clarity, relevance, and reproducibility. We accept two types of submissions – full research papers no longer than 8 pages, and poster papers with 2 – 4 pages. References will not count towards the page limit. Submissions will be accepted via Easychair (submission details and deadlines on the workshop website).
Organizing Committee

Rahul Ladhania, University of Michigan, ladhania@umich.edu
Sabina Tomkins, University of Michigan, stomkins@umich.edu
Michael Sobolev, Cornell Tech, michael.sobolev@cornell.edu
Lyle Ungar, University of Pennsylvania, ungar@cis.upenn.edu

Additional Information
For any questions, please reach out to us at ai4behaviorchange at gmail dot comWebsite: https://ai4bc.github.io/ai4bc23/

W3: AI for Credible Elections: A Call to Action with Trusted AI
We invite papers that describe innovative use of AI technology or techniques in election processes. The workshop is intended to provide a forum for discussing new approaches and challenges in building AI that people trust and use for critical applications that power society – conducting elections, and for exchanging ideas about how to move the area forward.
Artificial Intelligence and machine learning have transformed modern society. It also impacts how elections are conducted in democracies, with mixed outcomes. For example, digital marketing campaigns have enabled candidates to connect with voters at scale and communicate remotely during COVID-19, but there remains widespread concern about the spread of election disinformation as the result of AI-enabled bots and aggressive strategies.
In response, we conducted the first workshop at Neurips 2021 to examine the challenges of credible elections globally in an academic setting with apolitical discussion of significant issues. The speakers, panels and reviewed papers discussed current and best practices in holding elections, tools available for candidates and the experience of voters. They highlighted gaps and experience regarding AI-based interventions and methodologies. To ground the discussion, the invited speakers and panelists were drawn from three International geographies: US – representing one of the world’s oldest democracies; India – representing the largest democracy in the world; and Estonia – representing a country using digital technologies extensively during elections and as a facet of daily life. The workshop had contributions on all technological and methodological aspects of elections and voting.
Topics
At AAAI 2023, we will run the second edition of the workshop.
The workshop welcomes contributions on all aspects of elections and voting, but especially focus on the use of AI in the following:

For election candidates○      Organizing candidate campaigns○      Detecting, informing and managing mis and disinformation
For election organizers○      Identifying and validating voters○      Informing people about election information
For voters○      Knowing about election procedures○      Verifying individual and community votes○      Navigating candidates and issues
Cross-cutting○      Promoting transparency in the election process○      Technology for data management and validation○      Case-studies of success or failure, and the reasons thereof

The intended audience of the workshop are students, academic researchers, professionals involved in technology for election management and informed voters.
Format
TBD
Invited Speakers
Colin Camerer (California Institute of Technology), Susan Murphy (Harvard University)
Submissions
Either extended abstracts (4 pages) or full papers (7 pages) anonymized using the AAAI 2023 style guidelines found here. 
All accepted papers will be presented in a virtual poster session. We welcome articles currently under review or papers planned for publication elsewhere.
Submissions site: https://easychair.org/conferences/?conf=ai4ce2023
Publication: Select papers will be considered for a forthcoming special issue of the AI Magazine of “AI for Credible Elections” in 2023.  All accepted papers will be made available online on the workshop website and will count as non-archival reports to allow submissions to future conferences/journals.
Important Dates

Workshop paper submissions due: November 11, 2022
Notification to authors: November 22, 2022
Camera-ready copies of authors’ papers: December 1, 2022
Early-bird registration to the conference: December 12, 2022

Organizing Committee
Biplav Srivastava (University of South Carolina), Anita Nikolich (University of Illinois-Urbana Champaign), Andrea Hickerson (University of Mississippi), Tarmo Koppel (Tallinn University), Chris Dawes (New York University), Sachindra Joshi (IBM Research)
Additional Information
Workshop info: https://sites.google.com/view/aielections Submissions: https://easychair.org/conferences/?conf=ai4ce2023

W4: AI for Energy Innovation
In light of pressing and transformative global needs for equitable and secure access to clean, affordable, and sustainable energy, as well as of the significant investment provided from governments and industries, the alignment of R&amp;D efforts on automation and AI across the entire spectrum is timelier than ever, from fundamental to applied energy sciences. Despite recent monumental AI progress and widespread interest, there may be disconnects between the AI frontier and energy-focused research. We envision a near future where energy systems will be equally intelligent as the most adept AI systems in existence, with energy resources equipped with smart functionalities to effectively operate under uncertainty, volatility, and threats, where communities empower their lives with reliable and sustainable energy, and where the entire AI community undertakes the challenge of providing solutions and inspiration for sustained energy innovation. This workshop will invite AAAI-23 attendees, researchers, practitioners, sponsors, and vendors from academia, government agencies, and the industry who will present diverse views and engage in fruitful conversations on how innovation in all aspects of AI may support and propel further energy innovation.
Topics
(i) fundamental energy sciences (incl. AI/ML methods for reduced order modeling, digital twins, and general, energy-focused physics-based ML)(ii) applied energy sciences (incl. AI/ML methods for efficient, robust, and equitable generation, distribution, and management of energy)(iii) AI assurance &amp; cybersecurity (incl. AI/ML methods for secure operation of intelligent entities across transmission and distribution grids)
Format
The one-day workshop will consist of keynote and invited presentations, talks of selected contributed papers, a panel discussion, and a lightning session outlining unique opportunities at national laboratories on applied AI for energy innovation. We strongly encourage dialogue-provoking contributions that summarize broader ongoing themes and efforts as well as upcoming and/or future opportunities that may stimulate a productive exchange and forge partnerships among participants. At the end of their talk, participants will be encouraged to propose a new energy-related benchmark problem that they would like to see the AI community adopting, recognizing that well-known general datasets and problems may be suitable for general AI/ML education and research, but possibly not ideal nor focused-enough vehicles to propel AI-equipped, energy-focused innovations. Contributions presented by both (a) established researchers/practitioners and (b) graduate students, early-career researchers, and start-up representatives are actively encouraged.
Submissions
Relevant short (2-4 pages) and long (6-8 pages) contributions in PDF AAAI-23 format are solicited. Submission details will be available soon on the workshop website aienergyworkshop2023.inl.gov (page expected to be active on October 1, 2022). Selected and presented contributions will be compiled in a workshop report, to be published at the open access DOE repository osti.gov by INL.
Organizing Committee
Humberto Garcia (U.S. DOE Idaho National Laboratory; humberto.garcia@inl.gov), Karthik Duraisamy (University of Michigan), Asok Ray (Pennsylvania State University), Dimitrios Pylorof (U.S. DOE Idaho National Laboratory).
Additional Information
Website: aienergyworkshop2023.inl.gov (page expected to be active on October 1, 2022).

W5: AI for Web Advertising
With the popularity of various forms of E-commerce, web advertising has become one prominent channel that businesses use to reach out to the customers. It leverages the Internet to promote products and services to audiences, which also has been an important revenue source of many Internet companies such as online social media platforms and search engines.
AI techniques have been extensively used in the pipeline of a web advertising system, such as retrieval, ranking and bidding. Despite the remarkable progress, there are still many unsolved and emerging issues about applying the state-of-the-art AI techniques to Web Advertising, such as the “cold-start” problem; trade-off between online AI systems serving accuracy and efficiency; data privacy protection and big data management.
This workshop is targeted on the above and other relevant issues, aiming to create a platform for people from academia and industry to communicate their insights and recent results.
Topics
Topics of interest include, but are not limited to, the following:

AI models and algorithms for Web Advertising, e.g. retrieval and ranking models; CTR and CVR prediction models; bidding algorithms; ads targeting; query understanding; user and ad item representations learning; cold-start model learning, etc.
AI infrastructure for Web Advertising, e.g. large scale multi-modality data collection, utilization and management; MLOps; real-time AI system design and deployment; AutoML techniques, etc.
Trustworthy AI in Web Advertising, e.g. data privacy protection; federated learning; differential privacy; model fairness, interpretability, and robustness against adversarial attacks, etc.
Other relevant applications and methods, e.g. recommendation, information retrieval, search, sequence learning, graph learning, etc.

Format
TBD
Submissions
Submissions should follow the AAAI-23 template. There is no page limit for the paper submission. Paper submission will be reviewed by domain experts. We welcome submissions of unpublished papers, including those that are submitted/accepted to other venues if that other venue allows so.
Paper submission website: https://cmt3.research.microsoft.com/AI4WebAds2023
Important Dates
Friday, November 4, 2022: Workshop Submissions Due to OrganizersFriday, November 18, 2022: Notifications Sent to AuthorsMonday, December 12, 2022: AAAI-23 Early Registration DeadlineFebruary 13 – 14, 2023: AAAI-23 Workshop Program
Organization Committee
Bo Liu (Walmart Ads); Rui Chen (Samsung Ads); Yong Ge (University of Arizona); Huayu Li (Meta Ads); Sheng Li (University of Virginia); Nastaran Ghadar (Twitter Ads)
Additional Information
Workshop website: https://ai4webads2023.github.io/Contact us: ai4webads2023@gmail.com

W6: AI to Accelerate Science and Engineering
Scientists and engineers in diverse application domains are increasingly relying on using computational and artificial intelligence (AI) tools to accelerate scientific discovery and engineering design. AI, machine learning, and reasoning algorithms are useful in building models and decision-making towards this goal. We have already seen several success stories of AI in applications such as materials discovery, ecology, wildlife conservation, and molecule design optimization. This workshop aims to bring together researchers from AI and diverse science/engineering communities to achieve the following goals:

Identify and understand the challenges in applying AI to specific science and engineering problems.
Develop, adapt, and refine AI tools for novel problem settings and challenges.
Community-building and education to encourage collaboration between AI researchers and domain area experts.

Invited Speakers
This year’s theme is AI for Earth and Environmental Sciences. Our invited speakers and panelists from both AI and Environmental sciences community include:
Prof. Milind Tambe, Harvard UniversityProf. Amy McGovern, University of OklahomaProf. Ryan Adams, Princeton UniversityDr. Ilkay Altintas, University of California San DiegoDr. Priya Donti, Incoming Faculty, Massachusetts Institute of TechnologyDr. Sara Beery, Incoming Faculty, Massachusetts Institute of Technology
Important Dates
Paper submission deadline: November 3rd, 2022 (11:59 PM PST)Notification: November 18th, 2022 (11:59 PM PST)Camera-ready due: November 31st, 2022 (11:59 PM PST)
Submissions
We welcome submissions of long (max. 8 pages), short (max. 4 pages), and position (max. 4 pages) papers describing research at the intersection of AI and science/engineering domains including chemistry, physics, power systems, materials, catalysis, health sciences, computing systems design and optimization, epidemiology, agriculture, transportation, earth and environmental sciences, genomics and bioinformatics, civil and mechanical engineering etc. Submissions must be formatted in the AAAI submission format. All submissions should be done electronically via CMT.
The submission deadline is November 3rd, 2022 (11:59 PM PST).
Submission site: https://cmt3.research.microsoft.com/AI2SE2023
Organizing Committee
Aryan Deshwal (Washington State University)Syrine Belakaria (Washington State University)Jana Doppa (Washington State University)Mrinal K Sen (University of Texas at Austin)Yolanda Gil (Information Sciences Institute, University of Southern California)
Additional Information
Website: https://ai-2-ase.github.io/

W7: AI4EDU: AI for Education
Introduction
Technology has transformed over the last few years, turning from futuristic ideas into today’s reality. AI is one of these transformative technologies that is now achieving great successes in various real-world applications and making our life more convenient and safe. AI is now shaping the way businesses, governments, and educational institutions doing things and is making its way into classrooms, schools and districts across many countries.
In fact, the increasingly digitalized education tools and the popularity of online learning have produced an unprecedented amount of data that provides us with invaluable opportunities for applying AI in education. Recent years have witnessed growing efforts from AI research community devoted to advancing our education and promising results have been obtained in solving various critical problems in education. For examples, AI tools are built to ease the workload for teachers. Instead of grading each piece of work individually, which can take up a bulk of extra time, intelligent scoring tools allow teachers the ability to have their students work automatically graded. In the coronavirus era, requiring many schools to move to online learning, the ability to give feedback at scale could provide needed support to teachers. What’s more, various AI based models are trained on massive student behavioral and exercise data to have the ability to take note of a student’s strengths and weaknesses, identifying where they may be struggling. These models can also generate instant feedback to instructors and help them to improve their teaching effectiveness. Furthermore, leveraging AI to connect disparate social networks among teachers, we may be able to provide greater resources for their planning, which have been shown to significantly effect students’ achievement.
Despite gratifying achievements have demonstrated the great potential and bright development prospect of introducing AI in education, developing and applying AI technologies to educational practice is fraught with its unique challenges, including, but not limited to, extreme data sparsity, lack of labeled data, and privacy issues. Hence, this workshop will focus on introducing research progress on applying AI to education and discussing recent advances of handling challenges encountered in AI educational practice.
Workshop Description
In this workshop, we invited AIED enthusiasts from all around the world through the following three different channels:
First, we invited established researchers in the AIED community to give a broad talk that (1) describes a vision for bridging AIED communities; (2) summarizes a well-developed AIED research area; or (3) presents promising ideas and visions for new AIED research directions.
Second, we called for regular workshop paper submissions and cross-submissions (papers that have appeared in or submitted to alternative venues) related to a broad range of AI domains for education.
Third, we hosted a global challenge on Codalab for a fair comparison of state-of-the-art Knowledge Tracing models and invited technical reports from winning teams.
Regular Workshop Paper Submission
We invite high-quality paper submissions of theoretical and experimental nature on AIED topics. The workshop solicits 4-6 pages double-blind paper submissions from participants. Submissions of the following flavors will be sought: (1) research ideas, (2) case studies (or deployed projects), (3) review papers, (4) best practice papers, and (5) lessons learned. The format is the standard double-column AAAI Proceedings Style. All submissions will be peer-reviewed. Some will be selected for spotlight talks, and some for the poster session.
Cross-submissions
In addition to previously unpublished work, we invite papers on relevant topics which have appeared in or submitted to alternative venues (such as other ML or AIED conferences). Accepted cross-submissions will be presented as posters, with an indication of the original venue. Selection of cross-submissions will be determined solely by the organizing committee.
Format
This will be a one day workshop with a number of paper presentations and poster spotlights, a poster session, several invited talks, and a panel discussion.
Prof. Max Welling, University of Amsterdam and Microsoft ResearchProf. José Miguel Hernández-Lobato, University of CambridgeProf. Connor Coley, Massachusetts Institute of TechnologyProf. Andrew White, University of RochesterDr. Rocío Mercado, Massachusetts Institute of Technology
We will include a panel discussion to close the workshop, in which the audience can ask follow up questions and to identify the key AI challenges to push the frontiers in Chemistry.
Submission Website
Submission website: https://easychair.org/conferences/?conf=aaai2023ai4edu.The submission AUTHOR KIT can be found at https://www.aaai.org/Publications/Templates/AnonymousSubmission23.zip.
Global Knowledge Tracing Challenge
In this competition, we would like to call for researchers and practitioners worldwide to investigate the opportunities of improving the student assessment performance via knowledge tracing approaches with rich side information.
The details of this competition can be found at http://ai4ed.cc/competition/aaai2023competition.
Organizing Committee
Weiqi Luo, Guangdong Institute of Smart Education, Jinan University, ChinaShaghayegh (Sherry) Sahebi, University at Albany – SUNY, USALu Yu, Beijing Normal University, ChinaRichard Tong, Squirrel AI Learning, USAJiahao Chen, TAL Education Group, ChinaQiongqiong Liu, TAL Education Group, China
Additional Information
Zitao Liu (main contact), TAL Education Group, China, zitao.jerry.liu@gmail.comHomepage: http://www.zitaoliu.com/

W8: Artificial Intelligence and Diplomacy
Advances in AI and advanced data analytics are having considerable policy-related, geopolitical, economic, societal, legal, and security impacts. Recent global challenges such as the COVID19 pandemic, concerns related to representative governments and associated democratic processes, as well as the importance of advanced data analytics and the potential use of AI-enabled systems in conflicts such as the war in Ukraine, motivate the importance of the topic of AI and diplomacy. There may be scenarios where diplomats, ambassadors, and other government representatives lack the technical understanding of AI and advanced data analytics to address challenges in all these domains, while the technical AI and data communities often lack a sophisticated understanding of the diplomatic processes and opportunities necessary for addressing AI challenges internationally. This workshop will explore the impact of advances both in artificial intelligence as well as advanced data analytics. This includes considering the broad impact of AI as well as data collection and curation globally, focusing especially on the impact that AI and data have on the conduct and practice of diplomacy.
Topics
Diplomacy-related topics include, but are not limited to:

AI and data as tools for diplomacy, including sources of data sets and expert models that could be utilized with machine-learning tools to promote diplomacy.
Issues that AI raises for diplomacy and policy formation in terms of the cybersecurity, national security, defense, intelligence, representative forms of government, civil liberties, and social wellbeing.
Opportunities for diplomatic cooperation on AI in the above issues, including on standards, restraints, voluntary agreements and multilateral and bilateral diplomacy to address concerns about AI while also protecting open research opportunities.

Technical topics include, but are not limited to:

The use of AI and data in synthetic news and media;
Data cooperatives and coalitions to provide equity in training AI models;
AI and data linked to deepfake production;
AI and data tied to personalization and micro-targeting;
AI and community data linked to public policy, international security activities, etc. We also welcome contributions related to best-practice in the development, testing, verification, and assessment of both AI systems and data governance efforts, especially from an ethical and trustworthiness perspective.

Format
This workshop will take place over one day. This workshop will involve a set of invited talks from international experts working at the intersection of diplomacy and artificial intelligence. Submissions will be sought from AI researchers and diplomacy experts alike. We envisage two panel discussions: one on the challenges to the conduct of diplomacy created by AI, and a second on the technical challenges posed by diplomatic practice on the development, evaluation, verification, and deployment of AI systems. The program will also involve sessions presenting accepted papers and position statements.
Attendance
Attendance is open to all those interested in the workshop topic.
Submissions
Authors are invited to send a contribution in the AAAI 2023 proceedings format. We welcome submissions of full-length papers of up to 8 pages in length (including references) as well as position papers of up to 4 pages in length (including references). Shorter contributions are welcome.
Submission site: https://easychair.org/my/conference?conf=AIDip2023
Organizing Committee
Professor Barry O’Sullivan (b.osullivan@cs.ucc.ie), University College Cork, IrelandDr. David A. Bray (dbray@stimson.org), Stimson Center, USA, and Business Executives for National Security, USAEric Richardson (richardson@hdcentre.org), Centre for Humanitarian Dialogue, Geneva, and University of Michigan and University of California-Berkeley Law Schools, USA
Additional Information
http://osullivan.ucc.ie/AIDip2023

W9: Artificial Intelligence for Cyber Security (AICS)
The workshop will focus on the application of AI to problems in cyber-security. Cyber systems generate large volumes of data and utilizing this effectively is beyond human capabilities. Additionally, adversaries continue to develop new attacks. The workshop will address AI technologies and their security applications, such as machine learning, game theory, natural language processing, knowledge representation, automated and assistive reasoning and human machine interactions.
This year the AICS will emphasize practical considerations in the real world with a special focus on social attacks, that is, attacking the human in the loop to gain access to critical systems.
In general, AI techniques are still not widely adopted in many real world cyber security situations. There are many reasons for this including practical constraints (power, memory, etc.), lack of formal guarantees within a practical real world model, and lack of meaningful, trustworthy explanations. Moreover, in response to improved automated systems security (better hardware security, better cryptographic solutions), cyber criminals have amplified their efforts with social attacks such as phishing attacks and spreading misinformation. These large-scale attacks are cheap and need only succeed for a tiny fraction of all attempts to be effective.  Thus, AI assistive techniques robust to human errors and insusceptible to manipulations can be very beneficial.
Topics
Topics of interest include, but are not limited to:

Machine learning (including RL) approaches to make cyber systems secure and resiliento Natural language processing techniqueso Anomaly/Threat detection techniqueso Big Data noise reduction techniqueso Adversarial Learningo Deception in Learningo Human behavioral modeling, being robust to human errors
Formal reasoning, with focus on human behavior element, in cyber systems
Game Theoretic reasoning in cyber security
Adversarial robust AI metrics
Multi-agent interaction/agent-based modeling in cyber systems
Modeling and simulation of cyber systems and system components
Decision making under uncertainty in cyber systems
Automation of cyber dataset labeling for realistic, benchmark datasets
Meta-ML techniques (i.e., learning to learn) for cyber-security
Quantitative human behavior models with application to cyber security
Operational and commercial applications of AI in security
Explanations of security decisions and vulnerability of explanation techniques

Format
Like previous years, the workshop will have two invited talks by recognized figures in the combined area of AI and cyber security. These plenary talks will set the context for the workshop by describing the domain and the major challenges in securing machine learning capabilities. We will host a series of short (15-20 minute) presentations of the papers accepted for this workshop. The number and length of presentations to be presented will be based on the volume and quality of responses to the Call for Participation (CFP). Finally, we will hold a moderated roundtable/panel discussion between members of the AI community on practical issues related to the use of AI and security.
The AICS workshop will be a one-day meeting, from roughly 9am to 5pm.
Attendance
About 50
Submissions
PDF file to be submitted on Easychair, at max 7 pages in AAAI format.
*Submit to: https://easychair.org/conferences/?conf=aics230
Main Contact
Arunesh Sinha – arunesh.sinha@rutgers.edu
Organizing Committee
James Holt, Laboratory for Physical Sciences, USA, holt@lps.umd.eduEdward Raff, Booz Allen Hamilton, USA, raff.edward@umbc.eduAhmad Ridley, National Security Agency, USADennis Ross, MIT Lincoln Laboratory, USA, Dennis.Ross@ll.mit.eduArunesh Sinha, Rutgers University, USA, arunesh.sinha@rutgers.eduDiane Staheli, Department of Defense, USA, diane.staheli@ll.mit.eduDiane Staheli serves as the DoD Chief Digital and Artificial Intelligence Officer (CDAO) Chief ofResponsible Artificial Allan Wollaber, MIT Lincoln Laboratory, USA, Allan.Wollaber@ll.mit.edu
Additional Information
Workshop URL: http://aics.site/

W10: Artificial Intelligence for Social Good (AI4SG)
Scope and Topics
The field of Artificial Intelligence stands at an inflection point, and there could be many different directions in which the future of AI research could unfold. Accordingly, there is a growing interest to ensure that current and future AI research is used in a responsible manner for the benefit of humanity (i.e., for social good). To achieve this goal, a wide range of perspectives and contributions are needed, spanning the full spectrum from fundamental research to sustained deployments in the real-world.
This workshop will explore how AI research can contribute to solving challenging problems faced by current-day societies. For example, what role can AI research play in promoting health, sustainable development and infrastructure security? How can AI initiatives be used to achieve consensus among a set of negotiating self-interested entities (e.g., finding resolutions to trade talks between countries)? To address such questions, this workshop will bring together researchers and practitioners across different strands of AI research and a wide range of important real-world application domains. The objective is to share the current state of research and practice, explore directions for future work, and create opportunities for collaboration. The workshop will be a very nice complement to the AAAI Special Track on AI for Social Impact as it will provide a forum where researchers interested in this area can connect in a more direct way.
The proposed workshop complements the objectives of the main conference by providing a forum for AI algorithm designers, such as those working in the areas of agent-based modelling, machine learning, spatio-temporal models, deep learning, explainable AI, fairness, social choice, non-cooperative and cooperative game theory, convex optimization, and planning under uncertainty on innovative and impactful real-world applications. Specifically, the proposed workshop serves two purposes. First, the workshop will provide an opportunity to showcase real-world deployments of AI research. More often than not, unexpected practical challenges emerge when solutions developed in the lab are deployed in the real world, which makes it challenging to utilize complex and well thought out computational/modeling advances. Learning about the challenges faced in these deployments during the workshop will help us understand lessons of moving from the lab to the real world. Second, the workshop will provide opportunities to showcase AI systems which dynamically adapt to changing environments, are robust to errors in execution and planning, and handle uncertainties of different kinds that are common in the real world. Addressing these challenges requires collaboration from different communities including machine learning, game theory, operations research, social science, and psychology. This workshop is structured to  encourage a lively exchange of ideas between members from these communities. We encourage submissions to the workshop from: (i) computer scientists who have used (or are currently using) their AI research to solve important real-world problems for society’s benefit in a measurable manner; (ii) interdisciplinary researchers combining AI research with various disciplines (e.g., social science, ecology, climate, health, psychology and criminology); and (iii) engineers and scientists from organizations who aim for social good, and look to build real systems. Topics of interest include, but are not limited to the areas identified in the AAAI Special Track on AI for Social Impact:

AISI: Agriculture/Food
AISI: Assistive Technology for Well-Being
AISI: Biodiversity or Habitat
AISI: Computational Social Science
AISI: Climate
AISI: Education
AISI: Economic/Financial
AISI: Energy
AISI: Environmental Sustainability
AISI: Health and Well-Being
AISI: Humanities
AISI: Low and Middle-Income Countries
AISI: Mobility/Transportation
AISI: Natural Sciences
AISI: Web or Social Networks
AISI: Philosophical and Ethical Issues
AISI: Security and Privac
AISI: Social Development
AISI: Social Welfare, Justice, Fairness and Equality
AISI: Urban Planning and Resilience
AISI: Underserved Communities
AISI: Socially Responsible AI: Fairness, Accountability, and Transparency
AISI: Other Social Impact

Format
The workshop will be a one-day meeting. It will include a number of (possibly parallel) technical sessions, a virtual poster session where presenters can discuss their work, with the aim of further fostering collaborations, multiple invited speakers covering crucial challenges for the field of AI for Social Good and learning and will conclude with a panel discussion.
Attendance
Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submission Information
Submission Link: https://easychair.org/my/conference?conf=ai4sg2021
Important Dates
Paper Submission Deadline – November 30, 2022Author Notification – December 20, 2022Camera Ready Version Due – January 10, 2023
Submission Types

Technical Papers: Full-length research papers of up to 7 pages (excluding references and appendices) detailing high quality work in progress or work that could potentially be published at a major conference in AAAI format
Short Papers: Position or short papers of up to 4 pages (excluding references and appendices) in AAAI format that describe initial work or the release of privacy-preserving benchmarks and datasets on the topics of interest.

All papers must be submitted in PDF format, using the AAAI-23 author kit. Submissions should include the name(s), affiliations, and email addresses of all authors. Submissions will be refereed on the basis of technical quality, novelty, significance, and clarity. Each submission will be thoroughly reviewed by at least two program committee members.
Submissions of papers rejected from the NeurIPS 2022 and AAAI 2023 technical program are welcomed. For questions about the submission process, contact the workshop chairs.
Organizing Committee
Amulya Yadav (Penn State University); Haipeng Chen (Harvard University); Sasha Luccioni (Mila, Universite de Montreal); Thanh Nguyen (University of Oregon)
Additional Information
https://amulyayadav.github.io/AI4SG2021/#contact

W11: Artificial Intelligence Safety (SafeAI)
Submission Deadline: Nov 04, 2022http://www.safeaiw.org
Scope
The accelerated developments in the field of Artificial Intelligence (AI) hint at the need for considering Safety as a design principle rather than an option. However, theoreticians and practitioners of AI and Safety are confronted with different levels of safety, different ethical standards and values, and different degrees of liability, that force them to examine a multitude of trade-offs and alternative solutions. These choices can only be analyzed holistically if the technological and ethical perspectives are integrated into the engineering problem, while considering both the theoretical and practical challenges of AI safety. A new and comprehensive view of AI Safety must cover a wide range of AI paradigms, including systems that are application-specific as well as those that are more general, considering potentially unanticipated risks. In this workshop, we want to explore ways to bridge short-term with long-term issues, idealistic with pragmatic solutions, operational with policy issues, and industry with academia, to build, evaluate, deploy, operate and maintain AI-based systems that are demonstrably safe.
This workshop seeks to explore new ideas on AI safety with particular focus on addressing the following questions:

What is the status of existing approaches in ensuring AI and Machine Learning (ML) safety, and what are the gaps?
How can we engineer trustable AI software architectures?
How can we make AI-based systems more ethically aligned?
What safety engineering considerations are required to develop safe human-machine interaction?
What AI safety considerations and experiences are relevant from industry?
How can we characterize or evaluate AI systems according to their potential risks and vulnerabilities?
How can we develop solid technical visions and new paradigms about AI Safety?
How do metrics of capability and generality, and the trade-offs with performance affect safety?
The main interest of the proposed workshop is to look at a new perspective of system engineering where multiple disciplines such as AI and safety engineering are viewed as a larger whole, while considering ethical and legal issues, in order to build trustable intelligent autonomy.

Topics
Contributions are sought in (but are not limited to) the following topics:

Safety in AI-based system architectures
Continuous V&V and predictability of AI safety properties
Runtime monitoring and (self-)adaptation of AI safety
Accountability, responsibility and liability of AI-based systems
Effect of Uncertainty in AI Safety
Avoiding negative side effects in AI-based systems
Role and effectiveness of oversight: corrigibility and interruptibility
Loss of values and the catastrophic forgetting problem
Confidence, self-esteem and the distributional shift problem
Safety of AGI systems and the role of generality
Reward hacking and training corruption
Self-explanation, self-criticism and the transparency problem
Human-machine interaction safety
Regulating AI-based systems: safety standards and certification
Human-in-the-loop and the scalable oversight problem
Evaluation platforms for AI safety
AI safety education and awareness
Experiences in AI-based safety-critical systems, including industrial processes, health, automotive systems, robotics, critical infrastructures, among others

Important Dates

Paper submission: Nov 04, 2022 – AOE time
Notification of acceptance: Nov 22, 2022 – AOE time
Camera-ready submission: Dec 06, 2022 – AOE time

Format
To deliver a truly memorable event, we will follow a highly interactive format that will include invited talks and thematic sessions. The thematic sessions will be structured into short pitches and a common panel slot to discuss both individual paper contributions and shared topic issues. Three specific roles are part of this format: session chairs, presenters and paper discussants. The workshop will be organized as a 1.5 or 2 days meeting (depending upon number of accepted submissions and events). Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
You are invited to submit:

Full technical papers (7-9 pages, including references), or
Proposals for technical Talks (up to one-page abstract including short Bio of the main speaker), without associated paper,
Position papers (5-7 pages, including references),

Manuscripts must be submitted as PDF files via EasyChair online submission system: https://easychair.org/conferences/?conf=safeai2023
Please keep your paper format according to CEUR Formatting Instructions (two-column format). The CEUR author kit can be downloaded from: http://ceur-ws.org/Vol-XXX/CEURART.zip
Papers will be peer-reviewed by the Program Committee (2-3 reviewers per paper). The workshop follows a single-blind reviewing process. However, we will also accept anonymized submissions.
The workshop proceedings will be published on CEUR-WS. CEUR-WS is archival in the sense that a paper cannot be removed once it’s published. Authors will keep the copyright of their papers as per CC BY 4.0. In other words, CEUR-WS is similar to arxiv. In any case, authors of accepted papers can opt out and decide not to include their paper in the proceedings. We will inform the authors about the procedure in due term.
We are also planning a Special Issue in a Journal, after the workshop.
For any question, please send an email to: safeai2023@easychair.org
Organizing Committee

Gabriel Pedroza, CEA LIST, France
Xiaowei Huang, University of Liverpool, UK
Xin Cynthia Chen, University of Hong Kong, China
Andreas Theodorou, UmeÂ University, Sweden

Steering Committee

José Hernández-Orallo, Universitat Politècnica de València, Spain
Mauricio Castillo-Effen, Lockheed Martin, USA
Richard Mallah, Future of Life Institute, USA
John McDermid, University of York, UK

Program Committee (look at the website: http://www.safeaiw.org)
Additional Information
Easychair CFP: https://easychair.org/cfp/safeai2023

W12: Creative AI Across Modalities
For the past few years, we have witnessed eye-opening generation results from AI foundation models such as GPT-3, and DALL-E2. These models have set up great infrastructures for new types of creative generation across various modalities such as language (e.g. story generation), images (e.g. text-to-image generation, fashion design), and audio (e.g. lyrics-to-music generation). Researchers in these fields encounter many similar challenges such as how to use AI to help professional creators, how to evaluate creativity for an AI system, how to boost the creativity of AI, how to avoid negative social impact, and so on. There have been various workshops that focus on some aspects of AI generation. This workshop aims to bridge researchers and practitioners from NLP, computer vision, music, ML, and other computational fields to create the 1st workshop on “Creative AI across Modalities”.
Topics
This multidisciplinary workshop will broadly explore topic areas including, but not limited to:

Creative language generation: stories, poetry, figurative languages.
Generative model and algorithms for image/audio, and multi-modal/video generation.
Theory and analysis for creativity (e.g., humor understanding)
Detecting and quantifying creativity
AI technologies for improving human creativity (e.g., HCI+ML studies to accelerate scientific novelty)
Data and resources for creative generation
Applications of creative AI generation, such as automatic video dubbing
Novel evaluation for creative AI generated outputs
Social, cultural, and ethical considerations of creative AI generations, such as racial/gender bias, trustworthiness

Format
This workshop will be a one-day hybrid event (on 2/13/2023), consisting in person and virtual talks from invited speakers, an in-person panel discussions, and hybrid paper presentations (oral and posters).
Attendance
We expect 50 or so attendance and open the workshop to all AAAI-23 participants.
Submissions
Authors are invited to send the following relevant work, either archival or non-archival, in the AAAI-23 proceedings format:Long paper: Submission of original work up to eight pages in length (including references).Short paper: Submission of work in progress with preliminary results, and position papers, up to four pages in length (+ references).
Submit to: Submission is through the OpenReview: https://openreview.net/group?id=AAAI.org/2023/Workshop/creativeAI
Workshop Chair
Dr. Jing Huang (Alexa AI, jhuangz@amaon.com)
Workshop Committee
Prof. Violet Peng (UCLA, violetpeng@cs.ucla.edu); Prof. Mohit Bansal (UNC Chapel Hill, mbansal@cs.unc.edu); Prof. Julian McAuley (UCSD, jmcauley@eng.ucsd.edu); Prof. Jiajun Wu (Stanford, jiajunwu@cs.stanford.edu); Dr. Arindam Mandal (Alexa AI, arindamm@amazon.com); Dr. Prithviraj Ammanabrolu (Allen Institute for AI, raja@allenai.org); Dr. Faeze Brahman (Allen Institute for AI, fbrahman@ucsc.edu); Dr. Ruohan Gao (Stanford, rhgao@cs.stanford.edu); Dr. Haw-Shiuan Chang (Alexa AI, chawshiu@amazon.com).
Additional Information
https://creativeai-ws.github.io/

W13: Deep Learning on Graphs: Methods and Applications (DLG-AAAI’23)
Deep Learning models are at the core of research in Artificial Intelligence research today. It is well- known that deep learning techniques that were disruptive for Euclidean data such as images or sequence data such as text are not immediately applicable to graph-structured data. This gap has driven a tide in research for deep learning on graphs on various tasks such as graph representation learning, graph generation, and graph classification. New neural network architectures on graph-structured data have achieved remarkable performance in these tasks when applied to domains such as social networks, bioinformatics and medical informatics.
This one-day workshop aims to bring together both academic researchers and industrial practitioners from different backgrounds and perspectives to the above challenges. The workshop will consist of contributed talks, contributed posters, and invited talks on a wide variety of the methods and applications. Work-in-progress papers, demos, and visionary papers are also welcome. This workshop intends to share visions of investigating new approaches and methods at the intersection of Graph Neural Networks and real-world applications. It aims to bring together both academic researchers and industrial practitioners from different backgrounds to discuss a wide range of topics of emerging importance for GNN.
Topics

Representation learning on graphs
Graph neural networks on node classification, graph classification, link prediction
The expressive power of Graph neural networks
Interpretability in Graph Neural Networks Adversarial Robustness in Graph Neural Networks
Graph structure learning and graph matching
Dynamic/incremental graph-embedding, prediction and generation
Learning representation on heterogeneous networks, knowledge graphs
Deep generative models for graph generation and graph transformation
AutoML in Graph Neural Networks
Graph2Seq, Graph2Tree, and Graph2Graph models

And with particular focuses but not limited to these applications:

Natural language processing
User/content understanding and recommendation
Bioinformatics (drug discovery, protein generation, protein structure prediction)
Program synthesis and analysis and software mining
Deep learning in neuroscience (brain network modeling and prediction)
Cybersecurity (authentication graph, Internet of Things, malware propagation)
Geographical network modeling and prediction (Transportation and mobility networks, Internet, mobile phone networks, power grids, social and contact networks)

Format
Full-day (8 hours)Our program consists of two sessions: academic session and industry session. The academic session will focus on the most recent research developments on GNNs. The industry session will emphasize practical industrial product developments using GNNs. We will also have a panel discussion on the current and future of GNNs on both research and industry. There will be keynote speakers who will deliver a live invited talk (25 minute) in person and four contributed speakers who will give a live invited talk (12 minutes) about the accepted workshop papers. There will be a poster session to display and discuss the accepted works.
Attendance
250
Submissions
Submissions are limited to a total of 5 pages, including all content and references, and must be in PDF format and formatted according to the new Standard ACM Conference Proceedings Template. Following this AAAI conference submission policy, reviews are double-blind, and author names and affiliations should NOT be listed. Submitted papers will be assessed based on their novelty, technical quality, potential impact, and clarity of writing. For papers that rely heavily on empirical evaluations, the experimental methods and results should be clear, well executed, and repeatable. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will be posted on the workshop website and will not appear in the AAAI proceedings.
Submit to: https://easychair.org/conferences/?conf=dlgaaai23
Workshop Chair
1) Main contact: Lingfei Wu (Pinterest)2) Jian Pei (Duke University)3) Jiliang Tang (Michigan State University)4) Yinglong Xia (Meta AI)5) Xiaojie Guo (IBM T.J. Watson Research Center)
Workshop Committee

Yuanqi Du, George Mason University, ydu6@masonlive.gmu.edu
Xiaojie Guo, George Mason Univerty,xguo7@gmu.edu
Lingwei Chen, Pennsylvania State University, lgchen@mix.wvu.edu
Xiang Ling, Institute of Software, Chinese Academy of Science, lingxiang@zju.edu.cn
Shiyu Wang, Emory University, shiyu.wang@emory.edu
Lingfei Wu, JD.com, lwu@email.wm.edu
Chen Ling, Emory University, chen.ling@emory.edu
Yinglong Xia, Facebook, yinglong.xia.2010@ieee.org
Junxiang Wang, Emory University, jwan936@emory.edu
Xiaoyun Wang, University of California, Davis, xiaoyunw@nvidia.com
Xinyi Zhang, Meta, xinyizhang@fb.com
Ankit Jain, Meta, asj.ankit@gmail.com
Li Zhang, George Mason University, lzhang18@gmu.edu
Zhicheng Liang, Rensselaer Polytechnic Institute, liangz4@rpi.edu
Yunsheng Bai, University of California, Los Angeles, yba@g.ucla.edu
Mingming Sun, Baidu, sunmingming01@baidu.com
Noah Lee, Meta, noahlee@fb.com

Additional Information
https://deep-learning-graphs.bitbucket.io/dlg-aaai23/

W14: DEFACTIFY: Multimodal Fact-Checking and Hate Speech Detection
Combating fake news is one of the burning societal crisis. It is difficult to expose false claims before they create a lot of damage. Automatic fact/claim verification has recently become a topic of interest among diverse research communities. Research efforts and datasets on text fact verification could be found, but there is not much attention towards multi-modal or cross-modal fact-verification. This workshop will encourage researchers from interdisciplinary domains working on multi-modality and/or fact-checking to come together and work on multimodal (images, memes, videos etc.) fact-checking. At the same time, multimodal hate-speech detection is an important problem but has not received much attention. Lastly, learning joint modalities is of interest to both Natural Language Processing (NLP) and Computer Vision (CV) forums. The second iteration will continue the research and discussion started last year.
Topics
It is a forum to bring attention towards collecting, measuring, managing, mining, and understanding multimodal disinformation, misinformation, and malinformation data from social media. This workshop covers (but not limited to) the following topics: —

Development of corpora and annotation guidelines for multimodal fact checking
Computational models for multimodal fact checking
Development of corpora and annotation guidelines for multimodal hate speech detection and classification
Computational models for multimodal hate speech detection and classification
Analysis of diffusion of Multimodal fake news and hate speech in social networks
Understanding the impact of the hate content on specific groups (like targeted groups)
Fake news and hate speech detection in low resourced languages

Format
It is a one-day workshop and includes: invited talks, interactive discussions, paper presentations, shared task presentations, poster session etc. We expect 60-70 participants.
Submissions
We encourage long papers, short papers and demo papers. Submissions will undergo double blind review. Accepted papers will be archived.
Primary Contact
Amitava Das (University of South Carolina; AMITAVA@mailbox.sc.edu) AI Institute, UofSC (AIISC)
Workshop Chairs
Amitava Das (University of South Carolina, USA), Amit Sheth (University of South Carolina, USA), Asif Ekbal (IIT Patna, India), Manoj Chinnakotla (Microsoft, USA), Parth Patwa (UCLA, USA)
Student Volunteers
Shreyash Mishra (IIIT Sri City, India), S. Suryavardan (IIIT Sri City, India), Megha Chakraborty (University of South Carolina, USA)
Additional Information
website: https://aiisc.ai/defactify2/ (under development)

W15: Deployable AI (DAI)
Deployment of AI models into the real world requires several fundamental research questions and issues involving algorithmic, systemic and societal aspects to be addressed. It is crucial to carry out progressive research in this domain and study the various deployability aspects with respect to AI models that can ensure positive impacts on society. In this workshop, we intend to focus on research works that propose models that can be used as real-world solutions and implement techniques/strategies that enable and ensure the ideal deployment of AI models while adhering to various standards.
Topics
Contributions are sought in (but are not limited to) the following topics:

Deployable AI- concepts and Models
Explainable and Interpretable AI
Human-in-the-loop
Online Learning and Transfer Learning
Fairness and Ethics in AI
Safety Security and Privacy in AI
Responsible AI
Integrity and Robustness in AI
Distilled and Lightweight AI Models
AI Models and Social Impact

Papers will be presented in poster format, and some will be selected for oral presentation. Through invited talks and presentations by the participants, this workshop will bring together current advances in Deployable AI and set the stage for continuing interdisciplinary research discussions.
Important Dates

Poster/short/position papers submission deadline: Oct 28, 2022
Full paper submission deadline: Oct 28, 2022
Paper notification: Nov 18, 2022

Format
This is a 1-day workshop involving talks by pioneer researchers from respective areas, poster presentations, and short talks of accepted papers.
Attendance
The eligibility criteria for attending the workshop will be registration in the conference/workshop as per AAAI norms. We expect 45-50 people in the workshop.
Submissions
You are invited to submit:

Poster/short/position papers (up to 4 pages)
Full papers (up to 7 pages)

The submissions should adhere to the AAAI paper guidelines available at (https://aaai.org/Conferences/AAAI-23/aaai23call/)
Accepted submissions will have the option of being posted online on the workshop website. Please mention this in the workshop submission for authors who do not wish their papers to be posted online. The submissions need to be anonymized.
See the webpage https://sites.google.com/view/dai-2023 for detailed instructions and submission link.
Workshop Chair
Balaraman Ravindran Affiliation: Indian Institute of Technology Madras, India
Workshop Committee
Balaraman Ravindran, IIT Madras, IndiaPrimary contact (ravi@cse.iitm.ac.in)Nandan Sudarsanam, IIT Madras, (nandan@iitm.ac.in)Arun Rajkumar, IIT Madras, (arunr@cse.iitm.ac.in)Harish Guruprasad, IIT Madras, (hariguru@cse.iitm.ac.in)Chandrashekar Lakshminarayanan, IIT Madras, (chandrashekar@cse.iitm.ac.in)Gokul S Krishnan, IIT Madras, (gokul@rbcdsai.org)Rahul Vashisht, IIT Madras (rahul@cse.iitm.ac.in)Krishna P, IIT Madras, (pkrishna@cse.iitm.ac.in)
Additional Information
Workshop URL: https://sites.google.com/view/dai-2023

W16: DL-Hardware Co-Design for AI Acceleration
As deep learning (DL) continues to permeate all areas of computing, algorithm engineers are increasingly relying on hardware system design solutions to improve the efficiency and performance of deep learning models. However, the vast majority of DL studies rarely consider limitations such as power/energy, memory footprint, and model size of real-world computing platforms, and even lessconsider the computational speed of hardware systems and their own computational characteristics. Addressing all of these metrics is critical if advances in DL are to be widely used on real device platforms and scenarios, especially those with high requirements for computational efficiencies, such as mobile devices and AR/VR. Therefore, it is desirable to design and optimize both the DL models and the hardware computing platforms. The workshop provides a great venue for the international research community to share mutual challenges and solutions between deep neural network learning and computing system platforms, with a focus on accelerating AI technologies on real system platforms through DL-hardware co-design.
Topics

Neural network pruning &amp; quantization &amp; distillation
Deep learning acceleration for applications
Hardware-aware network architecture search &amp; design
Applications of deep learning on mobile and AR/VR
New theory and fundamentals of DL-hardware co-design
Deep learning to improve computer architecture design
Real-time and energy-efficient deep learning systems
Hardware accelerators for deep learning

Format
The workshop will be a half-day meeting comprising several invited talks from distinguished researchers in the field, spotlight lightning talks and a poster session where contributing paper presenters can discuss their work, and a concluding panel discussion focusing on future directions. Attendance is open to all registered participants.
Submissions
Submitted technical papers can be up to 4 pages long (excluding references and appendices). Position papers are welcome. All papers must be submitted in PDF format using the AAAI-23 author kit. Papers will be peer-reviewed and selected for spotlight and/or poster presentation. Submission site: https://cmt3.research.microsoft.com/DCAA2023/Submission/Index
Organizing Committee
Dongkuan Xu (NC State), Hua Wei (NJIT), Ang Li (Qualcomm AI Research), Peipei Zhou (University of Pittsburgh), Caiwen Ding (UConn), Yingyan Lin (Rice University), Yanzhi Wang (Northeastern University)
Additional Information
Workshop URL: https://ncsu-dk-lab.github.io/workshops/dcaa@2023/

W17: Energy Efficient Training and Inference of Transformer Based Models
Transformers are the foundational principles of large deep learning language models. Recent successes of Transformer-based models in image classification and action prediction use cases indicate their wide applicability. In this workshop, we want to focus on the leading ideas using Transformer models such as PALM from Google. We will learn what have been their key observations on performance of the model, optimizations for inference and power consumption of both mixed-precision inference and training.
The goal of this Workshop is to provide a forum for researchers and industry experts who are exploring novel ideas, tools, and techniques to improve the energy efficiency of machine learning and deep learning as it is practiced today and would evolve in the next decade. We envision that only through close collaboration between industry and the academia we will be able to address the difficult challenges and opportunities of reducing the carbon footprint of AI and its uses. We have tailored our program to best serve the participants in a fully digital setting.  Our forum facilitates active exchange of ideas through

Keynotes, invited talks and discussion panels by leading researchers from industry and academia
Peer-reviewed papers on latest solutions including works-in-progress to seek directed feedback from experts
Independent publication of proceedings through IEEE CPS

Topics
We invite full-length papers describing original, cutting-edge, and even work-in-progress research projects about efficient machine learning. Suggested topics for papers include, but are not limited to:

Neural network architectures for resource constrained applications
Efficient hardware designs to implement neural networks including sparsity, locality, and systolic designs
Power and performance efficient memory architectures suited for neural networks
Network reduction techniques – approximation, quantization, reduced precision, pruning, distillation, and reconfiguration
Exploring interplay of precision, performance, power, and energy through benchmarks,workloads, and characterization
Simulation and emulation techniques, frameworks, tools, and platforms for machine learning
Optimizations to improve performance of training techniques including on-device and large- scale learning
Load balancing and efficient task distribution, communication and computation overlapping for optimal performance
Verification, validation, determinism, robustness, bias, safety, and privacy challenges in AI systems

The proceedings from previous instances have been published through the prestigious IEEE Conference Publishing Services (CPS) and are available to the community via IEEE Xplore. In each instance, IEEE conducted independent assessment of the papers for quality.
Format
Keynotes – Two keynote talks, each 45 minutes including 5 min for Q&amp;AInvited Talks – Six to eight invited talks, each 30 minutes including Q&amp;AOral Presentations – 10 to 12 short presentations, each 15 minutes in two sessionsPoster Sessions – During coffee and lunch breaksPanel Discussions – Two panel discussions of 30 min followed by 30 min for audience questions/commentsBreakout Sessions – After position statements by panelists
Attendance
50-75 people including authors, invited speakers, panelist and general audience.
Submissions
Up to 5 pages, electronic submission. Prior workshops editions:IEEE Xplore – Conference Table of ContentsAndIEEE Xplore – Conference Table of Contents
Important dates
Submission Deadline: Nov 7, 2022 (AOE)Notifications sent: Nov 18, 2022Final Manuscript due: Dec 1st, 2022Talk Recording due: Dec 19, 2022
Submission site: https://www.emc2-ai.org/submissionWebsite site: https://www.emc2-ai.org/aaai-23
Workshop Chair
Fanny Nina Paravecino, fanny.nina@microsoft.comKushal Datta, kushaldatta@microsoft.com
Organizing Committee
Raj Parihar, Chief AI Architect at d-Matrix Corporation (rparihar@d-matrix.ai)Satyam Srivastava, Chief AI Software Architect at d-Matrix Corporation (ssrivastava@d-matrix.ai)Tao Sheng, Director of AI and Machine Learning at Oracle Cloud (tao.t.sheng@oracle.com)Ananya Pareek, System Architect at Apple (ananyapareek@gmail.com)Prerana Maslekar, Silicon Verification Engineer at Microsoft (Prerana.maslekar@microsoft.com)Sushant Kondguli, Graphics Architect at Meta Reality Labs (sushantkondguli@fb.com)
Additional Information
https://www.emc2-ai.org/aaai-23

W18: Graphs and More Complex Structures for Learning and Reasoning (GCLR)
Topics
The study of complex graphs is a highly interdisciplinary field that aims to study complex systems by using mathematical models, physical laws, inference and learning algorithms, etc. Complex systems are often characterized by several components that interact in multiple ways among each other. Such systems are better modeled by complex graph structures such as edge and vertex labeled graphs (e.g., knowledge graphs), attributed graphs, multilayer graphs, hypergraphs, temporal/dynamic graphs, etc. In this 3rd instance of the GCLR (Graphs and more Complex structures for Learning and Reasoning) workshop, we will focus on various complex structures along with inference and learning algorithms for these structures. The current research in this area is focused on extending existing ML algorithms as well as network science measures to these complex structures. This workshop aims to bring researchers from these diverse but related fields together and embark on interesting discussions on new challenging applications that require complex system modeling and discovering ingenious reasoning methods. We have invited several distinguished speakers with research interests spanning from the theoretical to experimental aspects of complex networks.
Call For Papers
We invite submissions from participants who can contribute to the theory and applications of modeling complex graph structures such as hypergraphs, multilayer networks, multi-relational graphs, heterogeneous information networks, multi-modal graphs, signed networks, bipartite networks, temporal/dynamic graphs, etc. The topics of interest include, but are not limited to:

Constraint satisfaction and programming (CP), (inductive) logic programming (LP and ILP)
Learning with Multi-relational graphs (alignment, knowledge graph construction, completion, reasoning with knowledge graphs, etc.)
Learning with algebraic or combinatorial structure
Link analysis/prediction, node classification, graph classification, clustering for complex graph structures
Network representation learning
Theoretical analysis of graph algorithms or models
Optimization methods for graphs/manifolds
Probabilistic and graphical models for structured data
Social network analysis and measures
Unsupervised graph/manifold embedding methods

The papers will be presented in poster format, and some will be selected for oral presentation. Through invited talks and presentations by the participants, this workshop will bring together current advances in Network Science as well as Machine Learning and set the stage for continuing interdisciplinary research discussions.
Important Dates

XPoster/short/position papers submission deadline: Oct 28, 2022
Full paper submission deadline: Oct 28, 2022
Paper notification: Nov 18, 2022

Submission Guidelines
We invite submissions to the AAAI-23 workshop on Graphs and more Complex structures for Learning and Reasoning to be held on February 13 or 14, 2023. We welcome the submissions in the following two formats:

Poster/short/position papers: We encourage participants to submit preliminary but interesting ideas that have not been published before as short papers. These submissions would benefit from additional exposure and discussion that can shape a better future publication. We also invite papers that have been published at other venues to spark discussions and foster new collaborations. Submissions may consist of up to 4 pages plus one additional page solely for references.
Full papers: Submissions must represent original material that has not appeared elsewhere for publication and that is not under review for another refereed publication. Submissions may consist of up to 7 pages of technical content plus up to two additional pages solely for references.

The submissions should adhere to the AAAI paper guidelines available at (https://aaai.org/Conferences/AAAI-23/aaai23call/)
Accepted submissions will have the option of being posted online on the workshop website. For authors who do not wish their papers to be posted online, please mention this in the workshop submission. The submissions need to be anonymized.
See the webpage https://sites.google.com/view/gclr2023/submissions for detailed instructions and submission link.
Format
This is a 1-day workshop involving talks by pioneer researchers from respective areas, poster presentations, and short talks of accepted papers.
Attendance
The eligibility criteria for attending the workshop will be registration in the conference/workshop as per AAAI norms. We expect 50-65 people in the workshop.
Workshop Chair
Balaraman Ravindran, Affiliation: Indian Institute of Technology Madras, IndiaEmail: ravi@cse.iitm.ac.in
Workshop Committee

Balaraman Ravindran , Indian Institute of Technology Madras, India, Primary contact (ravi@cse.iitm.ac.in)
Ginestra Bianconi , Queen Mary University of London, UK (ginestra.bianconi@gmail.com)
Philip S. Chodrow, Middlebury College, USA (pchodrow@middlebury.edu)
Srinivasan Parthasarathy, Ohio State University, USA (srini@cse.ohio-state.edu)
Tarun Kumar, Hewlett Packard Labs, Bengaluru, India (tarun.kumar2@hpe.com)
Deepak Maurya, Purdue University, India (dmaurya@purdue.edu)
Anasua Mitra, IIT Guwahati, India (anasua.mitra@iitg.ac.in)

Additional Information
https://sites.google.com/view/gclr2023/

W19: Health Intelligence (W3PHIAI-23)
The integration of information from now widely available -omics and imaging modalities at multiple time and spatial scales with personal health records has become the standard of disease care in modern public health. Moreover, given the ever-increasing role of the World Wide Web as a source of information in many domains including healthcare, accessing, managing, and analyzing its content has brought new opportunities and challenges. The advances in web science and technology for data management, integration, mining, classification, filtering, and visualization has given rise to a variety of applications representing real-time data on epidemics.
Furthermore, to tackle and overcome several issues in personalized healthcare, information technology will need to evolve to improve communication, collaboration, and teamwork among patients, their families, healthcare communities, and care teams involving practitioners from different fields and specialties. All these changes require novel solutions, and the AI community is well-positioned to provide both theoretical- and application-based methods and frameworks.
Topics
The workshop will include original contributions on theory, methods, systems, and applications of data mining, machine learning, databases, network theory, natural language processing, knowledge representation, artificial intelligence, semantic web, and big data analytics in web-based healthcare applications, with a focus on applications in population and personalized health. The scope of the workshop includes, but is not limited to, the following areas:

Knowledge Representation and Extraction
Integrated Health Information Systems
Patient Education
Patient-Focused Workflows
Shared Decision Making
Geographical Mapping and Visual Analytics for Health Data
Social Media Analytics
Epidemic Intelligence
Predictive Modeling and Decision Support
Semantic Web and Web Services
Biomedical Ontologies, Terminologies, and Standards
Bayesian Networks and Reasoning under Uncertainty
Temporal and Spatial Representation and Reasoning
Case-based Reasoning in Healthcare
Crowdsourcing and Collective Intelligence
Risk Assessment, Trust, Ethics, Privacy, and Security
Sentiment Analysis and Opinion Mining
Computational Behavioral/Cognitive Modeling
Health Intervention Design, Modeling and Evaluation
Online Health Education and E-learning
Mobile Web Interfaces and Applications
Applications in Epidemiology and Surveillance (e.g., Bioterrorism, Participatory Surveillance, Syndromic Surveillance, Population Screening)
Hybrid methods, combining data driven and predictive forward models
Response to Covid-19
Computational models of ageing

We also invite participants to an interactive hack-a-thon focused on finding creative solutions to novel problems in health with an emphasis on ageing. We will design an ageing-related challenge that leverages publicly available data from the Gateway to Global Aging Data and the CDC’s Healthy Ageing dataset. The aim of the hack-a-thon is not only to foster innovation, but rather to engage the community and create new collaborations.
Submissions
We invite workshop participants to submit their original contributions following the AAAI format through EasyChair. Three categories of contributions are sought: full-research papers up to 8 pages; short papers up to 4 pages; and posters and demos up to 2 pages. Participants in the hack-a-thon will be asked to either register as team or be randomly assigned to a team after registration. Their results willbe submitted in either a short paper or poster format. A dataset(s) will be provided to hack-a-thon participants and the workshop organizers are engaged with Altos Labs to sponsor the event.
Organizing Committee
Martin Michalowski, PhD, FAMIA (Co-chair), University of Minnesota; Arash Shaban-Nejad, PhD, MPH (Co-chair), The University of Tennessee Health Science Center – Oak-Ridge National Lab (UTHSC-ORNL) Center for Biomedical Informatics; Simone Bianco, PhD (Co-chair), Altos Labs – Bay Area Institute of Science; Szymon Wilk, PhD, Poznan University of Technology; David L. Buckeridge, MD, PhD, McGill University; John S. Brownstein, PhD, Boston Children’s Hospital
Additional Information
http://w3phiai2023.w3phi.com/

W20: Knowledge-Augmented Methods for Natural Language Processing
We invite submission of papers describing innovative research methods and applications in knowledge- enhanced NLP. Papers that introduce new theoretical proofs or methods, help to develop a better understanding of new emerging concepts topics extensive empirical experiments, or demonstrate a novel application in natural language processing of these methods to a domain are strongly encouraged.
The topics include but are not limited to the following:Knowledge-augmented language model pre-trainingKnowledge-augmented language model fine-tuning
Knowledge retrieval from unstructured dataKnowledge retrieval from structured data
NLP methods augmented by knowledge graphsNLP methods augmented by commonsenseNLP methods augmented by heuristic rulesNLP methods augmented by dictionaryNLP methods augmented by linguistic featuresNLP methods augmented by retrieved textsNLP methods augmented by large language models
Submissions
Regular papers are limited to a total of 7 pages, excluding all references. We also encourage extended abstracts and short papers, which can be ranged from 2 to 4 pages excluding all references. All submissions must be in PDF format and formatted according to the new Standard AAAI Conference Proceedings Template. Following this AAAI conference submission policy, reviews are double-blind, and author names and affiliations should NOT be listed. Submitted papers will be assessed based on their novelty, technical quality, potential impact, and clarity of writing. For papers that rely heavily on empirical evaluations, the experimental methods and results should be clear, well executed, and repeatable. Authors are strongly encouraged to make code publicly available.
The accepted papers will be posted on the workshop website and will not appear in the AAAI proceedings.

Submission link (CMT)https://cmt3.research.microsoft.com/KnowledgeNLP2023/Submission/Index

Important Dates
Paper submission deadline: Nov. 4, 2022Author notification: Nov. 18, 2022All deadlines are 11:59pm UTC -12h (“anywhere on Earth”)
Organizing Committee
Chenguang Zhu (Microsoft Cognitive Service Research); Meng Jiang (University of Notre Dame); Lu Wang (University of Michigan); Shuohang Wang (Microsoft Cognitive Service Research); Wenhao Yu (University of Notre Dame); Huan Sun (Ohio State University)
Additional Information
Please email chezhu@microsoft.com, shuowa@microsoft.com if you have any questions!Website: https://knowledge-nlp.github.io/aaai2023

W21: Modelling Uncertainty in the Financial World (MUFin’23)
Of many things, Covid-19 has provided a stark proof that uncertainty is real, and it is here to stay. Perhaps nothing is more sensitive to uncertainty than the Financial World. To couple with it, while Artificial Intelligence techniques are used to predict the future state of events, their performance is significantly impacted by disruptions not captured in the past. Unforeseen scenarios such as economy changes, variations in the customer behavior, pandemics, recessions, and fraudulent transactions often result in unexpected behavior of financial models, thus associating a level of uncertainty with them. It is thus imperative for the research community to explore, identify, analyze, and address such uncertainties to develop robust models applicable in real-world scenarios. To this effect, the goal of this workshop is to bring academics and industry experts together to discuss on this important, timely and yet-unsolved area of modelling uncertainties in the financial world.
Submissions
We invite papers in the following categories (that have not been published before and nor are currently under consideration at some other venue) focused on modelling data uncertainty for financial applications.

Full papers up to 7-pages (with results)
Position papers up to 2-pages (with an idea that deserves broader discussion)

Topics
Topics of interest include, but are not limited to the following:
Application Topics:

Evaluating financial risk
Forecasting stock market
Modelling seasonality in market trends
Fraud transaction prediction
Modelling temporal social media activity
Recommendation systems

Technical Topics:

Temporal/Sequential data modelling – clustering, classification
Modelling uncertainty in financial data
Temporal graphs
Time Series Forecasting
Text analytics of financial reports, forecasts, and documents
Explainable/interpretable sequential modelling
Exploring fairness and robustness towards bias in financial models
Representation learning from temporal/sequential data
Modelling financial data as temporal point processes

Submissions need to be made at https://easychair.org/conferences/?conf=mufin23
The paper formatting must be consistent with that of AAAI 2023 main conference research track, details of which are mentioned in the Author Kit athttps://www.aaai.org/Publications/Templates/AuthorKit23.zip 
The best paper will be awarded a Best Paper Award worth $500! (sponsored by Mastercard)!
Format
MuFin 2023 will be a full day workshop with a diverse program including keynote talks, panel discussions, full-paper presentations and poster-sessions for the position papers. The attendance will be derived through paper authors, invited speakers and participants interested to learn more about the area.
Organizing Committee
Bonnie Buchanan, Karamjit Singh, Maneet Singh, Nitendra Rajput, Shraddha Pandey, Srijan Kumar
Additional Information
Workshop Website: https://sites.google.com/view/w-mufin/

W22: Multi-Agent Path Finding
Multi-Agent Path Finding (MAPF) requires computing collision-free paths for multiple agents from their current locations to given destinations in a known environment. Example applications vary from robot coordination to traffic management. In recent years, researchers from artificial intelligence, robotics, and theoretical computer science explore different variants of the MAPF problem as well as various approaches with different properties. The purpose of this workshop is to bring these researchers together to present their research, discuss future research directions, and cross-fertilize the different communities.
Topics
All works that relate to collision-free path planning or navigation for multiple agents are welcome,including but not limited to:
– Search-, rule-, reduction-, reactive-, and learning-based MAPF planners;– Combination of MAPF and task allocation, scheduling, and execution monitoring, etc.;– Real-world applications of MAPF planners;– Multi-agent reinforcement learning for centralized and decentralized MAPF;– Customization of MAPF planners for actual robots (e.g. motion and communication constraints, environment changes, etc.);– Standardization of MAPF terminology and benchmarks.
Format
The workshop is a One-Day workshop including invited talks, paper presentations, Q&As, and community discussion.
Attendance
The workshop expects to invite 30 participants, including program committees, accepted authors, invited speakers, and researchers who are active in the MAPF community. People who are not invited but interested in MAPF are welcome to attend.
Submissions
Submissions can contain relevant work in all possible stages, including work that was recently published, is under submission elsewhere, was only recently finished, or is still ongoing. Authors of papers published or under submission elsewhere are encouraged to submit the original papers or short versions (including abstracts) to educate other researchers about their work, as long as resubmissions are clearly labelled to avoid copyright violations. Position papers and surveys are also welcome. Submissions will go through a light review process to ensure a fit with the topic and acceptable quality. Non-archival workshop notes will be produced containing the material presented at the workshop.
Format: Any format is acceptable.
Page limitation: There is no limit on the number of pages.
Important Dates
Note: all deadlines are “anywhere on earth” (UTC-12)Paper submission deadline: Oct 31, 2022Paper notification: Nov 18, 2022Final version: Dec 14, 2022Workshop: Feb 13-14, 2023 (TBD)
Workshop Committee
Jiaoyang Li, Carnegie Mellon University (jiaoyangli@cmu.edu)Zhongqiang Ren, Carnegie Mellon University (zhongqir@andrew.cmu.edu)Han Zhang, University of Southern California (zhan645@usc.edu)Zhe Chen, Monash University (zhe.chen@monash.edu)Additional Information
Advisory Board
Sven Koenig, University of Southern CaliforniaHowie Choset, Carnegie Mellon UniversityPeter Stuckey, Monash University
Additional Information
http://idm-lab.org/wiki/AAAI23-MAPF/index.php/Main/HomePage

W23: Multimodal AI for Financial Forecasting (Muffin)
Financial forecasting is an essential task that helps investors make sound investment decisions and wealth creation. With increasing public interest in trading stocks, cryptocurrencies, bonds, commodities, currencies, crypto coins and non-fungible tokens (NFTs), there have been several attempts to utilize unstructured data for financial forecasting. Unparalleled advances in multimodal deep learning have made it possible to utilize multimedia such as textual reports, news articles, streaming video content, audio conference calls, user social media posts, customer web searches, etc for identifying profit creation opportunities in the market. E.g., how can we leverage new and better information to predict movements in stocks and cryptocurrencies well before others? However, there are several hurdles towards realizing this goal (1) large volumes of chaotic data, (2) combining text, audio, video, social media posts, and other modalities is non-trivial, (3) long context of media spanning multiple hours, days or even months, (4) user sentiment and media hype-driven stock/crypto price movement and volatility, (5) difficulty in automatically capturing market moving events using traditional statistical methods (6) misinformation and non-interpretability of financial systems leading to massive losses and bankruptcies.
To address all these major challenges, this workshop on Multimodal AI for Financial Forecasting (Muffin) at AAAI 2023 aims to bring together researchers from natural language processing, computer vision, speech recognition, machine learning, statistics and quantitative trading communities to expand research on the intersection of AI and financial time series forecasting. To further motivate and direct attention to unsolved problems in this domain, this workshop is organizing two shared tasks in this workshop – (1) Stock Price and Volatility Prediction post Monetary Conference Calls and (2) Cryptocurrency Bubble Detection.
Topics
This workshop will hold a research track and a shared task track. The research track aims to explore recent advances and challenges of multimodal AI for finance. As this topic is an inherently multi-modal subject, researchers from artificial intelligence, computer vision, speech processing, natural language processing, data mining, statistics, optimization, and other fields are invited to submit papers on recent advances, resources, tools, and challenges on the broad theme of Multimodal AI for finance. The topics of the workshop include but are not limited to the following:

Transformer models / Self-supervised Learning on Financial Data
Machine Learning for Finance
Video processing for facial expression detection, emotion detection, deception detection, gait and posture analysis
Financial Document Processing
Audio-visual-textual alignment, information extraction, salient
Vision-language model for financial video analysis
Financial Event detection in Multimedia
Entity extraction and linking on financial text
Conversational dialogue modeling for Financial Conference Calls
Social media and User NLP for Finance
Natural Language Processing Applications for Finance
Transfer learning approaches on financial data
Named-entity recognition, relationship extraction, ontology learning in financial documents
Multi-modal knowledge discovery
Data acquisition, augmentation, feature engineering, for financial analysis and risk management
Bias analysis and mitigation in financial models and data
Statistical Modeling for Time Series Forecasting
Interpretability and explainability for financial AI models
Privacy-preserving AI for finance
Video understanding (human behavior cognition, topic mining, etc.)

Important Dates

Paper submission deadline: November 4, 2022
Acceptance notification: November 18, 2022
Camera-ready submission: December 25, 2022
Muffin workshop at AAAI 2023: Feb 13, 2022

All deadlines are “anywhere on earth” (UTC-12)
Submissions
Authors are invited to submit their unpublished work that represents novel research. The papers should be written in English using the AAAI-23 author kit and follow the AAAI 2023 formatting guidelines. Authors can also submit the supplementary materials, including technical appendices, source codes, datasets, and multimedia appendices. All submissions, including the main paper and its supplementary materials, should be fully anonymized. For more information on formatting and anonymity guidelines, please refer to AAAI 2023 call for paper page.
All papers will be double blind peer reviewed. Muffin workshop accepts both long papers and shortpapers:

Short Paper: Up to 4 pages of content including the references. Upon the acceptance, the authors are provided with 1 more page to address the reviewer’s comments.
Long Paper: Up to 8 pages of content including the references. Upon the acceptance, the authors are provided with 1 more page to address the reviewer’s comments.
Shared Task Track: Participants are invited to take part in shared tasks: (1) Financial Prediction from Conference Call Videos and (2) Cryptocurrency Bubble Detection. Participants are invited to submit a system paper of 4-8 pages of content including the references.

Two reviewers with the same technical expertise will review each paper. Authors of the accepted papers will present their work in either the Oral or Poster session. All accepted papers will appear on the workshop proceedings that will be published on CEUR-WS. The authors will keep the copyright of their papers that are published on CEUR-WS. The workshop proceedings will be indexed by DBLP.
Paper must be submitted using  EasyChair (TBD) . For information on System Paper submission for the share tasks, please refer to our shared tasks page.
Organizing Committee

Puneet Mathur, University of Maryland College Park, USA
Franck Dernoncourt, Adobe Research, USA
Fu-Ming Guo, Fidelity Investments, USA
Lucie Flek, University of Marburg, Germany
Ramit Sawhney, Georgia Institute of Technology, USA
Sanghamitra Dutta, University of Maryland College Park, USA
Sudheer Chava, Georgia Institute of Technology, USA
Dinesh Manocha, University of Maryland College Park, USA

Additional Information
https://muffin-aaai23.github.io/cfp.html

W24: Practical Deep Learning in the Wild (Practical-DL)
Deep learning has achieved great success for artificial intelligence (AI) in many advanced tasks, such as computer vision, natural language processing, and robotics. However, research in the AI field also shows that their performance in the wild is far from practical towards open-world data and scenarios. Besides the accuracy that is widely concerned in deep learning, the phenomena are significantly related to the studies about model efficiency and robustness, which we abstract as Practical Deep Learning in the Wild (Practical-DL).
Regarding model efficiency, in contrast to the ideal environment, it is impractical to train a huge neural network containing billions of parameters using a large-scale high-quality dataset and then deploy it to an edge device in practice. Meanwhile, considering model robustness, input data with noises frequently occur in open-world scenarios, which presents critical challenges for the building of robust AI systems in practice. Moreover, existing research presents that there is a trade-off between the robustness and accuracy of deep learning models, while in the context of efficient deep learning with limited resources, it is more challenging to achieve a better trade-off under the premise of satisfying efficiency. These complex demands would bring profound implications and an explosion of interest for research into the topic of this Practical-DL workshop in AAAI 2023, namely building practical AI with efficient and robust deep learning models.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Network sparsity, quantization, and binarization
Adversarial attacking deep learning systems
Neural architecture search (NAS)
Robust architectures against adversarial attacks
Hardware implementation and on-device deployment
Benchmark for evaluating model robustness
On-device learning
New methodologies and architectures for efficient and robust deep learning

Important Dates
November 4, 2022 – Submission DeadlineNovember 23, 2022 – Acceptance NotificationFebruary 13, 2023 – Workshop Date
Format
The workshop will be a 1.5-day meeting.
The workshop will include several technical sessions, i.e., oral sessions and poster sessions where presenters can discuss their work, to further foster collaborations, invited talk sessions that covering crucial aspects for the practical deep learning in the wild, especially the efficient and robust deep learning. Besides, this workshop will hold a challenge to offer a fertile ground for designing efficient deep learning systems in practice.
Attendance
Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
URL:  https://cmt3.research.microsoft.com/PracticalDL2023Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-23 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentations at the workshop.
Invited Speakers
Adam Kortylewski (Research Scientist, Max Planck for Informatics and Saarland Informatics Campus)Priyadarshini Panda (Assistant Professor, Yale University)Florian Tramer (Assistant Professor, ETH Zürich)Tom Goldstein (Associate Professor, University of Maryland)Neil Gong (Assistant Professor, Duke University)Jie M. Zhang(Lecturer/Assistant Professor, King’s College London)Cihang Xie (Assistant Professor, UC Santa Cruz)Xiaochun Cao (Professor, Shenzhen Campus, Sun Yat-sen University)Shouling Ji (Professor, Zhejiang University)Bichen Wu (Staff Research Scientist, Meta Reality Labs)
Workshop Chair
Haotong Qin (Beihang University)Ruihao Gong (SenseTime Research)Jiakai Wang (Zhongguancun Laboratory)Siyuan Liang (Chinese Academy of Sciences)Zeyu Sun (Zhongguancun Laboratory)Aishan Liu (Beihang University)Wenbo Zhou (University of Science and Technology of China)Shanghang Zhang (Peking University.)Fisher Yu (ETH Zurich)Xianglong Liu (Beihang University)
Workshop Committee (Incomplete list)
Xiuying Wei (Beihang University)Jun Guo (Beihang University)Shunchang Liu (Beihang University)Simin Li (Beihang University)Yifu Ding (Beihang University)Mingyuan Zhang (Nanyang Technological University)Jinyang Guo (Beihang University)Renshuai Tao (Huawei)
Additional Information
https://practical-dl.github.io/

W25: Privacy-Preserving Artificial Intelligence
Overview
The availability of massive amounts of data, coupled with high-performance cloud computing platforms, has driven significant progress in artificial intelligence and, in particular, machine learning and optimization. It has profoundly impacted several areas, including computer vision, natural language processing, and transportation. However, the use of rich data sets also raises significant privacy concerns: They often reveal personal sensitive information that can be exploited, without the knowledge and/or consent of the involved individuals, for various purposes including monitoring, discrimination, and illegal activities. In its fourth edition, the AAAI Workshop on Privacy-Preserving Artificial Intelligence (PPAI-23) provides a platform for researchers, AI practitioners, and policymakers to discuss technical and societal issues and present solutions related to privacy in AI applications. The workshop will focus on both the theoretical and practical challenges related to the design of privacy-preserving AI systems and algorithms and will have strong multidisciplinary components, including soliciting contributions about policy, legal issues, and the societal impact of privacy in AI.
Topics
The workshop organizers invite paper submissions on the following (and related) topics:

Applications of privacy-preserving AI systems
Attacks on data privacy
Differential privacy: theory and applications
Distributed privacy-preserving algorithms
Privacy-preserving Federated learning
Human rights and privacy
Privacy and Fairness
Privacy and causality
Privacy-preserving optimization and machine learning
Privacy-preserving test cases and benchmarks
Surveillance and societal issues

Finally, the workshop will welcome papers that describe the release of privacy-preserving benchmarks and data sets that can be used by the community to solve fundamental problems of interest, including in machine learning and optimization for health systems and urban networks, to mention but a few examples.
Format
The workshop will be a one-day meeting and will include a number of technical sessions, a poster session where presenters can discuss their work, with the aim of further fostering collaborations, multiple invited speakers covering crucial challenges for the field of privacy-preserving AI applications, a tutorial talk, and will conclude with a panel discussion. Attendance is open to all. At least one author of each accepted submission must be present at the workshop.
Submissions
Submissions of technical papers can be up to 7 pages excluding references and appendices. Short or position papers of up to 4 pages are also welcome. All papers must be submitted in PDF format, using the AAAI-23 author kit. Papers will be peer-reviewed and selected for oral and/or poster presentation at the workshop.Submission site: https://cmt3.research.microsoft.com/PPAI2023
Organizing Committee
Ferdinando Fioretto, ffiorett@syr.edu (Syracuse University)Catuscia Palamidessi, catuscia@lix.polytechnique.fr (Inria, Ecole Polytechnique)Pascal Van Hentenryck, pascal.vanhentenryck@isye.gatech.edu (Georgia Institute of Technology)
Additional Information
Supplemental workshop site: https://aaai-ppai23.github.io/

W26: Recent Trends in Human-Centric AI
Human-Centric Artificial Intelligence is the notion of developing and using AI systems to help enhance, augment, and improve the quality of human life. Naturally, this paradigm involves two major components: human-centered computing and representation learning and responsible AI in human-centric applications. 
The first component revolves around tasks such as user authentication, activity recognition, pose estimation, affective computing, health analytics, and others, which often rely on modeling data with specific spatiotemporal properties, for instance human activity images/videos, audio signals,sensor-based time-series (e.g., PPG, ECG, EEG, IMU, clinical/medical data), and more. In recent years, learning effective representations for computer vision and natural language has revolutionized the effectiveness of solutions in these domains. Nonetheless, other data modalities, especially human-centric ones, have been largely under-served in terms of research and development. For these under-served domains, the general attitude has been to take advances from the ‘vision’ or ‘NLP’ communities and adapt them where possible. We argue, however, that a more original and stand-alone perspective on human-centric data can be highly beneficial and can lead to new and exciting advancements in the area. While the first component of this workshop mostly covers interpretation of people by AI, the second key component of the workshop is centered around interpretation of AI by people. This means aiding humans to investigate AI systems to facilitate responsible development, prioritizing concepts such as explainability, fairness, robustness, and security. We argue that identifying potential failure points and devising actionable directions for improvement is imperative for responsible AI and can benefit from translating model complexities into a language that humans can interpret and act on. Hence, this workshop also aims to cover recent advances in the area of responsible AI in human-centric applications.
In the R2HCAI workshop, we aim to bring together researchers broadly interested in Representation Learning for Responsible Human-Centric AI to discuss recent and novel findings in the intersection of these communities.
Topics
The workshop invites contributions to novel methods, innovations, and applications of Human- Centric AI including (but not limited to):

Curation and handling for human-generated data (e.g., speech, human-related images/videos such as faces, gait, activities, interactions, etc, wearable, clinical, medical, and health data such as PPG, ECG, EEG, IMU, and others),
Learning frameworks such as unsupervised (self-supervised, semi-supervised) learning for human-generated sensor signals & medical data,
Learning architectures such as novel networks and loss functions, for human-generated data,
Explainable/interpretable machine learning,
Fairness, accountability, and transparency,
Evaluation and benchmarking of responsible AI development,
Responsible human-AI interaction
Theoretical frameworks for responsible AI,
Privacy-preserving AI.

Format
The workshop will be a 1-day event with a number of invited talks by prominent researchers, a panel discussion, and a combination of oral and poster presentations of accepted papers.
Submissions

The AAAI template (https://aaai.org/Conferences/AAAI-23/aaai23call/) should be used for all submissions.
Two types of submissions will be considered: full papers (6-8 pages + references + unlimited appendices), and short papers (2-4 pages + references).
Publication in the workshop is considered non-archival and does not prohibit authors from publishing their papers in archival venues such as NeurIPS/ICLR/ICML or IEEE/ACM Conferences and Journals. We also welcome submissions that are currently under consideration in such archival venues. Upon acceptance papers will be made publicly available on the workshop website.
Submissions will go through a double-blind review process.
Submit to: https://cmt3.research.microsoft.com/R2HCAI2023/

Organizing Committee
Ahmad Bei rami (Google Research)Ali Etemad (Queen&#39;s University &amp; Google Research)Asma Ghandeharioun (Google Research)Luyang Liu (Google Research)Ninareh Mehrabi (USC ISI)Pritam Sarkar (Queen’s University & Vector Institute)
Additional Information
Contact: r2hcai@googlegroups.comWebsite: https://r2hcai.github.io/

W27: Reinforcement Learning Ready for Production
The 1st Reinforcement Learning Ready for Production workshop, held at AAAI 2023, focuses on understanding reinforcement learning trends and algorithmic developments that bridge the gap between theoretical reinforcement learning and production environments.
Topics

Efficient reinforcement learning algorithms that optimize sample complexity in real-world environments
Counterfactual evaluation for reinforcement learning algorithms
Reinforcement learning research for Recommendation Systems, Robotics, Optimization and many more industry fields that enables productionalization of reinforcement learning.
Novel applications for reinforcement learning in the internet, robotics, chip design, supply chain and many more industry fields. Outcomes from these applications should come from either production environments or well-recognized high-fidelity simulators (excluding standard OpenAI Gym and standard Atari Games)

Format
This workshop will be a 1-day workshop. We have confirmed 7 distinguished reinforcement learning researchers and practitioners to speak or participate in a panel for this workshop (listed in the next section, some have scheduling pending). We will have a reinforcement learning foundations panel, and talks on reinforcement learning advancements, applications in recommender systems, robotics, medical systems, and production A/B experiments. We anticipate about 4 hours of hosted content from the workshop and 1.5 hours of poster sessions and 1.5 hours of contributed talks, which will go from 10 am to 5 pm on the workshop day.
Attendance
We expect to invite people who have their paper accepted and industry/academia experts familiar with this matter.
Submissions
We expect 6-8 pages for full papers excluding reference and supplement.
Submit to: https://cmt3.research.microsoft.com/RLRP2023/
Workshop Chair
Zheqing Zhu, Meta AI / Stanford University, billzhu@fb.com
Organizing Committee
Zheqing Zhu, Meta AI / Stanford University, billzhu@fb.com; Yuandong Tian, Meta AI, yuandong@fb.com; Timothy Mann, Meta, kingtim@fb.com; Haque Ishfaq, McGill University, haque.ishfaq@mail.mcgill.ca; Zhiwei Qin, Lyft, zq2107@caa.columbia.edu; Doina Precup, McGill University / DeepMind, dprecup@cs.mcgill.ca; Shie Mannor, Technion / Nvidia, shie@ee.technion.ac.il
Additional Information
https://sites.google.com/view/rlready4prodworkshop/home

W28: Scientific Document Understanding
Scientific documents such as research papers, patents, books, or technical reports are some of the most valuable resources of human knowledge. At the AAAI-23 Workshop on Scientific Document Understanding (SDU@AAAI-23), we aim to gather insights into the recent advances and remaining challenges in scientific document understanding. Researchers from related fields are invited to submit papers on the recent advances, resources, tools, and upcoming challenges for SDU.
Topics
SDU is a workshop to gather insights into the recent advances and remaining challenges in scientific document understanding. As this topic is inherently a multi-disciplinary subject, researchers from artificial intelligence, natural language processing, information retrieval and extraction, image processing, data mining, statistics, bio-medicine, cybersecurity, finance, and other fields are invited to submit papers on the recent advances, resources, tools, and upcoming challenges for SDU. Topics of interest for this workshop include but are not limited to:

Information extraction and information retrieval for scientific documents;
Question answering and question generation for scholarly documents;
Word sense disambiguation, acronym identification and expansion, and definition extraction;
Document summarization, text mining, document topic classification, and machine reading comprehension for scientific documents;
Graph analysis applications including knowledge graph construction and representation, graph reasoning, and query knowledge graphs;
Multi-modal and multi-lingual scholarly text processing;
Biomedical image processing, scientific image plagiarism detection, and data visualization;
Code/Pseudo-code generation from text and image/diagram captioning;
New language understanding resources such as new syntactic/semantic parsers, language models, or techniques to encode scholarly text;
Survey or analysis papers on scientific document understanding and new tasks and challenges related to each scientific domain;
Factuality, data verification, and anti-science detection;

Format
SDU is a one-day workshop. The full-day workshop will start with an opening remark followed by research paper presentations in the morning. The post-launch session includes invited talks and shared task system paper representations. We will end the workshop with a closing remark.
Attendance
SDU invites all researchers in the fields of artificial intelligence, natural language processing, and computer vision to attend the workshop to discuss the recent advancements and challenges for SDU. Authors with accepted papers are also required to attend to present their work. 50 attendees are expected for this workshop.
Additional Information
For information on Submission requirements, how to submit, and workshop organizers and committeeplease refer to the workshop website: https://sites.google.com/view/sdu-aaai23

W29: Systems Neuroscience Approach to General Intelligence
AI technology and neuroscience have progressed such that it’s again prudent to look to the brain as a model for AI. Examining current artificial neural networks, theoretical computer science, and systems neuroscience, this workshop will uncover gaps in knowledge about the brain and models of intelligence.
Bernard Baars modeled the brain’s cognitive processes as a Global Workspace. This was elaborated in network neuroscience as the Global Neuronal Workspace, and in theoretical computer science as the Conscious Turing Machine (CTM) [1]. The CTM is a substrate independent model for consciousness. AI researchers have proposed variations and extensions of the Global Workspace, connecting the CTM to Transformers [2] and using them to communicate among specialist modules [3].
Meanwhile, neuroscience has identified large-scale brain circuits brain that bear striking resemblance to patterns found in contemporary AI architectures such as Transformers. This workshop will aim to map the Global Workspace and CTM to AI systems using the brain’s architecture as a guide. We hypothesize that this approach can achieve general intelligence and that high resolution recordings from the brain can be used to validate its models.
The goal of this workshop is to bring together a multi-disciplinary group comprising AI researchers, systems neuroscientists, algorithmic information theorists, and physicists to understand gaps in this larger agenda and to determine what’s known about what’s needed to build thinking machines.
References: [1] https://doi.org/10.1073/pnas.2115934119  [2] https://researcher.draco.res.ibm.com/researcher/view_group.php?id=11044 [3] https://arxiv.org/abs/2103.01197
Topics

Plausible comparisons between AI architectures and brain regions
Novel architectures for coupling AI components according to the brain’s functional neuroanatomy
Micro-benchmarks to validate novel architectures’ capabilities
Validation of synthetic AI brain models against brain recordings

Format
The workshop will be 2 days and will include invited talks, submitted talks by participants, and hybrid panel discussions. Three general discussion sessions will occur. Within 2 months after the workshop, participants will submit follow up articles, to be published in a forum to be determined.
Attendance
40 presenter/participants
Submissions
URL: https://docs.google.com/forms/d/e/1FAIpQLSf5xuuqUggzeNesfJ8Km-rpj__NLhhojQXspxAK446KtCbr6g/viewform
Workshop Chair
Co-chairs: Mark Wegman (wegman@us.ibm.com) and James Kozloski (kozloski@us.ibm.com), T.J. Watson Research Center, Yorktown Heights, NY 10598,
Workshop Committee
Lenore Blum, EECS, Berkeley. lblum@cs.cmu.eduIrina Rish, Computer Science and Operations Research, Université de Montréal, Mila – Quebec AI Institute. irina.rish@mila.quebecAndrew Sharott, Oxford University Medical Research Council, Brain Network Dynamics Unit. andrew.sharott@bndu.ox.ac.uk
Additional Information
https://researcher.draco.res.ibm.com/researcher/view_group_subpage.php?id=11048

W30: Uncertainty Reasoning and Quantification in Decision Making (UDM’23)
Deep neural networks (DNNs) have received tremendous attention and achieved great success in various applications, such as image and video analysis, natural language processing, recommendation systems, and drug discovery. However, inherent uncertainties derived from different root causes have been serious hurdles for DNNs to find robust and trustworthy solutions for real-world problems. A lack of consideration of such uncertainties may lead to unnecessary risk. For example, a self-driving autonomous car can misclassify a human on the road. A deep learning-based medical assistant may misdiagnose cancer as a benign tumor. Uncertainty has become increasingly important, and it has been attracting attention from academia and industry due to its increased popularity in real-world applications with uncertain concerns. It also emphasizes decision-making problems, such as autonomous driving and diagnosis systems. Therefore, the wave of research at the intersection of uncertainty reasoning and quantification in data mining and machine learning has also influenced other fields of science, including computer vision, natural language processing, reinforcement learning, and social science.
Topics
We encourage submissions in various degrees of progress, such as new results, visions, techniques, innovative application papers, and progress reports under the topics that include, but are not limited to, the following broad categories:

Uncertainty quantification in classification and regression
Out-of-distribution detection
Conditional reasoning with uncertainty
Quantification of multidimensional uncertainty
Sequential uncertainty estimation
Interpretation of uncertainty
Uncertainty-aware deep reinforcement learning
Decision-making with uncertainty

And with particular focuses but not limited to these application domains:

Application of uncertainty methods in large-scale data mining
Computer vision (uncertainty in face recognition, object relation)
Natural language processing (language uncertainty, sentence uncertainty)
Reinforcement learning (uncertainty-aware offline reinforcement learning exploration vs. exploitation)

Important Dates
Following are the proposed important dates for the workshop. All deadlines are due Anywhere on Earth (AoE). 

Paper submission deadline: November 2nd, 2022.
Paper review begins: November 7th, 2022.
Paper review due: November 16th, 2022.
Notification of decision: November 18th, 2022.
Camera-ready due: November 25th, 2022.

Submissions and Tentative CFP Guidelines:

Submissions are limited to a total of 5 pages, including all content and references, and must be in PDF format and use AAAI templates (two column format). Acknowledgements should be omitted from papers submitted for review. See AAAI-23 author kit for details at https://aaai.org/Conferences/AAAI-23/submission-guidelines/. Papers must be in trouble-free, high-resolution PDF format, formatted for US Letter (8.5′′ x 11′′) paper, using Type 1 or TrueType fonts. AAAI submissions are anonymous and must conform to the instructions (detailed below) for double-blind review. The authors must remove all author and affiliation information from their submission for review, and may replace it with other information, such as paper number and keywords.
Submitted papers will be assessed based on their novelty, technical quality, potential impact, and clarity of writing. For papers that rely heavily on empirical evaluations, the experimental methods and results should be clear, well-executed, and repeatable. Authors are strongly encouraged to make data and code publicly available whenever possible. The accepted papers will be posted on the workshop website but will not be included in the AAAI proceedings.

submission site: https://cmt3.research.microsoft.com/UDM2023/Submission/Index
Workshop Chairs:

Xujiang Zhao (NEC Laboratories America, xuzhao@nec-labs.com)
Chen Zhao (Kitware Inc., chen.zhao@kitware.com )
Feng Chen (The University of Texas at Dallas, feng.chen@utdallas.edu )
Jin-Hee Cho (Virginia Tech, jicho@vt.edu )
Haifeng Chen (NEC Laboratories America, haifeng@nec-labs.com )

Additional Information
https://charliezhaoyinpeng.github.io/UDM-AAAI23/

W31: User-Centric Artificial Intelligence for Assistance in At-Home Tasks
Recent advancements in AI and ML have enabled these technologies to enhance and improve our daily lives; however, these solutions are often based on simplified formulations and abstracted datasets that make them challenging to be applied in complex and personalized household domains. Furthermore, any household solution will require not only expertise across algorithmic AI but also experts in interaction, socio-technical issues, and problem space. Since the solutions touch on so many different fields, its research community is spread across different conferences. The workshop is designed to bring together interested AI experts who, while coming from different subfields, share the vision of using AI technologies to solve user problems at home. Participants of the workshop will have the opportunity to share their experience and progress in using AI technologies to assist and empower users at home as well as learn and engage with our expert speakers/panelists. More information and submission details can be found on our website: https://ai4athome.github.io/
Topics
We solicit contributions from topics including but not limited to:

Natural Language Processing for Household Tasks
AI Solutions for Accessibility
Social and Physical Assistance by Embodied Intelligence/Robots at Home
Assistance through Smart Home Technologies
Explainable AI (XAI) for Non-Expert Users
Semantic Knowledge in Household Tasks
Offline Learning for Household Assistive AI
Continual Learning for Household Tasks
Dataset Acquisition
Privacy, Ethics, and Societal Impact of AI for Household Tasks
Trustworthy AI and Calibrating Trust for Household Tasks

Format
The workshop will be a full-day hybrid workshop with a mix of keynotes, contribution lightning talks, poster sessions, and focused discussion.
Attendance
We welcome members of the community who are interested in this area.
Submissions
We welcome contributions of both short (2-4 pages) and long papers (6-8 pages) related to our stated vision. The contributions will be non-archival but will be hosted on our workshop website. More details and submission information are listed on our workshop website.
Workshop Chairs
Dr. Xiang Zhi Tan (Georgia Institute of Technology), Prof. Sonia Chernova (Georgia Institute of Technology), Prof. Jean Oh (Carnegie Mellon University), Russell Perkins (University of Massachusetts Lowell), Prof. Paul Robinette (University of Massachusetts Lowell), Peter Schaldenbrand (Carnegie Mellon University), Tanmay Shankar (Carnegie Mellon University), Prof. Diyi Yang (Stanford University)
For any questions and enquiry please contact Dr. Xiang Zhi Tan (zhi.tan@gatech.edu).
Additional Information
https://ai4athome.github.io/

W32: When Machine Learning Meets Dynamical Systems: Theory and Applications
The recent wave of using machine learning to analyze and manipulate real-world systems has inspired many research topics in the joint interface of machine learning and dynamical systems. However, the real world applications are diverse and complex with vulnerabilities such as simulation divergence or violation of certain prior knowledge. As ML-based dynamical models are implemented in real world systems, it generates a series of challenges including scalability, stability and trustworthiness.
Through this workshop, we aim to provide an informal and cutting-edge platform for research and discussion on the co-development between machine models and dynamical systems. We welcome all the contributions related to ML based application/theory on dynamical systems and solution to ML problem from dynamical system perspective.
Topics
We are opening this workshop to call for papers from research relevant to dynamical system and machine learning, which include (but are not limited to):

ML-based modeling of Dynamical Systems
Practical Applications of Data-driven Modeling;
Special ML structures for Learning Dynamical Systems;
Trustworthiness of ML-based Dynamical Systems;
Temporal Feature Analysis for Time Series Data;
Dynamical Systems in Model-based Reinforcement Learning;
Dynamical System Perspectives for ML Problems;
Optimization Algorithms for Learning Dynamical Systems;

Format
The workshop will last one day. It will consist of the following

invited talks with discussion;
oral presentations with discussion;
a poster session and to conclude;

We have three invited speakers, and authors of the best papers will give oral presentations.
Submissions
We welcome papers in AAAI style (from 3 to 6 pages), excluding references or supplementary materials. Submissions will be peer reviewed, double-blinded with openreview.Submission site: https://openreview.net/group?id=AAAI.org/2023/Workshop/MLmDS  
We will open the submission site in October. Authors might use as many pages of appendices as they wish but the reviewers are not required to read these. Authors have the right to withdraw papers from consideration at any time.
Note that accepted papers are considered workshop papers and can be submitted/published elsewhere. Published papers in this workshop are non-archival but will be stored permanently on the workshop website. Authors of accepted papers will be invited to participate in the Workshop day.
Organizing Committee
Lam M. Nguyen (lamnguyen.mltd@ibm.com)Trang H. Tran (htt27@cornell.edu)Wang Zhang (wzhang16@mit.edu)Subhro Das (subhro.Das@ibm.com)Tsui-Wei (Lily) Weng (lweng@ucsd.edu)
Additional Information
Supplemental workshop site: https://machinelearning-dynamic.github.io  Workshop Email: machinelearning.dynamic@gmail.com",2023
This site is protected by copyright and trademark laws under US and International law. All rights reserved. Copyright © 1995–2023 AAAI,2023
